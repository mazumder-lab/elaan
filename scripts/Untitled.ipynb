{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd21a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"\"\"/home/gridsan/shibal/.conda/envs/additive2/bin/python /home/gridsan/shibal/elaan/baselines/GamiNet/examples/gaminet_synthetic.py  --dist 'normal' --seed 1 --dataset 'synthetic' --correlation 0.5 --train_size 100 --version 1\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8523b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0] linux /home/gridsan/shibal/.conda/envs/additive2/bin/python\n",
      "2024-02-10 11:16:40.132877: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "===================FOLD: 0 ================\n",
      "\u001b[32m[I 2024-02-10 11:16:53,216]\u001b[0m A new study created in memory with name: no-name-ad13233c-1d16-40d0-8dcb-cc914161f11c\u001b[0m\n",
      "2024-02-10 11:16:53.810755: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-10 11:16:54.006595: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "[50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      " 98 99]\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 4.54950, val loss: 4.47838\n",
      "Main effects training epoch: 2, train loss: 4.53994, val loss: 4.46883\n",
      "Main effects training epoch: 3, train loss: 4.53058, val loss: 4.45957\n",
      "Main effects training epoch: 4, train loss: 4.52131, val loss: 4.45045\n",
      "Main effects training epoch: 5, train loss: 4.51226, val loss: 4.44151\n",
      "Main effects training epoch: 6, train loss: 4.50354, val loss: 4.43291\n",
      "Main effects training epoch: 7, train loss: 4.49500, val loss: 4.42450\n",
      "Main effects training epoch: 8, train loss: 4.48655, val loss: 4.41620\n",
      "Main effects training epoch: 9, train loss: 4.47831, val loss: 4.40803\n",
      "Main effects training epoch: 10, train loss: 4.47025, val loss: 4.40004\n",
      "Main effects training epoch: 11, train loss: 4.46230, val loss: 4.39218\n",
      "Main effects training epoch: 12, train loss: 4.45445, val loss: 4.38444\n",
      "Main effects training epoch: 13, train loss: 4.44669, val loss: 4.37682\n",
      "Main effects training epoch: 14, train loss: 4.43890, val loss: 4.36917\n",
      "Main effects training epoch: 15, train loss: 4.43105, val loss: 4.36147\n",
      "Main effects training epoch: 16, train loss: 4.42316, val loss: 4.35371\n",
      "Main effects training epoch: 17, train loss: 4.41522, val loss: 4.34590\n",
      "Main effects training epoch: 18, train loss: 4.40717, val loss: 4.33802\n",
      "Main effects training epoch: 19, train loss: 4.39909, val loss: 4.33008\n",
      "Main effects training epoch: 20, train loss: 4.39094, val loss: 4.32209\n",
      "Main effects training epoch: 21, train loss: 4.38271, val loss: 4.31401\n",
      "Main effects training epoch: 22, train loss: 4.37446, val loss: 4.30589\n",
      "Main effects training epoch: 23, train loss: 4.36622, val loss: 4.29775\n",
      "Main effects training epoch: 24, train loss: 4.35794, val loss: 4.28958\n",
      "Main effects training epoch: 25, train loss: 4.34959, val loss: 4.28134\n",
      "Main effects training epoch: 26, train loss: 4.34121, val loss: 4.27308\n",
      "Main effects training epoch: 27, train loss: 4.33278, val loss: 4.26476\n",
      "Main effects training epoch: 28, train loss: 4.32431, val loss: 4.25641\n",
      "Main effects training epoch: 29, train loss: 4.31582, val loss: 4.24804\n",
      "Main effects training epoch: 30, train loss: 4.30724, val loss: 4.23959\n",
      "Main effects training epoch: 31, train loss: 4.29860, val loss: 4.23109\n",
      "Main effects training epoch: 32, train loss: 4.28986, val loss: 4.22249\n",
      "Main effects training epoch: 33, train loss: 4.28106, val loss: 4.21384\n",
      "Main effects training epoch: 34, train loss: 4.27223, val loss: 4.20515\n",
      "Main effects training epoch: 35, train loss: 4.26330, val loss: 4.19638\n",
      "Main effects training epoch: 36, train loss: 4.25429, val loss: 4.18753\n",
      "Main effects training epoch: 37, train loss: 4.24522, val loss: 4.17863\n",
      "Main effects training epoch: 38, train loss: 4.23613, val loss: 4.16973\n",
      "Main effects training epoch: 39, train loss: 4.22696, val loss: 4.16077\n",
      "Main effects training epoch: 40, train loss: 4.21772, val loss: 4.15175\n",
      "Main effects training epoch: 41, train loss: 4.20838, val loss: 4.14260\n",
      "Main effects training epoch: 42, train loss: 4.19897, val loss: 4.13338\n",
      "Main effects training epoch: 43, train loss: 4.18945, val loss: 4.12405\n",
      "Main effects training epoch: 44, train loss: 4.17986, val loss: 4.11458\n",
      "Main effects training epoch: 45, train loss: 4.17016, val loss: 4.10494\n",
      "Main effects training epoch: 46, train loss: 4.16037, val loss: 4.09518\n",
      "Main effects training epoch: 47, train loss: 4.15045, val loss: 4.08529\n",
      "Main effects training epoch: 48, train loss: 4.14046, val loss: 4.07532\n",
      "Main effects training epoch: 49, train loss: 4.13043, val loss: 4.06529\n",
      "Main effects training epoch: 50, train loss: 4.12032, val loss: 4.05519\n",
      "Main effects training epoch: 51, train loss: 4.11005, val loss: 4.04494\n",
      "Main effects training epoch: 52, train loss: 4.09966, val loss: 4.03459\n",
      "Main effects training epoch: 53, train loss: 4.08921, val loss: 4.02417\n",
      "Main effects training epoch: 54, train loss: 4.07867, val loss: 4.01366\n",
      "Main effects training epoch: 55, train loss: 4.06801, val loss: 4.00303\n",
      "Main effects training epoch: 56, train loss: 4.05727, val loss: 3.99234\n",
      "Main effects training epoch: 57, train loss: 4.04640, val loss: 3.98150\n",
      "Main effects training epoch: 58, train loss: 4.03541, val loss: 3.97049\n",
      "Main effects training epoch: 59, train loss: 4.02431, val loss: 3.95937\n",
      "Main effects training epoch: 60, train loss: 4.01321, val loss: 3.94826\n",
      "Main effects training epoch: 61, train loss: 4.00203, val loss: 3.93708\n",
      "Main effects training epoch: 62, train loss: 3.99073, val loss: 3.92576\n",
      "Main effects training epoch: 63, train loss: 3.97932, val loss: 3.91434\n",
      "Main effects training epoch: 64, train loss: 3.96787, val loss: 3.90288\n",
      "Main effects training epoch: 65, train loss: 3.95630, val loss: 3.89132\n",
      "Main effects training epoch: 66, train loss: 3.94473, val loss: 3.87977\n",
      "Main effects training epoch: 67, train loss: 3.93317, val loss: 3.86823\n",
      "Main effects training epoch: 68, train loss: 3.92157, val loss: 3.85666\n",
      "Main effects training epoch: 69, train loss: 3.90991, val loss: 3.84506\n",
      "Main effects training epoch: 70, train loss: 3.89815, val loss: 3.83335\n",
      "Main effects training epoch: 71, train loss: 3.88628, val loss: 3.82154\n",
      "Main effects training epoch: 72, train loss: 3.87440, val loss: 3.80971\n",
      "Main effects training epoch: 73, train loss: 3.86240, val loss: 3.79776\n",
      "Main effects training epoch: 74, train loss: 3.85027, val loss: 3.78567\n",
      "Main effects training epoch: 75, train loss: 3.83803, val loss: 3.77347\n",
      "Main effects training epoch: 76, train loss: 3.82561, val loss: 3.76112\n",
      "Main effects training epoch: 77, train loss: 3.81304, val loss: 3.74863\n",
      "Main effects training epoch: 78, train loss: 3.80039, val loss: 3.73607\n",
      "Main effects training epoch: 79, train loss: 3.78760, val loss: 3.72336\n",
      "Main effects training epoch: 80, train loss: 3.77468, val loss: 3.71052\n",
      "Main effects training epoch: 81, train loss: 3.76165, val loss: 3.69757\n",
      "Main effects training epoch: 82, train loss: 3.74859, val loss: 3.68458\n",
      "Main effects training epoch: 83, train loss: 3.73548, val loss: 3.67153\n",
      "Main effects training epoch: 84, train loss: 3.72228, val loss: 3.65840\n",
      "Main effects training epoch: 85, train loss: 3.70887, val loss: 3.64504\n",
      "Main effects training epoch: 86, train loss: 3.69530, val loss: 3.63152\n",
      "Main effects training epoch: 87, train loss: 3.68155, val loss: 3.61782\n",
      "Main effects training epoch: 88, train loss: 3.66766, val loss: 3.60397\n",
      "Main effects training epoch: 89, train loss: 3.65364, val loss: 3.59000\n",
      "Main effects training epoch: 90, train loss: 3.63938, val loss: 3.57580\n",
      "Main effects training epoch: 91, train loss: 3.62492, val loss: 3.56142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 92, train loss: 3.61041, val loss: 3.54700\n",
      "Main effects training epoch: 93, train loss: 3.59573, val loss: 3.53240\n",
      "Main effects training epoch: 94, train loss: 3.58097, val loss: 3.51775\n",
      "Main effects training epoch: 95, train loss: 3.56614, val loss: 3.50304\n",
      "Main effects training epoch: 96, train loss: 3.55118, val loss: 3.48819\n",
      "Main effects training epoch: 97, train loss: 3.53612, val loss: 3.47327\n",
      "Main effects training epoch: 98, train loss: 3.52086, val loss: 3.45813\n",
      "Main effects training epoch: 99, train loss: 3.50556, val loss: 3.44298\n",
      "Main effects training epoch: 100, train loss: 3.49007, val loss: 3.42764\n",
      "Main effects training epoch: 101, train loss: 3.47449, val loss: 3.41220\n",
      "Main effects training epoch: 102, train loss: 3.45884, val loss: 3.39670\n",
      "Main effects training epoch: 103, train loss: 3.44303, val loss: 3.38105\n",
      "Main effects training epoch: 104, train loss: 3.42709, val loss: 3.36525\n",
      "Main effects training epoch: 105, train loss: 3.41107, val loss: 3.34938\n",
      "Main effects training epoch: 106, train loss: 3.39494, val loss: 3.33342\n",
      "Main effects training epoch: 107, train loss: 3.37868, val loss: 3.31734\n",
      "Main effects training epoch: 108, train loss: 3.36215, val loss: 3.30100\n",
      "Main effects training epoch: 109, train loss: 3.34547, val loss: 3.28454\n",
      "Main effects training epoch: 110, train loss: 3.32863, val loss: 3.26791\n",
      "Main effects training epoch: 111, train loss: 3.31165, val loss: 3.25115\n",
      "Main effects training epoch: 112, train loss: 3.29453, val loss: 3.23425\n",
      "Main effects training epoch: 113, train loss: 3.27724, val loss: 3.21719\n",
      "Main effects training epoch: 114, train loss: 3.25985, val loss: 3.20003\n",
      "Main effects training epoch: 115, train loss: 3.24241, val loss: 3.18281\n",
      "Main effects training epoch: 116, train loss: 3.22465, val loss: 3.16527\n",
      "Main effects training epoch: 117, train loss: 3.20686, val loss: 3.14769\n",
      "Main effects training epoch: 118, train loss: 3.18890, val loss: 3.12994\n",
      "Main effects training epoch: 119, train loss: 3.17088, val loss: 3.11213\n",
      "Main effects training epoch: 120, train loss: 3.15266, val loss: 3.09413\n",
      "Main effects training epoch: 121, train loss: 3.13428, val loss: 3.07597\n",
      "Main effects training epoch: 122, train loss: 3.11574, val loss: 3.05766\n",
      "Main effects training epoch: 123, train loss: 3.09699, val loss: 3.03914\n",
      "Main effects training epoch: 124, train loss: 3.07806, val loss: 3.02045\n",
      "Main effects training epoch: 125, train loss: 3.05908, val loss: 3.00169\n",
      "Main effects training epoch: 126, train loss: 3.03989, val loss: 2.98277\n",
      "Main effects training epoch: 127, train loss: 3.02048, val loss: 2.96365\n",
      "Main effects training epoch: 128, train loss: 3.00084, val loss: 2.94429\n",
      "Main effects training epoch: 129, train loss: 2.98105, val loss: 2.92479\n",
      "Main effects training epoch: 130, train loss: 2.96121, val loss: 2.90526\n",
      "Main effects training epoch: 131, train loss: 2.94121, val loss: 2.88556\n",
      "Main effects training epoch: 132, train loss: 2.92114, val loss: 2.86579\n",
      "Main effects training epoch: 133, train loss: 2.90077, val loss: 2.84574\n",
      "Main effects training epoch: 134, train loss: 2.88042, val loss: 2.82572\n",
      "Main effects training epoch: 135, train loss: 2.86013, val loss: 2.80575\n",
      "Main effects training epoch: 136, train loss: 2.83978, val loss: 2.78574\n",
      "Main effects training epoch: 137, train loss: 2.81918, val loss: 2.76550\n",
      "Main effects training epoch: 138, train loss: 2.79858, val loss: 2.74526\n",
      "Main effects training epoch: 139, train loss: 2.77774, val loss: 2.72479\n",
      "Main effects training epoch: 140, train loss: 2.75679, val loss: 2.70421\n",
      "Main effects training epoch: 141, train loss: 2.73565, val loss: 2.68344\n",
      "Main effects training epoch: 142, train loss: 2.71429, val loss: 2.66250\n",
      "Main effects training epoch: 143, train loss: 2.69250, val loss: 2.64117\n",
      "Main effects training epoch: 144, train loss: 2.67070, val loss: 2.61984\n",
      "Main effects training epoch: 145, train loss: 2.64868, val loss: 2.59836\n",
      "Main effects training epoch: 146, train loss: 2.62645, val loss: 2.57667\n",
      "Main effects training epoch: 147, train loss: 2.60411, val loss: 2.55490\n",
      "Main effects training epoch: 148, train loss: 2.58145, val loss: 2.53280\n",
      "Main effects training epoch: 149, train loss: 2.55863, val loss: 2.51053\n",
      "Main effects training epoch: 150, train loss: 2.53574, val loss: 2.48823\n",
      "Main effects training epoch: 151, train loss: 2.51273, val loss: 2.46585\n",
      "Main effects training epoch: 152, train loss: 2.48971, val loss: 2.44346\n",
      "Main effects training epoch: 153, train loss: 2.46672, val loss: 2.42111\n",
      "Main effects training epoch: 154, train loss: 2.44345, val loss: 2.39852\n",
      "Main effects training epoch: 155, train loss: 2.41970, val loss: 2.37551\n",
      "Main effects training epoch: 156, train loss: 2.39600, val loss: 2.35256\n",
      "Main effects training epoch: 157, train loss: 2.37223, val loss: 2.32956\n",
      "Main effects training epoch: 158, train loss: 2.34846, val loss: 2.30660\n",
      "Main effects training epoch: 159, train loss: 2.32457, val loss: 2.28354\n",
      "Main effects training epoch: 160, train loss: 2.30062, val loss: 2.26044\n",
      "Main effects training epoch: 161, train loss: 2.27649, val loss: 2.23720\n",
      "Main effects training epoch: 162, train loss: 2.25218, val loss: 2.21382\n",
      "Main effects training epoch: 163, train loss: 2.22773, val loss: 2.19035\n",
      "Main effects training epoch: 164, train loss: 2.20354, val loss: 2.16716\n",
      "Main effects training epoch: 165, train loss: 2.17922, val loss: 2.14388\n",
      "Main effects training epoch: 166, train loss: 2.15498, val loss: 2.12071\n",
      "Main effects training epoch: 167, train loss: 2.13060, val loss: 2.09742\n",
      "Main effects training epoch: 168, train loss: 2.10615, val loss: 2.07406\n",
      "Main effects training epoch: 169, train loss: 2.08149, val loss: 2.05054\n",
      "Main effects training epoch: 170, train loss: 2.05656, val loss: 2.02675\n",
      "Main effects training epoch: 171, train loss: 2.03154, val loss: 2.00291\n",
      "Main effects training epoch: 172, train loss: 2.00643, val loss: 1.97901\n",
      "Main effects training epoch: 173, train loss: 1.98134, val loss: 1.95515\n",
      "Main effects training epoch: 174, train loss: 1.95664, val loss: 1.93167\n",
      "Main effects training epoch: 175, train loss: 1.93198, val loss: 1.90825\n",
      "Main effects training epoch: 176, train loss: 1.90755, val loss: 1.88509\n",
      "Main effects training epoch: 177, train loss: 1.88294, val loss: 1.86177\n",
      "Main effects training epoch: 178, train loss: 1.85836, val loss: 1.83852\n",
      "Main effects training epoch: 179, train loss: 1.83407, val loss: 1.81558\n",
      "Main effects training epoch: 180, train loss: 1.80955, val loss: 1.79246\n",
      "Main effects training epoch: 181, train loss: 1.78479, val loss: 1.76915\n",
      "Main effects training epoch: 182, train loss: 1.76003, val loss: 1.74588\n",
      "Main effects training epoch: 183, train loss: 1.73538, val loss: 1.72275\n",
      "Main effects training epoch: 184, train loss: 1.71082, val loss: 1.69973\n",
      "Main effects training epoch: 185, train loss: 1.68639, val loss: 1.67688\n",
      "Main effects training epoch: 186, train loss: 1.66211, val loss: 1.65422\n",
      "Main effects training epoch: 187, train loss: 1.63790, val loss: 1.63168\n",
      "Main effects training epoch: 188, train loss: 1.61408, val loss: 1.60954\n",
      "Main effects training epoch: 189, train loss: 1.59052, val loss: 1.58769\n",
      "Main effects training epoch: 190, train loss: 1.56689, val loss: 1.56581\n",
      "Main effects training epoch: 191, train loss: 1.54322, val loss: 1.54394\n",
      "Main effects training epoch: 192, train loss: 1.51991, val loss: 1.52244\n",
      "Main effects training epoch: 193, train loss: 1.49685, val loss: 1.50123\n",
      "Main effects training epoch: 194, train loss: 1.47352, val loss: 1.47982\n",
      "Main effects training epoch: 195, train loss: 1.45010, val loss: 1.45838\n",
      "Main effects training epoch: 196, train loss: 1.42670, val loss: 1.43702\n",
      "Main effects training epoch: 197, train loss: 1.40352, val loss: 1.41594\n",
      "Main effects training epoch: 198, train loss: 1.38072, val loss: 1.39525\n",
      "Main effects training epoch: 199, train loss: 1.35849, val loss: 1.37514\n",
      "Main effects training epoch: 200, train loss: 1.33651, val loss: 1.35531\n",
      "Main effects training epoch: 201, train loss: 1.31481, val loss: 1.33581\n",
      "Main effects training epoch: 202, train loss: 1.29323, val loss: 1.31649\n",
      "Main effects training epoch: 203, train loss: 1.27228, val loss: 1.29778\n",
      "Main effects training epoch: 204, train loss: 1.25169, val loss: 1.27949\n",
      "Main effects training epoch: 205, train loss: 1.23187, val loss: 1.26195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 206, train loss: 1.21246, val loss: 1.24483\n",
      "Main effects training epoch: 207, train loss: 1.19344, val loss: 1.22813\n",
      "Main effects training epoch: 208, train loss: 1.17472, val loss: 1.21175\n",
      "Main effects training epoch: 209, train loss: 1.15625, val loss: 1.19566\n",
      "Main effects training epoch: 210, train loss: 1.13802, val loss: 1.17988\n",
      "Main effects training epoch: 211, train loss: 1.12030, val loss: 1.16460\n",
      "Main effects training epoch: 212, train loss: 1.10291, val loss: 1.14969\n",
      "Main effects training epoch: 213, train loss: 1.08620, val loss: 1.13542\n",
      "Main effects training epoch: 214, train loss: 1.06969, val loss: 1.12143\n",
      "Main effects training epoch: 215, train loss: 1.05394, val loss: 1.10817\n",
      "Main effects training epoch: 216, train loss: 1.03865, val loss: 1.09537\n",
      "Main effects training epoch: 217, train loss: 1.02350, val loss: 1.08277\n",
      "Main effects training epoch: 218, train loss: 1.00863, val loss: 1.07050\n",
      "Main effects training epoch: 219, train loss: 0.99422, val loss: 1.05870\n",
      "Main effects training epoch: 220, train loss: 0.98004, val loss: 1.04717\n",
      "Main effects training epoch: 221, train loss: 0.96647, val loss: 1.03624\n",
      "Main effects training epoch: 222, train loss: 0.95325, val loss: 1.02569\n",
      "Main effects training epoch: 223, train loss: 0.94064, val loss: 1.01572\n",
      "Main effects training epoch: 224, train loss: 0.92828, val loss: 1.00606\n",
      "Main effects training epoch: 225, train loss: 0.91667, val loss: 0.99709\n",
      "Main effects training epoch: 226, train loss: 0.90558, val loss: 0.98863\n",
      "Main effects training epoch: 227, train loss: 0.89489, val loss: 0.98056\n",
      "Main effects training epoch: 228, train loss: 0.88460, val loss: 0.97289\n",
      "Main effects training epoch: 229, train loss: 0.87442, val loss: 0.96542\n",
      "Main effects training epoch: 230, train loss: 0.86468, val loss: 0.95836\n",
      "Main effects training epoch: 231, train loss: 0.85508, val loss: 0.95152\n",
      "Main effects training epoch: 232, train loss: 0.84561, val loss: 0.94489\n",
      "Main effects training epoch: 233, train loss: 0.83645, val loss: 0.93860\n",
      "Main effects training epoch: 234, train loss: 0.82799, val loss: 0.93291\n",
      "Main effects training epoch: 235, train loss: 0.81984, val loss: 0.92754\n",
      "Main effects training epoch: 236, train loss: 0.81196, val loss: 0.92248\n",
      "Main effects training epoch: 237, train loss: 0.80437, val loss: 0.91774\n",
      "Main effects training epoch: 238, train loss: 0.79723, val loss: 0.91343\n",
      "Main effects training epoch: 239, train loss: 0.79040, val loss: 0.90943\n",
      "Main effects training epoch: 240, train loss: 0.78417, val loss: 0.90594\n",
      "Main effects training epoch: 241, train loss: 0.77813, val loss: 0.90269\n",
      "Main effects training epoch: 242, train loss: 0.77250, val loss: 0.89981\n",
      "Main effects training epoch: 243, train loss: 0.76749, val loss: 0.89738\n",
      "Main effects training epoch: 244, train loss: 0.76262, val loss: 0.89518\n",
      "Main effects training epoch: 245, train loss: 0.75803, val loss: 0.89327\n",
      "Main effects training epoch: 246, train loss: 0.75360, val loss: 0.89161\n",
      "Main effects training epoch: 247, train loss: 0.74944, val loss: 0.89024\n",
      "Main effects training epoch: 248, train loss: 0.74562, val loss: 0.88917\n",
      "Main effects training epoch: 249, train loss: 0.74217, val loss: 0.88840\n",
      "Main effects training epoch: 250, train loss: 0.73911, val loss: 0.88789\n",
      "Main effects training epoch: 251, train loss: 0.73616, val loss: 0.88761\n",
      "Main effects training epoch: 252, train loss: 0.73357, val loss: 0.88755\n",
      "Main effects training epoch: 253, train loss: 0.73137, val loss: 0.88768\n",
      "Main effects training epoch: 254, train loss: 0.72941, val loss: 0.88797\n",
      "Main effects training epoch: 255, train loss: 0.72765, val loss: 0.88841\n",
      "Main effects training epoch: 256, train loss: 0.72608, val loss: 0.88898\n",
      "Main effects training epoch: 257, train loss: 0.72466, val loss: 0.88968\n",
      "Main effects training epoch: 258, train loss: 0.72338, val loss: 0.89053\n",
      "Main effects training epoch: 259, train loss: 0.72229, val loss: 0.89142\n",
      "Main effects training epoch: 260, train loss: 0.72128, val loss: 0.89253\n",
      "Main effects training epoch: 261, train loss: 0.72050, val loss: 0.89350\n",
      "Main effects training epoch: 262, train loss: 0.71984, val loss: 0.89446\n",
      "Main effects training epoch: 263, train loss: 0.71927, val loss: 0.89534\n",
      "Main effects training epoch: 264, train loss: 0.71875, val loss: 0.89632\n",
      "Main effects training epoch: 265, train loss: 0.71831, val loss: 0.89719\n",
      "Main effects training epoch: 266, train loss: 0.71792, val loss: 0.89807\n",
      "Main effects training epoch: 267, train loss: 0.71758, val loss: 0.89878\n",
      "Main effects training epoch: 268, train loss: 0.71728, val loss: 0.89934\n",
      "Main effects training epoch: 269, train loss: 0.71700, val loss: 0.90003\n",
      "Main effects training epoch: 270, train loss: 0.71676, val loss: 0.90082\n",
      "Main effects training epoch: 271, train loss: 0.71653, val loss: 0.90152\n",
      "Main effects training epoch: 272, train loss: 0.71632, val loss: 0.90231\n",
      "Main effects training epoch: 273, train loss: 0.71612, val loss: 0.90287\n",
      "Main effects training epoch: 274, train loss: 0.71591, val loss: 0.90325\n",
      "Main effects training epoch: 275, train loss: 0.71567, val loss: 0.90340\n",
      "Main effects training epoch: 276, train loss: 0.71541, val loss: 0.90346\n",
      "Main effects training epoch: 277, train loss: 0.71512, val loss: 0.90339\n",
      "Main effects training epoch: 278, train loss: 0.71485, val loss: 0.90329\n",
      "Main effects training epoch: 279, train loss: 0.71457, val loss: 0.90315\n",
      "Main effects training epoch: 280, train loss: 0.71424, val loss: 0.90271\n",
      "Main effects training epoch: 281, train loss: 0.71391, val loss: 0.90219\n",
      "Main effects training epoch: 282, train loss: 0.71357, val loss: 0.90162\n",
      "Main effects training epoch: 283, train loss: 0.71324, val loss: 0.90109\n",
      "Main effects training epoch: 284, train loss: 0.71291, val loss: 0.90056\n",
      "Main effects training epoch: 285, train loss: 0.71259, val loss: 0.90013\n",
      "Main effects training epoch: 286, train loss: 0.71225, val loss: 0.89963\n",
      "Main effects training epoch: 287, train loss: 0.71192, val loss: 0.89915\n",
      "Main effects training epoch: 288, train loss: 0.71158, val loss: 0.89859\n",
      "Main effects training epoch: 289, train loss: 0.71124, val loss: 0.89777\n",
      "Main effects training epoch: 290, train loss: 0.71092, val loss: 0.89714\n",
      "Main effects training epoch: 291, train loss: 0.71061, val loss: 0.89672\n",
      "Main effects training epoch: 292, train loss: 0.71030, val loss: 0.89620\n",
      "Main effects training epoch: 293, train loss: 0.70999, val loss: 0.89570\n",
      "Main effects training epoch: 294, train loss: 0.70969, val loss: 0.89533\n",
      "Main effects training epoch: 295, train loss: 0.70939, val loss: 0.89507\n",
      "Main effects training epoch: 296, train loss: 0.70910, val loss: 0.89485\n",
      "Main effects training epoch: 297, train loss: 0.70881, val loss: 0.89480\n",
      "Main effects training epoch: 298, train loss: 0.70853, val loss: 0.89481\n",
      "Main effects training epoch: 299, train loss: 0.70825, val loss: 0.89482\n",
      "Main effects training epoch: 300, train loss: 0.70796, val loss: 0.89464\n",
      "Main effects training epoch: 301, train loss: 0.70768, val loss: 0.89455\n",
      "Main effects training epoch: 302, train loss: 0.70740, val loss: 0.89457\n",
      "Main effects training epoch: 303, train loss: 0.70715, val loss: 0.89475\n",
      "Early stop at epoch 303, with validation loss: 0.89475\n",
      "##########Stage 1: main effect training stop.##########\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.68583, val loss: 0.79842\n",
      "Interaction training epoch: 2, train loss: 0.68356, val loss: 0.79664\n",
      "Interaction training epoch: 3, train loss: 0.68177, val loss: 0.79532\n",
      "Interaction training epoch: 4, train loss: 0.67997, val loss: 0.79386\n",
      "Interaction training epoch: 5, train loss: 0.67799, val loss: 0.79278\n",
      "Interaction training epoch: 6, train loss: 0.67604, val loss: 0.79184\n",
      "Interaction training epoch: 7, train loss: 0.67426, val loss: 0.79109\n",
      "Interaction training epoch: 8, train loss: 0.67235, val loss: 0.79074\n",
      "Interaction training epoch: 9, train loss: 0.67052, val loss: 0.79041\n",
      "Interaction training epoch: 10, train loss: 0.66902, val loss: 0.78993\n",
      "Interaction training epoch: 11, train loss: 0.66715, val loss: 0.78985\n",
      "Interaction training epoch: 12, train loss: 0.66525, val loss: 0.78990\n",
      "Interaction training epoch: 13, train loss: 0.66362, val loss: 0.78982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 14, train loss: 0.66181, val loss: 0.78993\n",
      "Interaction training epoch: 15, train loss: 0.66030, val loss: 0.78977\n",
      "Interaction training epoch: 16, train loss: 0.65908, val loss: 0.78948\n",
      "Interaction training epoch: 17, train loss: 0.65756, val loss: 0.78931\n",
      "Interaction training epoch: 18, train loss: 0.65626, val loss: 0.78918\n",
      "Interaction training epoch: 19, train loss: 0.65478, val loss: 0.78918\n",
      "Interaction training epoch: 20, train loss: 0.65283, val loss: 0.78937\n",
      "Interaction training epoch: 21, train loss: 0.65069, val loss: 0.78974\n",
      "Interaction training epoch: 22, train loss: 0.64872, val loss: 0.79003\n",
      "Interaction training epoch: 23, train loss: 0.64682, val loss: 0.79061\n",
      "Interaction training epoch: 24, train loss: 0.64510, val loss: 0.79101\n",
      "Interaction training epoch: 25, train loss: 0.64353, val loss: 0.79102\n",
      "Interaction training epoch: 26, train loss: 0.64196, val loss: 0.79111\n",
      "Interaction training epoch: 27, train loss: 0.64045, val loss: 0.79125\n",
      "Interaction training epoch: 28, train loss: 0.63900, val loss: 0.79156\n",
      "Interaction training epoch: 29, train loss: 0.63756, val loss: 0.79163\n",
      "Interaction training epoch: 30, train loss: 0.63612, val loss: 0.79196\n",
      "Interaction training epoch: 31, train loss: 0.63465, val loss: 0.79192\n",
      "Interaction training epoch: 32, train loss: 0.63324, val loss: 0.79199\n",
      "Interaction training epoch: 33, train loss: 0.63185, val loss: 0.79204\n",
      "Interaction training epoch: 34, train loss: 0.63043, val loss: 0.79207\n",
      "Interaction training epoch: 35, train loss: 0.62895, val loss: 0.79198\n",
      "Interaction training epoch: 36, train loss: 0.62739, val loss: 0.79206\n",
      "Interaction training epoch: 37, train loss: 0.62592, val loss: 0.79204\n",
      "Interaction training epoch: 38, train loss: 0.62438, val loss: 0.79193\n",
      "Interaction training epoch: 39, train loss: 0.62276, val loss: 0.79159\n",
      "Interaction training epoch: 40, train loss: 0.62104, val loss: 0.79096\n",
      "Interaction training epoch: 41, train loss: 0.61946, val loss: 0.79012\n",
      "Interaction training epoch: 42, train loss: 0.61782, val loss: 0.78953\n",
      "Interaction training epoch: 43, train loss: 0.61626, val loss: 0.78872\n",
      "Interaction training epoch: 44, train loss: 0.61483, val loss: 0.78792\n",
      "Interaction training epoch: 45, train loss: 0.61340, val loss: 0.78742\n",
      "Interaction training epoch: 46, train loss: 0.61180, val loss: 0.78716\n",
      "Interaction training epoch: 47, train loss: 0.61012, val loss: 0.78730\n",
      "Interaction training epoch: 48, train loss: 0.60840, val loss: 0.78765\n",
      "Interaction training epoch: 49, train loss: 0.60670, val loss: 0.78818\n",
      "Interaction training epoch: 50, train loss: 0.60511, val loss: 0.78876\n",
      "Interaction training epoch: 51, train loss: 0.60343, val loss: 0.78925\n",
      "Interaction training epoch: 52, train loss: 0.60173, val loss: 0.78924\n",
      "Interaction training epoch: 53, train loss: 0.60001, val loss: 0.78926\n",
      "Interaction training epoch: 54, train loss: 0.59815, val loss: 0.78943\n",
      "Interaction training epoch: 55, train loss: 0.59641, val loss: 0.78998\n",
      "Interaction training epoch: 56, train loss: 0.59468, val loss: 0.79009\n",
      "Interaction training epoch: 57, train loss: 0.59287, val loss: 0.78999\n",
      "Interaction training epoch: 58, train loss: 0.59106, val loss: 0.78994\n",
      "Interaction training epoch: 59, train loss: 0.58924, val loss: 0.78971\n",
      "Interaction training epoch: 60, train loss: 0.58739, val loss: 0.78970\n",
      "Interaction training epoch: 61, train loss: 0.58553, val loss: 0.78989\n",
      "Interaction training epoch: 62, train loss: 0.58367, val loss: 0.78973\n",
      "Interaction training epoch: 63, train loss: 0.58192, val loss: 0.78939\n",
      "Interaction training epoch: 64, train loss: 0.58021, val loss: 0.78889\n",
      "Interaction training epoch: 65, train loss: 0.57848, val loss: 0.78868\n",
      "Interaction training epoch: 66, train loss: 0.57671, val loss: 0.78825\n",
      "Interaction training epoch: 67, train loss: 0.57498, val loss: 0.78738\n",
      "Interaction training epoch: 68, train loss: 0.57324, val loss: 0.78664\n",
      "Interaction training epoch: 69, train loss: 0.57153, val loss: 0.78584\n",
      "Interaction training epoch: 70, train loss: 0.56981, val loss: 0.78525\n",
      "Interaction training epoch: 71, train loss: 0.56787, val loss: 0.78533\n",
      "Interaction training epoch: 72, train loss: 0.56611, val loss: 0.78502\n",
      "Interaction training epoch: 73, train loss: 0.56435, val loss: 0.78480\n",
      "Interaction training epoch: 74, train loss: 0.56259, val loss: 0.78467\n",
      "Interaction training epoch: 75, train loss: 0.56065, val loss: 0.78499\n",
      "Interaction training epoch: 76, train loss: 0.55871, val loss: 0.78540\n",
      "Interaction training epoch: 77, train loss: 0.55670, val loss: 0.78620\n",
      "Interaction training epoch: 78, train loss: 0.55474, val loss: 0.78666\n",
      "Interaction training epoch: 79, train loss: 0.55273, val loss: 0.78730\n",
      "Interaction training epoch: 80, train loss: 0.55067, val loss: 0.78790\n",
      "Interaction training epoch: 81, train loss: 0.54878, val loss: 0.78910\n",
      "Interaction training epoch: 82, train loss: 0.54706, val loss: 0.79027\n",
      "Interaction training epoch: 83, train loss: 0.54541, val loss: 0.79138\n",
      "Interaction training epoch: 84, train loss: 0.54392, val loss: 0.79229\n",
      "Interaction training epoch: 85, train loss: 0.54196, val loss: 0.79245\n",
      "Interaction training epoch: 86, train loss: 0.53993, val loss: 0.79248\n",
      "Interaction training epoch: 87, train loss: 0.53780, val loss: 0.79255\n",
      "Interaction training epoch: 88, train loss: 0.53551, val loss: 0.79178\n",
      "Interaction training epoch: 89, train loss: 0.53317, val loss: 0.79054\n",
      "Interaction training epoch: 90, train loss: 0.53080, val loss: 0.78921\n",
      "Interaction training epoch: 91, train loss: 0.52864, val loss: 0.78806\n",
      "Interaction training epoch: 92, train loss: 0.52663, val loss: 0.78709\n",
      "Interaction training epoch: 93, train loss: 0.52464, val loss: 0.78624\n",
      "Interaction training epoch: 94, train loss: 0.52259, val loss: 0.78560\n",
      "Interaction training epoch: 95, train loss: 0.52058, val loss: 0.78455\n",
      "Interaction training epoch: 96, train loss: 0.51871, val loss: 0.78320\n",
      "Interaction training epoch: 97, train loss: 0.51682, val loss: 0.78169\n",
      "Interaction training epoch: 98, train loss: 0.51490, val loss: 0.78079\n",
      "Interaction training epoch: 99, train loss: 0.51279, val loss: 0.78053\n",
      "Interaction training epoch: 100, train loss: 0.51068, val loss: 0.78032\n",
      "Interaction training epoch: 101, train loss: 0.50844, val loss: 0.78062\n",
      "Interaction training epoch: 102, train loss: 0.50628, val loss: 0.78075\n",
      "Interaction training epoch: 103, train loss: 0.50397, val loss: 0.78125\n",
      "Interaction training epoch: 104, train loss: 0.50172, val loss: 0.78146\n",
      "Interaction training epoch: 105, train loss: 0.49954, val loss: 0.78163\n",
      "Interaction training epoch: 106, train loss: 0.49749, val loss: 0.78161\n",
      "Interaction training epoch: 107, train loss: 0.49552, val loss: 0.78175\n",
      "Interaction training epoch: 108, train loss: 0.49353, val loss: 0.78149\n",
      "Interaction training epoch: 109, train loss: 0.49159, val loss: 0.78165\n",
      "Interaction training epoch: 110, train loss: 0.48978, val loss: 0.78198\n",
      "Interaction training epoch: 111, train loss: 0.48792, val loss: 0.78167\n",
      "Interaction training epoch: 112, train loss: 0.48622, val loss: 0.78198\n",
      "Interaction training epoch: 113, train loss: 0.48444, val loss: 0.78227\n",
      "Interaction training epoch: 114, train loss: 0.48241, val loss: 0.78241\n",
      "Interaction training epoch: 115, train loss: 0.48015, val loss: 0.78187\n",
      "Interaction training epoch: 116, train loss: 0.47784, val loss: 0.78121\n",
      "Interaction training epoch: 117, train loss: 0.47536, val loss: 0.77974\n",
      "Interaction training epoch: 118, train loss: 0.47305, val loss: 0.77897\n",
      "Interaction training epoch: 119, train loss: 0.47079, val loss: 0.77781\n",
      "Interaction training epoch: 120, train loss: 0.46868, val loss: 0.77688\n",
      "Interaction training epoch: 121, train loss: 0.46655, val loss: 0.77640\n",
      "Interaction training epoch: 122, train loss: 0.46437, val loss: 0.77598\n",
      "Interaction training epoch: 123, train loss: 0.46217, val loss: 0.77542\n",
      "Interaction training epoch: 124, train loss: 0.45980, val loss: 0.77507\n",
      "Interaction training epoch: 125, train loss: 0.45738, val loss: 0.77480\n",
      "Interaction training epoch: 126, train loss: 0.45500, val loss: 0.77462\n",
      "Interaction training epoch: 127, train loss: 0.45264, val loss: 0.77437\n",
      "Interaction training epoch: 128, train loss: 0.45030, val loss: 0.77464\n",
      "Interaction training epoch: 129, train loss: 0.44808, val loss: 0.77509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 130, train loss: 0.44590, val loss: 0.77519\n",
      "Interaction training epoch: 131, train loss: 0.44378, val loss: 0.77576\n",
      "Interaction training epoch: 132, train loss: 0.44170, val loss: 0.77634\n",
      "Interaction training epoch: 133, train loss: 0.43964, val loss: 0.77698\n",
      "Interaction training epoch: 134, train loss: 0.43741, val loss: 0.77760\n",
      "Interaction training epoch: 135, train loss: 0.43540, val loss: 0.77811\n",
      "Interaction training epoch: 136, train loss: 0.43372, val loss: 0.77893\n",
      "Interaction training epoch: 137, train loss: 0.43156, val loss: 0.77879\n",
      "Interaction training epoch: 138, train loss: 0.42896, val loss: 0.77752\n",
      "Interaction training epoch: 139, train loss: 0.42577, val loss: 0.77491\n",
      "Interaction training epoch: 140, train loss: 0.42280, val loss: 0.77232\n",
      "Interaction training epoch: 141, train loss: 0.42054, val loss: 0.77038\n",
      "Interaction training epoch: 142, train loss: 0.41868, val loss: 0.76902\n",
      "Interaction training epoch: 143, train loss: 0.41708, val loss: 0.76813\n",
      "Interaction training epoch: 144, train loss: 0.41525, val loss: 0.76761\n",
      "Interaction training epoch: 145, train loss: 0.41338, val loss: 0.76758\n",
      "Interaction training epoch: 146, train loss: 0.41091, val loss: 0.76732\n",
      "Interaction training epoch: 147, train loss: 0.40858, val loss: 0.76741\n",
      "Interaction training epoch: 148, train loss: 0.40591, val loss: 0.76764\n",
      "Interaction training epoch: 149, train loss: 0.40357, val loss: 0.76820\n",
      "Interaction training epoch: 150, train loss: 0.40155, val loss: 0.76892\n",
      "Interaction training epoch: 151, train loss: 0.39968, val loss: 0.76912\n",
      "Interaction training epoch: 152, train loss: 0.39792, val loss: 0.76889\n",
      "Interaction training epoch: 153, train loss: 0.39615, val loss: 0.76851\n",
      "Interaction training epoch: 154, train loss: 0.39452, val loss: 0.76833\n",
      "Interaction training epoch: 155, train loss: 0.39328, val loss: 0.76877\n",
      "Interaction training epoch: 156, train loss: 0.39176, val loss: 0.76920\n",
      "Interaction training epoch: 157, train loss: 0.38990, val loss: 0.76865\n",
      "Interaction training epoch: 158, train loss: 0.38759, val loss: 0.76733\n",
      "Interaction training epoch: 159, train loss: 0.38472, val loss: 0.76505\n",
      "Interaction training epoch: 160, train loss: 0.38200, val loss: 0.76348\n",
      "Interaction training epoch: 161, train loss: 0.37955, val loss: 0.76207\n",
      "Interaction training epoch: 162, train loss: 0.37717, val loss: 0.76024\n",
      "Interaction training epoch: 163, train loss: 0.37479, val loss: 0.75813\n",
      "Interaction training epoch: 164, train loss: 0.37254, val loss: 0.75626\n",
      "Interaction training epoch: 165, train loss: 0.37034, val loss: 0.75458\n",
      "Interaction training epoch: 166, train loss: 0.36816, val loss: 0.75253\n",
      "Interaction training epoch: 167, train loss: 0.36605, val loss: 0.75080\n",
      "Interaction training epoch: 168, train loss: 0.36404, val loss: 0.74900\n",
      "Interaction training epoch: 169, train loss: 0.36181, val loss: 0.74753\n",
      "Interaction training epoch: 170, train loss: 0.35958, val loss: 0.74589\n",
      "Interaction training epoch: 171, train loss: 0.35731, val loss: 0.74426\n",
      "Interaction training epoch: 172, train loss: 0.35509, val loss: 0.74272\n",
      "Interaction training epoch: 173, train loss: 0.35299, val loss: 0.74080\n",
      "Interaction training epoch: 174, train loss: 0.35091, val loss: 0.73914\n",
      "Interaction training epoch: 175, train loss: 0.34877, val loss: 0.73763\n",
      "Interaction training epoch: 176, train loss: 0.34657, val loss: 0.73646\n",
      "Interaction training epoch: 177, train loss: 0.34437, val loss: 0.73576\n",
      "Interaction training epoch: 178, train loss: 0.34232, val loss: 0.73422\n",
      "Interaction training epoch: 179, train loss: 0.34032, val loss: 0.73260\n",
      "Interaction training epoch: 180, train loss: 0.33832, val loss: 0.73114\n",
      "Interaction training epoch: 181, train loss: 0.33626, val loss: 0.72993\n",
      "Interaction training epoch: 182, train loss: 0.33424, val loss: 0.72917\n",
      "Interaction training epoch: 183, train loss: 0.33206, val loss: 0.72924\n",
      "Interaction training epoch: 184, train loss: 0.32995, val loss: 0.72926\n",
      "Interaction training epoch: 185, train loss: 0.32784, val loss: 0.72980\n",
      "Interaction training epoch: 186, train loss: 0.32575, val loss: 0.73043\n",
      "Interaction training epoch: 187, train loss: 0.32384, val loss: 0.73077\n",
      "Interaction training epoch: 188, train loss: 0.32180, val loss: 0.73193\n",
      "Interaction training epoch: 189, train loss: 0.31965, val loss: 0.73353\n",
      "Interaction training epoch: 190, train loss: 0.31764, val loss: 0.73483\n",
      "Interaction training epoch: 191, train loss: 0.31569, val loss: 0.73616\n",
      "Interaction training epoch: 192, train loss: 0.31367, val loss: 0.73763\n",
      "Interaction training epoch: 193, train loss: 0.31188, val loss: 0.73898\n",
      "Interaction training epoch: 194, train loss: 0.31017, val loss: 0.74015\n",
      "Interaction training epoch: 195, train loss: 0.30868, val loss: 0.74163\n",
      "Interaction training epoch: 196, train loss: 0.30717, val loss: 0.74269\n",
      "Interaction training epoch: 197, train loss: 0.30556, val loss: 0.74368\n",
      "Interaction training epoch: 198, train loss: 0.30399, val loss: 0.74416\n",
      "Interaction training epoch: 199, train loss: 0.30245, val loss: 0.74469\n",
      "Interaction training epoch: 200, train loss: 0.30074, val loss: 0.74485\n",
      "Interaction training epoch: 201, train loss: 0.29878, val loss: 0.74476\n",
      "Interaction training epoch: 202, train loss: 0.29669, val loss: 0.74430\n",
      "Interaction training epoch: 203, train loss: 0.29471, val loss: 0.74422\n",
      "Interaction training epoch: 204, train loss: 0.29281, val loss: 0.74415\n",
      "Interaction training epoch: 205, train loss: 0.29118, val loss: 0.74346\n",
      "Interaction training epoch: 206, train loss: 0.29006, val loss: 0.74260\n",
      "Interaction training epoch: 207, train loss: 0.28908, val loss: 0.74159\n",
      "Interaction training epoch: 208, train loss: 0.28787, val loss: 0.74058\n",
      "Interaction training epoch: 209, train loss: 0.28634, val loss: 0.73836\n",
      "Interaction training epoch: 210, train loss: 0.28496, val loss: 0.73632\n",
      "Interaction training epoch: 211, train loss: 0.28309, val loss: 0.73423\n",
      "Interaction training epoch: 212, train loss: 0.28128, val loss: 0.73208\n",
      "Interaction training epoch: 213, train loss: 0.27994, val loss: 0.73029\n",
      "Interaction training epoch: 214, train loss: 0.27843, val loss: 0.72822\n",
      "Interaction training epoch: 215, train loss: 0.27663, val loss: 0.72637\n",
      "Interaction training epoch: 216, train loss: 0.27484, val loss: 0.72531\n",
      "Interaction training epoch: 217, train loss: 0.27316, val loss: 0.72431\n",
      "Interaction training epoch: 218, train loss: 0.27161, val loss: 0.72327\n",
      "Interaction training epoch: 219, train loss: 0.27011, val loss: 0.72216\n",
      "Interaction training epoch: 220, train loss: 0.26873, val loss: 0.72137\n",
      "Interaction training epoch: 221, train loss: 0.26736, val loss: 0.72076\n",
      "Interaction training epoch: 222, train loss: 0.26585, val loss: 0.72029\n",
      "Interaction training epoch: 223, train loss: 0.26435, val loss: 0.71959\n",
      "Interaction training epoch: 224, train loss: 0.26298, val loss: 0.71868\n",
      "Interaction training epoch: 225, train loss: 0.26156, val loss: 0.71776\n",
      "Interaction training epoch: 226, train loss: 0.26010, val loss: 0.71719\n",
      "Interaction training epoch: 227, train loss: 0.25864, val loss: 0.71707\n",
      "Interaction training epoch: 228, train loss: 0.25721, val loss: 0.71695\n",
      "Interaction training epoch: 229, train loss: 0.25576, val loss: 0.71602\n",
      "Interaction training epoch: 230, train loss: 0.25435, val loss: 0.71548\n",
      "Interaction training epoch: 231, train loss: 0.25302, val loss: 0.71535\n",
      "Interaction training epoch: 232, train loss: 0.25200, val loss: 0.71583\n",
      "Interaction training epoch: 233, train loss: 0.25078, val loss: 0.71656\n",
      "Interaction training epoch: 234, train loss: 0.24911, val loss: 0.71646\n",
      "Interaction training epoch: 235, train loss: 0.24741, val loss: 0.71574\n",
      "Interaction training epoch: 236, train loss: 0.24569, val loss: 0.71491\n",
      "Interaction training epoch: 237, train loss: 0.24471, val loss: 0.71444\n",
      "Interaction training epoch: 238, train loss: 0.24406, val loss: 0.71448\n",
      "Interaction training epoch: 239, train loss: 0.24317, val loss: 0.71424\n",
      "Interaction training epoch: 240, train loss: 0.24208, val loss: 0.71423\n",
      "Interaction training epoch: 241, train loss: 0.24110, val loss: 0.71428\n",
      "Interaction training epoch: 242, train loss: 0.23969, val loss: 0.71407\n",
      "Interaction training epoch: 243, train loss: 0.23811, val loss: 0.71396\n",
      "Interaction training epoch: 244, train loss: 0.23625, val loss: 0.71349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 245, train loss: 0.23460, val loss: 0.71298\n",
      "Interaction training epoch: 246, train loss: 0.23366, val loss: 0.71311\n",
      "Interaction training epoch: 247, train loss: 0.23369, val loss: 0.71468\n",
      "Interaction training epoch: 248, train loss: 0.23436, val loss: 0.71675\n",
      "Interaction training epoch: 249, train loss: 0.23434, val loss: 0.71824\n",
      "Interaction training epoch: 250, train loss: 0.23385, val loss: 0.71843\n",
      "Interaction training epoch: 251, train loss: 0.23348, val loss: 0.71872\n",
      "Interaction training epoch: 252, train loss: 0.23238, val loss: 0.71755\n",
      "Interaction training epoch: 253, train loss: 0.23076, val loss: 0.71542\n",
      "Interaction training epoch: 254, train loss: 0.22865, val loss: 0.71175\n",
      "Interaction training epoch: 255, train loss: 0.22629, val loss: 0.70753\n",
      "Interaction training epoch: 256, train loss: 0.22455, val loss: 0.70395\n",
      "Interaction training epoch: 257, train loss: 0.22315, val loss: 0.70065\n",
      "Interaction training epoch: 258, train loss: 0.22203, val loss: 0.69806\n",
      "Interaction training epoch: 259, train loss: 0.22096, val loss: 0.69539\n",
      "Interaction training epoch: 260, train loss: 0.21977, val loss: 0.69225\n",
      "Interaction training epoch: 261, train loss: 0.21873, val loss: 0.69006\n",
      "Interaction training epoch: 262, train loss: 0.21784, val loss: 0.68761\n",
      "Interaction training epoch: 263, train loss: 0.21705, val loss: 0.68556\n",
      "Interaction training epoch: 264, train loss: 0.21654, val loss: 0.68444\n",
      "Interaction training epoch: 265, train loss: 0.21613, val loss: 0.68325\n",
      "Interaction training epoch: 266, train loss: 0.21558, val loss: 0.68273\n",
      "Interaction training epoch: 267, train loss: 0.21488, val loss: 0.68305\n",
      "Interaction training epoch: 268, train loss: 0.21412, val loss: 0.68301\n",
      "Interaction training epoch: 269, train loss: 0.21276, val loss: 0.68317\n",
      "Interaction training epoch: 270, train loss: 0.21078, val loss: 0.68356\n",
      "Interaction training epoch: 271, train loss: 0.20871, val loss: 0.68422\n",
      "Interaction training epoch: 272, train loss: 0.20742, val loss: 0.68471\n",
      "Interaction training epoch: 273, train loss: 0.20634, val loss: 0.68602\n",
      "Interaction training epoch: 274, train loss: 0.20540, val loss: 0.68692\n",
      "Interaction training epoch: 275, train loss: 0.20462, val loss: 0.68835\n",
      "Interaction training epoch: 276, train loss: 0.20391, val loss: 0.68968\n",
      "Interaction training epoch: 277, train loss: 0.20281, val loss: 0.69004\n",
      "Interaction training epoch: 278, train loss: 0.20175, val loss: 0.69064\n",
      "Interaction training epoch: 279, train loss: 0.20115, val loss: 0.69167\n",
      "Interaction training epoch: 280, train loss: 0.20051, val loss: 0.69220\n",
      "Interaction training epoch: 281, train loss: 0.20014, val loss: 0.69318\n",
      "Interaction training epoch: 282, train loss: 0.19962, val loss: 0.69468\n",
      "Interaction training epoch: 283, train loss: 0.19853, val loss: 0.69478\n",
      "Interaction training epoch: 284, train loss: 0.19779, val loss: 0.69542\n",
      "Interaction training epoch: 285, train loss: 0.19688, val loss: 0.69618\n",
      "Interaction training epoch: 286, train loss: 0.19579, val loss: 0.69618\n",
      "Interaction training epoch: 287, train loss: 0.19431, val loss: 0.69504\n",
      "Interaction training epoch: 288, train loss: 0.19318, val loss: 0.69439\n",
      "Interaction training epoch: 289, train loss: 0.19215, val loss: 0.69427\n",
      "Interaction training epoch: 290, train loss: 0.19133, val loss: 0.69406\n",
      "Interaction training epoch: 291, train loss: 0.19069, val loss: 0.69390\n",
      "Interaction training epoch: 292, train loss: 0.19022, val loss: 0.69340\n",
      "Interaction training epoch: 293, train loss: 0.18937, val loss: 0.69326\n",
      "Interaction training epoch: 294, train loss: 0.18845, val loss: 0.69408\n",
      "Interaction training epoch: 295, train loss: 0.18767, val loss: 0.69507\n",
      "Interaction training epoch: 296, train loss: 0.18692, val loss: 0.69632\n",
      "Interaction training epoch: 297, train loss: 0.18626, val loss: 0.69722\n",
      "Interaction training epoch: 298, train loss: 0.18556, val loss: 0.69835\n",
      "Interaction training epoch: 299, train loss: 0.18488, val loss: 0.69871\n",
      "Interaction training epoch: 300, train loss: 0.18418, val loss: 0.69878\n",
      "Interaction training epoch: 301, train loss: 0.18345, val loss: 0.69837\n",
      "Interaction training epoch: 302, train loss: 0.18272, val loss: 0.69816\n",
      "Interaction training epoch: 303, train loss: 0.18204, val loss: 0.69687\n",
      "Interaction training epoch: 304, train loss: 0.18143, val loss: 0.69611\n",
      "Interaction training epoch: 305, train loss: 0.18093, val loss: 0.69493\n",
      "Interaction training epoch: 306, train loss: 0.18049, val loss: 0.69381\n",
      "Interaction training epoch: 307, train loss: 0.17978, val loss: 0.69284\n",
      "Interaction training epoch: 308, train loss: 0.17906, val loss: 0.69220\n",
      "Interaction training epoch: 309, train loss: 0.17834, val loss: 0.69218\n",
      "Interaction training epoch: 310, train loss: 0.17768, val loss: 0.69243\n",
      "Interaction training epoch: 311, train loss: 0.17706, val loss: 0.69227\n",
      "Interaction training epoch: 312, train loss: 0.17647, val loss: 0.69175\n",
      "Interaction training epoch: 313, train loss: 0.17597, val loss: 0.69080\n",
      "Interaction training epoch: 314, train loss: 0.17553, val loss: 0.69034\n",
      "Interaction training epoch: 315, train loss: 0.17519, val loss: 0.68937\n",
      "Interaction training epoch: 316, train loss: 0.17469, val loss: 0.68856\n",
      "Interaction training epoch: 317, train loss: 0.17405, val loss: 0.68782\n",
      "Early stop at epoch 317, with validation loss: 0.68782\n",
      "##########Stage 2: interaction training stop.##########\n",
      "Fine tuning epoch: 1, train loss: 0.38401, val loss: 0.61223\n",
      "Fine tuning epoch: 2, train loss: 0.38286, val loss: 0.61382\n",
      "Fine tuning epoch: 3, train loss: 0.38139, val loss: 0.61626\n",
      "Fine tuning epoch: 4, train loss: 0.38001, val loss: 0.61798\n",
      "Fine tuning epoch: 5, train loss: 0.37847, val loss: 0.61994\n",
      "Fine tuning epoch: 6, train loss: 0.37677, val loss: 0.62207\n",
      "Fine tuning epoch: 7, train loss: 0.37505, val loss: 0.62405\n",
      "Fine tuning epoch: 8, train loss: 0.37327, val loss: 0.62649\n",
      "Fine tuning epoch: 9, train loss: 0.37151, val loss: 0.62936\n",
      "Fine tuning epoch: 10, train loss: 0.36995, val loss: 0.63168\n",
      "Fine tuning epoch: 11, train loss: 0.36838, val loss: 0.63361\n",
      "Fine tuning epoch: 12, train loss: 0.36682, val loss: 0.63547\n",
      "Fine tuning epoch: 13, train loss: 0.36520, val loss: 0.63638\n",
      "Fine tuning epoch: 14, train loss: 0.36345, val loss: 0.63703\n",
      "Fine tuning epoch: 15, train loss: 0.36187, val loss: 0.63665\n",
      "Fine tuning epoch: 16, train loss: 0.36078, val loss: 0.63478\n",
      "Fine tuning epoch: 17, train loss: 0.36003, val loss: 0.63371\n",
      "Fine tuning epoch: 18, train loss: 0.35928, val loss: 0.63327\n",
      "Fine tuning epoch: 19, train loss: 0.35822, val loss: 0.63338\n",
      "Fine tuning epoch: 20, train loss: 0.35698, val loss: 0.63367\n",
      "Fine tuning epoch: 21, train loss: 0.35532, val loss: 0.63456\n",
      "Fine tuning epoch: 22, train loss: 0.35309, val loss: 0.63663\n",
      "Fine tuning epoch: 23, train loss: 0.35090, val loss: 0.63908\n",
      "Fine tuning epoch: 24, train loss: 0.34897, val loss: 0.64147\n",
      "Fine tuning epoch: 25, train loss: 0.34712, val loss: 0.64459\n",
      "Fine tuning epoch: 26, train loss: 0.34555, val loss: 0.64717\n",
      "Fine tuning epoch: 27, train loss: 0.34408, val loss: 0.64922\n",
      "Fine tuning epoch: 28, train loss: 0.34287, val loss: 0.65193\n",
      "Fine tuning epoch: 29, train loss: 0.34214, val loss: 0.65495\n",
      "Fine tuning epoch: 30, train loss: 0.34125, val loss: 0.65697\n",
      "Fine tuning epoch: 31, train loss: 0.34032, val loss: 0.65873\n",
      "Fine tuning epoch: 32, train loss: 0.33934, val loss: 0.65988\n",
      "Fine tuning epoch: 33, train loss: 0.33816, val loss: 0.66063\n",
      "Fine tuning epoch: 34, train loss: 0.33687, val loss: 0.66061\n",
      "Fine tuning epoch: 35, train loss: 0.33538, val loss: 0.65960\n",
      "Fine tuning epoch: 36, train loss: 0.33406, val loss: 0.65932\n",
      "Fine tuning epoch: 37, train loss: 0.33279, val loss: 0.65857\n",
      "Fine tuning epoch: 38, train loss: 0.33165, val loss: 0.65861\n",
      "Fine tuning epoch: 39, train loss: 0.33067, val loss: 0.65888\n",
      "Fine tuning epoch: 40, train loss: 0.32973, val loss: 0.65935\n",
      "Fine tuning epoch: 41, train loss: 0.32880, val loss: 0.65992\n",
      "Fine tuning epoch: 42, train loss: 0.32799, val loss: 0.66038\n",
      "Fine tuning epoch: 43, train loss: 0.32686, val loss: 0.65992\n",
      "Fine tuning epoch: 44, train loss: 0.32584, val loss: 0.66020\n",
      "Fine tuning epoch: 45, train loss: 0.32497, val loss: 0.66080\n",
      "Fine tuning epoch: 46, train loss: 0.32411, val loss: 0.66188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning epoch: 47, train loss: 0.32288, val loss: 0.66098\n",
      "Fine tuning epoch: 48, train loss: 0.32193, val loss: 0.66105\n",
      "Fine tuning epoch: 49, train loss: 0.32116, val loss: 0.66214\n",
      "Fine tuning epoch: 50, train loss: 0.32061, val loss: 0.66379\n",
      "Fine tuning epoch: 51, train loss: 0.31982, val loss: 0.66511\n",
      "Fine tuning epoch: 52, train loss: 0.31888, val loss: 0.66545\n",
      "Early stop at epoch 52, with validation loss: 0.66545\n",
      "####################GAMI-Net training finished.####################\n",
      "Train: MSE: 0.31887834802677484\n",
      "Val: MSE: 0.6654451849045807\n",
      "[6 1 8 2]\n",
      "[[1 2]\n",
      " [0 2]]\n",
      "\u001b[32m[I 2024-02-10 11:19:53,351]\u001b[0m Trial 0 finished with value: 0.6654451849045807 and parameters: {'num_of_interactions': 15}. Best is trial 0 with value: 0.6654451849045807.\u001b[0m\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "[50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      " 98 99]\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 4.56981, val loss: 4.54377\n",
      "Main effects training epoch: 2, train loss: 4.55566, val loss: 4.53397\n",
      "Main effects training epoch: 3, train loss: 4.54061, val loss: 4.51887\n",
      "Main effects training epoch: 4, train loss: 4.52561, val loss: 4.50384\n",
      "Main effects training epoch: 5, train loss: 4.51097, val loss: 4.49021\n",
      "Main effects training epoch: 6, train loss: 4.49629, val loss: 4.47544\n",
      "Main effects training epoch: 7, train loss: 4.48179, val loss: 4.46080\n",
      "Main effects training epoch: 8, train loss: 4.46735, val loss: 4.44626\n",
      "Main effects training epoch: 9, train loss: 4.45307, val loss: 4.43191\n",
      "Main effects training epoch: 10, train loss: 4.43890, val loss: 4.41769\n",
      "Main effects training epoch: 11, train loss: 4.42487, val loss: 4.40358\n",
      "Main effects training epoch: 12, train loss: 4.41098, val loss: 4.38959\n",
      "Main effects training epoch: 13, train loss: 4.39722, val loss: 4.37570\n",
      "Main effects training epoch: 14, train loss: 4.38346, val loss: 4.36184\n",
      "Main effects training epoch: 15, train loss: 4.36977, val loss: 4.34801\n",
      "Main effects training epoch: 16, train loss: 4.35617, val loss: 4.33424\n",
      "Main effects training epoch: 17, train loss: 4.34266, val loss: 4.32054\n",
      "Main effects training epoch: 18, train loss: 4.32919, val loss: 4.30688\n",
      "Main effects training epoch: 19, train loss: 4.31579, val loss: 4.29327\n",
      "Main effects training epoch: 20, train loss: 4.30241, val loss: 4.27980\n",
      "Main effects training epoch: 21, train loss: 4.28899, val loss: 4.26637\n",
      "Main effects training epoch: 22, train loss: 4.27556, val loss: 4.25292\n",
      "Main effects training epoch: 23, train loss: 4.26217, val loss: 4.23954\n",
      "Main effects training epoch: 24, train loss: 4.24882, val loss: 4.22622\n",
      "Main effects training epoch: 25, train loss: 4.23552, val loss: 4.21296\n",
      "Main effects training epoch: 26, train loss: 4.22234, val loss: 4.19986\n",
      "Main effects training epoch: 27, train loss: 4.20926, val loss: 4.18684\n",
      "Main effects training epoch: 28, train loss: 4.19630, val loss: 4.17392\n",
      "Main effects training epoch: 29, train loss: 4.18345, val loss: 4.16111\n",
      "Main effects training epoch: 30, train loss: 4.17072, val loss: 4.14837\n",
      "Main effects training epoch: 31, train loss: 4.15815, val loss: 4.13584\n",
      "Main effects training epoch: 32, train loss: 4.14572, val loss: 4.12345\n",
      "Main effects training epoch: 33, train loss: 4.13338, val loss: 4.11119\n",
      "Main effects training epoch: 34, train loss: 4.12117, val loss: 4.09903\n",
      "Main effects training epoch: 35, train loss: 4.10893, val loss: 4.08688\n",
      "Main effects training epoch: 36, train loss: 4.09668, val loss: 4.07474\n",
      "Main effects training epoch: 37, train loss: 4.08447, val loss: 4.06267\n",
      "Main effects training epoch: 38, train loss: 4.07227, val loss: 4.05069\n",
      "Main effects training epoch: 39, train loss: 4.06001, val loss: 4.03869\n",
      "Main effects training epoch: 40, train loss: 4.04774, val loss: 4.02673\n",
      "Main effects training epoch: 41, train loss: 4.03542, val loss: 4.01475\n",
      "Main effects training epoch: 42, train loss: 4.02308, val loss: 4.00273\n",
      "Main effects training epoch: 43, train loss: 4.01068, val loss: 3.99065\n",
      "Main effects training epoch: 44, train loss: 3.99823, val loss: 3.97851\n",
      "Main effects training epoch: 45, train loss: 3.98571, val loss: 3.96631\n",
      "Main effects training epoch: 46, train loss: 3.97307, val loss: 3.95399\n",
      "Main effects training epoch: 47, train loss: 3.96031, val loss: 3.94156\n",
      "Main effects training epoch: 48, train loss: 3.94749, val loss: 3.92908\n",
      "Main effects training epoch: 49, train loss: 3.93460, val loss: 3.91655\n",
      "Main effects training epoch: 50, train loss: 3.92157, val loss: 3.90389\n",
      "Main effects training epoch: 51, train loss: 3.90827, val loss: 3.89096\n",
      "Main effects training epoch: 52, train loss: 3.89483, val loss: 3.87788\n",
      "Main effects training epoch: 53, train loss: 3.88130, val loss: 3.86474\n",
      "Main effects training epoch: 54, train loss: 3.86771, val loss: 3.85154\n",
      "Main effects training epoch: 55, train loss: 3.85399, val loss: 3.83822\n",
      "Main effects training epoch: 56, train loss: 3.84021, val loss: 3.82484\n",
      "Main effects training epoch: 57, train loss: 3.82628, val loss: 3.81131\n",
      "Main effects training epoch: 58, train loss: 3.81216, val loss: 3.79757\n",
      "Main effects training epoch: 59, train loss: 3.79792, val loss: 3.78372\n",
      "Main effects training epoch: 60, train loss: 3.78362, val loss: 3.76983\n",
      "Main effects training epoch: 61, train loss: 3.76920, val loss: 3.75582\n",
      "Main effects training epoch: 62, train loss: 3.75457, val loss: 3.74164\n",
      "Main effects training epoch: 63, train loss: 3.73978, val loss: 3.72732\n",
      "Main effects training epoch: 64, train loss: 3.72488, val loss: 3.71291\n",
      "Main effects training epoch: 65, train loss: 3.70978, val loss: 3.69830\n",
      "Main effects training epoch: 66, train loss: 3.69463, val loss: 3.68366\n",
      "Main effects training epoch: 67, train loss: 3.67947, val loss: 3.66904\n",
      "Main effects training epoch: 68, train loss: 3.66422, val loss: 3.65432\n",
      "Main effects training epoch: 69, train loss: 3.64888, val loss: 3.63952\n",
      "Main effects training epoch: 70, train loss: 3.63337, val loss: 3.62453\n",
      "Main effects training epoch: 71, train loss: 3.61769, val loss: 3.60935\n",
      "Main effects training epoch: 72, train loss: 3.60199, val loss: 3.59411\n",
      "Main effects training epoch: 73, train loss: 3.58611, val loss: 3.57869\n",
      "Main effects training epoch: 74, train loss: 3.57004, val loss: 3.56313\n",
      "Main effects training epoch: 75, train loss: 3.55388, val loss: 3.54747\n",
      "Main effects training epoch: 76, train loss: 3.53750, val loss: 3.53162\n",
      "Main effects training epoch: 77, train loss: 3.52089, val loss: 3.51556\n",
      "Main effects training epoch: 78, train loss: 3.50418, val loss: 3.49940\n",
      "Main effects training epoch: 79, train loss: 3.48731, val loss: 3.48308\n",
      "Main effects training epoch: 80, train loss: 3.47026, val loss: 3.46659\n",
      "Main effects training epoch: 81, train loss: 3.45307, val loss: 3.44997\n",
      "Main effects training epoch: 82, train loss: 3.43580, val loss: 3.43329\n",
      "Main effects training epoch: 83, train loss: 3.41848, val loss: 3.41655\n",
      "Main effects training epoch: 84, train loss: 3.40105, val loss: 3.39970\n",
      "Main effects training epoch: 85, train loss: 3.38334, val loss: 3.38255\n",
      "Main effects training epoch: 86, train loss: 3.36540, val loss: 3.36518\n",
      "Main effects training epoch: 87, train loss: 3.34724, val loss: 3.34761\n",
      "Main effects training epoch: 88, train loss: 3.32889, val loss: 3.32987\n",
      "Main effects training epoch: 89, train loss: 3.31042, val loss: 3.31196\n",
      "Main effects training epoch: 90, train loss: 3.29165, val loss: 3.29377\n",
      "Main effects training epoch: 91, train loss: 3.27261, val loss: 3.27534\n",
      "Main effects training epoch: 92, train loss: 3.25355, val loss: 3.25690\n",
      "Main effects training epoch: 93, train loss: 3.23427, val loss: 3.23827\n",
      "Main effects training epoch: 94, train loss: 3.21493, val loss: 3.21959\n",
      "Main effects training epoch: 95, train loss: 3.19557, val loss: 3.20090\n",
      "Main effects training epoch: 96, train loss: 3.17608, val loss: 3.18209\n",
      "Main effects training epoch: 97, train loss: 3.15655, val loss: 3.16325\n",
      "Main effects training epoch: 98, train loss: 3.13677, val loss: 3.14419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 99, train loss: 3.11701, val loss: 3.12514\n",
      "Main effects training epoch: 100, train loss: 3.09705, val loss: 3.10591\n",
      "Main effects training epoch: 101, train loss: 3.07701, val loss: 3.08660\n",
      "Main effects training epoch: 102, train loss: 3.05691, val loss: 3.06725\n",
      "Main effects training epoch: 103, train loss: 3.03662, val loss: 3.04772\n",
      "Main effects training epoch: 104, train loss: 3.01621, val loss: 3.02808\n",
      "Main effects training epoch: 105, train loss: 2.99571, val loss: 3.00838\n",
      "Main effects training epoch: 106, train loss: 2.97509, val loss: 2.98859\n",
      "Main effects training epoch: 107, train loss: 2.95430, val loss: 2.96868\n",
      "Main effects training epoch: 108, train loss: 2.93318, val loss: 2.94844\n",
      "Main effects training epoch: 109, train loss: 2.91194, val loss: 2.92813\n",
      "Main effects training epoch: 110, train loss: 2.89048, val loss: 2.90764\n",
      "Main effects training epoch: 111, train loss: 2.86882, val loss: 2.88701\n",
      "Main effects training epoch: 112, train loss: 2.84697, val loss: 2.86623\n",
      "Main effects training epoch: 113, train loss: 2.82495, val loss: 2.84528\n",
      "Main effects training epoch: 114, train loss: 2.80285, val loss: 2.82428\n",
      "Main effects training epoch: 115, train loss: 2.78074, val loss: 2.80327\n",
      "Main effects training epoch: 116, train loss: 2.75827, val loss: 2.78192\n",
      "Main effects training epoch: 117, train loss: 2.73581, val loss: 2.76060\n",
      "Main effects training epoch: 118, train loss: 2.71319, val loss: 2.73913\n",
      "Main effects training epoch: 119, train loss: 2.69059, val loss: 2.71765\n",
      "Main effects training epoch: 120, train loss: 2.66780, val loss: 2.69603\n",
      "Main effects training epoch: 121, train loss: 2.64486, val loss: 2.67426\n",
      "Main effects training epoch: 122, train loss: 2.62176, val loss: 2.65234\n",
      "Main effects training epoch: 123, train loss: 2.59843, val loss: 2.63021\n",
      "Main effects training epoch: 124, train loss: 2.57491, val loss: 2.60792\n",
      "Main effects training epoch: 125, train loss: 2.55138, val loss: 2.58561\n",
      "Main effects training epoch: 126, train loss: 2.52768, val loss: 2.56316\n",
      "Main effects training epoch: 127, train loss: 2.50378, val loss: 2.54053\n",
      "Main effects training epoch: 128, train loss: 2.47961, val loss: 2.51766\n",
      "Main effects training epoch: 129, train loss: 2.45532, val loss: 2.49471\n",
      "Main effects training epoch: 130, train loss: 2.43104, val loss: 2.47180\n",
      "Main effects training epoch: 131, train loss: 2.40661, val loss: 2.44876\n",
      "Main effects training epoch: 132, train loss: 2.38223, val loss: 2.42576\n",
      "Main effects training epoch: 133, train loss: 2.35756, val loss: 2.40251\n",
      "Main effects training epoch: 134, train loss: 2.33304, val loss: 2.37943\n",
      "Main effects training epoch: 135, train loss: 2.30871, val loss: 2.35653\n",
      "Main effects training epoch: 136, train loss: 2.28444, val loss: 2.33368\n",
      "Main effects training epoch: 137, train loss: 2.25992, val loss: 2.31062\n",
      "Main effects training epoch: 138, train loss: 2.23553, val loss: 2.28769\n",
      "Main effects training epoch: 139, train loss: 2.21088, val loss: 2.26455\n",
      "Main effects training epoch: 140, train loss: 2.18623, val loss: 2.24141\n",
      "Main effects training epoch: 141, train loss: 2.16143, val loss: 2.21816\n",
      "Main effects training epoch: 142, train loss: 2.13653, val loss: 2.19479\n",
      "Main effects training epoch: 143, train loss: 2.11119, val loss: 2.17103\n",
      "Main effects training epoch: 144, train loss: 2.08595, val loss: 2.14739\n",
      "Main effects training epoch: 145, train loss: 2.06060, val loss: 2.12369\n",
      "Main effects training epoch: 146, train loss: 2.03511, val loss: 2.09988\n",
      "Main effects training epoch: 147, train loss: 2.00963, val loss: 2.07609\n",
      "Main effects training epoch: 148, train loss: 1.98388, val loss: 2.05208\n",
      "Main effects training epoch: 149, train loss: 1.95807, val loss: 2.02804\n",
      "Main effects training epoch: 150, train loss: 1.93238, val loss: 2.00414\n",
      "Main effects training epoch: 151, train loss: 1.90675, val loss: 1.98031\n",
      "Main effects training epoch: 152, train loss: 1.88134, val loss: 1.95670\n",
      "Main effects training epoch: 153, train loss: 1.85620, val loss: 1.93337\n",
      "Main effects training epoch: 154, train loss: 1.83090, val loss: 1.90993\n",
      "Main effects training epoch: 155, train loss: 1.80528, val loss: 1.88620\n",
      "Main effects training epoch: 156, train loss: 1.77994, val loss: 1.86276\n",
      "Main effects training epoch: 157, train loss: 1.75477, val loss: 1.83952\n",
      "Main effects training epoch: 158, train loss: 1.72985, val loss: 1.81655\n",
      "Main effects training epoch: 159, train loss: 1.70498, val loss: 1.79367\n",
      "Main effects training epoch: 160, train loss: 1.68028, val loss: 1.77097\n",
      "Main effects training epoch: 161, train loss: 1.65562, val loss: 1.74833\n",
      "Main effects training epoch: 162, train loss: 1.63098, val loss: 1.72576\n",
      "Main effects training epoch: 163, train loss: 1.60640, val loss: 1.70329\n",
      "Main effects training epoch: 164, train loss: 1.58244, val loss: 1.68141\n",
      "Main effects training epoch: 165, train loss: 1.55861, val loss: 1.65969\n",
      "Main effects training epoch: 166, train loss: 1.53513, val loss: 1.63835\n",
      "Main effects training epoch: 167, train loss: 1.51172, val loss: 1.61710\n",
      "Main effects training epoch: 168, train loss: 1.48849, val loss: 1.59603\n",
      "Main effects training epoch: 169, train loss: 1.46528, val loss: 1.57502\n",
      "Main effects training epoch: 170, train loss: 1.44200, val loss: 1.55400\n",
      "Main effects training epoch: 171, train loss: 1.41889, val loss: 1.53319\n",
      "Main effects training epoch: 172, train loss: 1.39597, val loss: 1.51260\n",
      "Main effects training epoch: 173, train loss: 1.37333, val loss: 1.49232\n",
      "Main effects training epoch: 174, train loss: 1.35140, val loss: 1.47272\n",
      "Main effects training epoch: 175, train loss: 1.32976, val loss: 1.45343\n",
      "Main effects training epoch: 176, train loss: 1.30868, val loss: 1.43467\n",
      "Main effects training epoch: 177, train loss: 1.28761, val loss: 1.41597\n",
      "Main effects training epoch: 178, train loss: 1.26683, val loss: 1.39758\n",
      "Main effects training epoch: 179, train loss: 1.24664, val loss: 1.37977\n",
      "Main effects training epoch: 180, train loss: 1.22645, val loss: 1.36200\n",
      "Main effects training epoch: 181, train loss: 1.20620, val loss: 1.34422\n",
      "Main effects training epoch: 182, train loss: 1.18623, val loss: 1.32672\n",
      "Main effects training epoch: 183, train loss: 1.16663, val loss: 1.30963\n",
      "Main effects training epoch: 184, train loss: 1.14737, val loss: 1.29289\n",
      "Main effects training epoch: 185, train loss: 1.12854, val loss: 1.27659\n",
      "Main effects training epoch: 186, train loss: 1.11012, val loss: 1.26070\n",
      "Main effects training epoch: 187, train loss: 1.09202, val loss: 1.24515\n",
      "Main effects training epoch: 188, train loss: 1.07458, val loss: 1.23026\n",
      "Main effects training epoch: 189, train loss: 1.05770, val loss: 1.21591\n",
      "Main effects training epoch: 190, train loss: 1.04097, val loss: 1.20176\n",
      "Main effects training epoch: 191, train loss: 1.02440, val loss: 1.18782\n",
      "Main effects training epoch: 192, train loss: 1.00845, val loss: 1.17447\n",
      "Main effects training epoch: 193, train loss: 0.99291, val loss: 1.16156\n",
      "Main effects training epoch: 194, train loss: 0.97732, val loss: 1.14867\n",
      "Main effects training epoch: 195, train loss: 0.96189, val loss: 1.13598\n",
      "Main effects training epoch: 196, train loss: 0.94668, val loss: 1.12358\n",
      "Main effects training epoch: 197, train loss: 0.93193, val loss: 1.11165\n",
      "Main effects training epoch: 198, train loss: 0.91777, val loss: 1.10029\n",
      "Main effects training epoch: 199, train loss: 0.90439, val loss: 1.08963\n",
      "Main effects training epoch: 200, train loss: 0.89147, val loss: 1.07943\n",
      "Main effects training epoch: 201, train loss: 0.87903, val loss: 1.06970\n",
      "Main effects training epoch: 202, train loss: 0.86693, val loss: 1.06032\n",
      "Main effects training epoch: 203, train loss: 0.85558, val loss: 1.05162\n",
      "Main effects training epoch: 204, train loss: 0.84473, val loss: 1.04340\n",
      "Main effects training epoch: 205, train loss: 0.83473, val loss: 1.03593\n",
      "Main effects training epoch: 206, train loss: 0.82528, val loss: 1.02896\n",
      "Main effects training epoch: 207, train loss: 0.81631, val loss: 1.02244\n",
      "Main effects training epoch: 208, train loss: 0.80770, val loss: 1.01628\n",
      "Main effects training epoch: 209, train loss: 0.79942, val loss: 1.01047\n",
      "Main effects training epoch: 210, train loss: 0.79146, val loss: 1.00498\n",
      "Main effects training epoch: 211, train loss: 0.78402, val loss: 0.99996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 212, train loss: 0.77697, val loss: 0.99529\n",
      "Main effects training epoch: 213, train loss: 0.77050, val loss: 0.99109\n",
      "Main effects training epoch: 214, train loss: 0.76431, val loss: 0.98719\n",
      "Main effects training epoch: 215, train loss: 0.75875, val loss: 0.98380\n",
      "Main effects training epoch: 216, train loss: 0.75359, val loss: 0.98072\n",
      "Main effects training epoch: 217, train loss: 0.74856, val loss: 0.97782\n",
      "Main effects training epoch: 218, train loss: 0.74378, val loss: 0.97517\n",
      "Main effects training epoch: 219, train loss: 0.73935, val loss: 0.97281\n",
      "Main effects training epoch: 220, train loss: 0.73510, val loss: 0.97067\n",
      "Main effects training epoch: 221, train loss: 0.73127, val loss: 0.96886\n",
      "Main effects training epoch: 222, train loss: 0.72768, val loss: 0.96727\n",
      "Main effects training epoch: 223, train loss: 0.72447, val loss: 0.96595\n",
      "Main effects training epoch: 224, train loss: 0.72144, val loss: 0.96480\n",
      "Main effects training epoch: 225, train loss: 0.71880, val loss: 0.96392\n",
      "Main effects training epoch: 226, train loss: 0.71643, val loss: 0.96320\n",
      "Main effects training epoch: 227, train loss: 0.71425, val loss: 0.96263\n",
      "Main effects training epoch: 228, train loss: 0.71225, val loss: 0.96218\n",
      "Main effects training epoch: 229, train loss: 0.71029, val loss: 0.96184\n",
      "Main effects training epoch: 230, train loss: 0.70850, val loss: 0.96161\n",
      "Main effects training epoch: 231, train loss: 0.70674, val loss: 0.96150\n",
      "Main effects training epoch: 232, train loss: 0.70504, val loss: 0.96151\n",
      "Main effects training epoch: 233, train loss: 0.70346, val loss: 0.96165\n",
      "Main effects training epoch: 234, train loss: 0.70213, val loss: 0.96187\n",
      "Main effects training epoch: 235, train loss: 0.70090, val loss: 0.96216\n",
      "Main effects training epoch: 236, train loss: 0.69976, val loss: 0.96256\n",
      "Main effects training epoch: 237, train loss: 0.69874, val loss: 0.96307\n",
      "Main effects training epoch: 238, train loss: 0.69785, val loss: 0.96362\n",
      "Main effects training epoch: 239, train loss: 0.69705, val loss: 0.96427\n",
      "Main effects training epoch: 240, train loss: 0.69638, val loss: 0.96490\n",
      "Main effects training epoch: 241, train loss: 0.69576, val loss: 0.96564\n",
      "Main effects training epoch: 242, train loss: 0.69522, val loss: 0.96638\n",
      "Main effects training epoch: 243, train loss: 0.69478, val loss: 0.96702\n",
      "Main effects training epoch: 244, train loss: 0.69439, val loss: 0.96777\n",
      "Main effects training epoch: 245, train loss: 0.69405, val loss: 0.96856\n",
      "Main effects training epoch: 246, train loss: 0.69375, val loss: 0.96948\n",
      "Main effects training epoch: 247, train loss: 0.69353, val loss: 0.97045\n",
      "Main effects training epoch: 248, train loss: 0.69337, val loss: 0.97144\n",
      "Main effects training epoch: 249, train loss: 0.69325, val loss: 0.97239\n",
      "Main effects training epoch: 250, train loss: 0.69315, val loss: 0.97322\n",
      "Main effects training epoch: 251, train loss: 0.69310, val loss: 0.97425\n",
      "Main effects training epoch: 252, train loss: 0.69305, val loss: 0.97512\n",
      "Main effects training epoch: 253, train loss: 0.69296, val loss: 0.97573\n",
      "Main effects training epoch: 254, train loss: 0.69288, val loss: 0.97628\n",
      "Main effects training epoch: 255, train loss: 0.69279, val loss: 0.97678\n",
      "Main effects training epoch: 256, train loss: 0.69269, val loss: 0.97724\n",
      "Main effects training epoch: 257, train loss: 0.69261, val loss: 0.97770\n",
      "Main effects training epoch: 258, train loss: 0.69258, val loss: 0.97831\n",
      "Main effects training epoch: 259, train loss: 0.69253, val loss: 0.97882\n",
      "Main effects training epoch: 260, train loss: 0.69256, val loss: 0.97960\n",
      "Main effects training epoch: 261, train loss: 0.69244, val loss: 0.97993\n",
      "Main effects training epoch: 262, train loss: 0.69227, val loss: 0.98012\n",
      "Main effects training epoch: 263, train loss: 0.69201, val loss: 0.98005\n",
      "Main effects training epoch: 264, train loss: 0.69179, val loss: 0.98010\n",
      "Main effects training epoch: 265, train loss: 0.69149, val loss: 0.97995\n",
      "Main effects training epoch: 266, train loss: 0.69119, val loss: 0.97979\n",
      "Main effects training epoch: 267, train loss: 0.69083, val loss: 0.97942\n",
      "Main effects training epoch: 268, train loss: 0.69042, val loss: 0.97890\n",
      "Main effects training epoch: 269, train loss: 0.69010, val loss: 0.97863\n",
      "Main effects training epoch: 270, train loss: 0.68983, val loss: 0.97847\n",
      "Main effects training epoch: 271, train loss: 0.68953, val loss: 0.97821\n",
      "Main effects training epoch: 272, train loss: 0.68930, val loss: 0.97814\n",
      "Main effects training epoch: 273, train loss: 0.68900, val loss: 0.97788\n",
      "Main effects training epoch: 274, train loss: 0.68866, val loss: 0.97745\n",
      "Main effects training epoch: 275, train loss: 0.68824, val loss: 0.97678\n",
      "Main effects training epoch: 276, train loss: 0.68782, val loss: 0.97606\n",
      "Main effects training epoch: 277, train loss: 0.68738, val loss: 0.97525\n",
      "Main effects training epoch: 278, train loss: 0.68696, val loss: 0.97451\n",
      "Main effects training epoch: 279, train loss: 0.68657, val loss: 0.97376\n",
      "Main effects training epoch: 280, train loss: 0.68611, val loss: 0.97279\n",
      "Main effects training epoch: 281, train loss: 0.68568, val loss: 0.97177\n",
      "Main effects training epoch: 282, train loss: 0.68527, val loss: 0.97079\n",
      "Early stop at epoch 282, with validation loss: 0.97079\n",
      "##########Stage 1: main effect training stop.##########\n",
      "##########No main effect is selected, training stop.##########\n",
      "Train: MSE: 0.7141909442517915\n",
      "Val: MSE: 0.8265182931177384\n",
      "[]\n",
      "[]\n",
      "\u001b[32m[I 2024-02-10 11:20:43,521]\u001b[0m Trial 1 finished with value: 0.8265182931177384 and parameters: {'num_of_interactions': 35}. Best is trial 0 with value: 0.6654451849045807.\u001b[0m\n",
      "Number of finished trials: 2\n",
      "Best trial:\n",
      "  Value: 0.6654451849045807\n",
      "  Params: \n",
      "    num_of_interactions: 15\n",
      "Training completed in 00:03:50.31 for 2 trials\n",
      "===================FOLD: 1 ================\n",
      "\u001b[32m[I 2024-02-10 11:20:43,871]\u001b[0m A new study created in memory with name: no-name-63e7d1ae-953a-4b29-ab5c-a4da99e16953\u001b[0m\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "[50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      " 98 99]\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 4.45670, val loss: 4.52789\n",
      "Main effects training epoch: 2, train loss: 4.44124, val loss: 4.51167\n",
      "Main effects training epoch: 3, train loss: 4.42620, val loss: 4.49603\n",
      "Main effects training epoch: 4, train loss: 4.41127, val loss: 4.48068\n",
      "Main effects training epoch: 5, train loss: 4.39658, val loss: 4.46561\n",
      "Main effects training epoch: 6, train loss: 4.38223, val loss: 4.45093\n",
      "Main effects training epoch: 7, train loss: 4.36814, val loss: 4.43649\n",
      "Main effects training epoch: 8, train loss: 4.35429, val loss: 4.42230\n",
      "Main effects training epoch: 9, train loss: 4.34069, val loss: 4.40836\n",
      "Main effects training epoch: 10, train loss: 4.32733, val loss: 4.39461\n",
      "Main effects training epoch: 11, train loss: 4.31416, val loss: 4.38108\n",
      "Main effects training epoch: 12, train loss: 4.30102, val loss: 4.36761\n",
      "Main effects training epoch: 13, train loss: 4.28797, val loss: 4.35422\n",
      "Main effects training epoch: 14, train loss: 4.27505, val loss: 4.34099\n",
      "Main effects training epoch: 15, train loss: 4.26224, val loss: 4.32787\n",
      "Main effects training epoch: 16, train loss: 4.24957, val loss: 4.31489\n",
      "Main effects training epoch: 17, train loss: 4.23690, val loss: 4.30190\n",
      "Main effects training epoch: 18, train loss: 4.22431, val loss: 4.28902\n",
      "Main effects training epoch: 19, train loss: 4.21187, val loss: 4.27626\n",
      "Main effects training epoch: 20, train loss: 4.19947, val loss: 4.26355\n",
      "Main effects training epoch: 21, train loss: 4.18710, val loss: 4.25091\n",
      "Main effects training epoch: 22, train loss: 4.17484, val loss: 4.23837\n",
      "Main effects training epoch: 23, train loss: 4.16260, val loss: 4.22585\n",
      "Main effects training epoch: 24, train loss: 4.15039, val loss: 4.21339\n",
      "Main effects training epoch: 25, train loss: 4.13823, val loss: 4.20096\n",
      "Main effects training epoch: 26, train loss: 4.12615, val loss: 4.18861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 27, train loss: 4.11405, val loss: 4.17624\n",
      "Main effects training epoch: 28, train loss: 4.10200, val loss: 4.16393\n",
      "Main effects training epoch: 29, train loss: 4.08992, val loss: 4.15158\n",
      "Main effects training epoch: 30, train loss: 4.07785, val loss: 4.13927\n",
      "Main effects training epoch: 31, train loss: 4.06572, val loss: 4.12685\n",
      "Main effects training epoch: 32, train loss: 4.05357, val loss: 4.11441\n",
      "Main effects training epoch: 33, train loss: 4.04136, val loss: 4.10190\n",
      "Main effects training epoch: 34, train loss: 4.02913, val loss: 4.08936\n",
      "Main effects training epoch: 35, train loss: 4.01687, val loss: 4.07677\n",
      "Main effects training epoch: 36, train loss: 4.00459, val loss: 4.06418\n",
      "Main effects training epoch: 37, train loss: 3.99220, val loss: 4.05149\n",
      "Main effects training epoch: 38, train loss: 3.97974, val loss: 4.03875\n",
      "Main effects training epoch: 39, train loss: 3.96718, val loss: 4.02592\n",
      "Main effects training epoch: 40, train loss: 3.95464, val loss: 4.01312\n",
      "Main effects training epoch: 41, train loss: 3.94209, val loss: 4.00033\n",
      "Main effects training epoch: 42, train loss: 3.92948, val loss: 3.98750\n",
      "Main effects training epoch: 43, train loss: 3.91670, val loss: 3.97451\n",
      "Main effects training epoch: 44, train loss: 3.90369, val loss: 3.96131\n",
      "Main effects training epoch: 45, train loss: 3.89061, val loss: 3.94807\n",
      "Main effects training epoch: 46, train loss: 3.87745, val loss: 3.93474\n",
      "Main effects training epoch: 47, train loss: 3.86421, val loss: 3.92135\n",
      "Main effects training epoch: 48, train loss: 3.85083, val loss: 3.90780\n",
      "Main effects training epoch: 49, train loss: 3.83744, val loss: 3.89423\n",
      "Main effects training epoch: 50, train loss: 3.82390, val loss: 3.88051\n",
      "Main effects training epoch: 51, train loss: 3.81019, val loss: 3.86660\n",
      "Main effects training epoch: 52, train loss: 3.79621, val loss: 3.85243\n",
      "Main effects training epoch: 53, train loss: 3.78211, val loss: 3.83814\n",
      "Main effects training epoch: 54, train loss: 3.76802, val loss: 3.82386\n",
      "Main effects training epoch: 55, train loss: 3.75395, val loss: 3.80959\n",
      "Main effects training epoch: 56, train loss: 3.73987, val loss: 3.79530\n",
      "Main effects training epoch: 57, train loss: 3.72562, val loss: 3.78081\n",
      "Main effects training epoch: 58, train loss: 3.71126, val loss: 3.76619\n",
      "Main effects training epoch: 59, train loss: 3.69688, val loss: 3.75157\n",
      "Main effects training epoch: 60, train loss: 3.68241, val loss: 3.73682\n",
      "Main effects training epoch: 61, train loss: 3.66786, val loss: 3.72198\n",
      "Main effects training epoch: 62, train loss: 3.65311, val loss: 3.70694\n",
      "Main effects training epoch: 63, train loss: 3.63816, val loss: 3.69169\n",
      "Main effects training epoch: 64, train loss: 3.62298, val loss: 3.67622\n",
      "Main effects training epoch: 65, train loss: 3.60777, val loss: 3.66072\n",
      "Main effects training epoch: 66, train loss: 3.59245, val loss: 3.64511\n",
      "Main effects training epoch: 67, train loss: 3.57702, val loss: 3.62938\n",
      "Main effects training epoch: 68, train loss: 3.56153, val loss: 3.61360\n",
      "Main effects training epoch: 69, train loss: 3.54585, val loss: 3.59762\n",
      "Main effects training epoch: 70, train loss: 3.53007, val loss: 3.58156\n",
      "Main effects training epoch: 71, train loss: 3.51413, val loss: 3.56532\n",
      "Main effects training epoch: 72, train loss: 3.49808, val loss: 3.54893\n",
      "Main effects training epoch: 73, train loss: 3.48203, val loss: 3.53253\n",
      "Main effects training epoch: 74, train loss: 3.46586, val loss: 3.51602\n",
      "Main effects training epoch: 75, train loss: 3.44942, val loss: 3.49925\n",
      "Main effects training epoch: 76, train loss: 3.43278, val loss: 3.48229\n",
      "Main effects training epoch: 77, train loss: 3.41596, val loss: 3.46513\n",
      "Main effects training epoch: 78, train loss: 3.39904, val loss: 3.44786\n",
      "Main effects training epoch: 79, train loss: 3.38208, val loss: 3.43055\n",
      "Main effects training epoch: 80, train loss: 3.36502, val loss: 3.41314\n",
      "Main effects training epoch: 81, train loss: 3.34785, val loss: 3.39564\n",
      "Main effects training epoch: 82, train loss: 3.33049, val loss: 3.37793\n",
      "Main effects training epoch: 83, train loss: 3.31310, val loss: 3.36020\n",
      "Main effects training epoch: 84, train loss: 3.29558, val loss: 3.34230\n",
      "Main effects training epoch: 85, train loss: 3.27794, val loss: 3.32428\n",
      "Main effects training epoch: 86, train loss: 3.26028, val loss: 3.30622\n",
      "Main effects training epoch: 87, train loss: 3.24249, val loss: 3.28802\n",
      "Main effects training epoch: 88, train loss: 3.22447, val loss: 3.26959\n",
      "Main effects training epoch: 89, train loss: 3.20634, val loss: 3.25103\n",
      "Main effects training epoch: 90, train loss: 3.18807, val loss: 3.23232\n",
      "Main effects training epoch: 91, train loss: 3.16962, val loss: 3.21340\n",
      "Main effects training epoch: 92, train loss: 3.15107, val loss: 3.19436\n",
      "Main effects training epoch: 93, train loss: 3.13248, val loss: 3.17527\n",
      "Main effects training epoch: 94, train loss: 3.11371, val loss: 3.15600\n",
      "Main effects training epoch: 95, train loss: 3.09488, val loss: 3.13664\n",
      "Main effects training epoch: 96, train loss: 3.07587, val loss: 3.11710\n",
      "Main effects training epoch: 97, train loss: 3.05663, val loss: 3.09730\n",
      "Main effects training epoch: 98, train loss: 3.03732, val loss: 3.07744\n",
      "Main effects training epoch: 99, train loss: 3.01811, val loss: 3.05766\n",
      "Main effects training epoch: 100, train loss: 2.99857, val loss: 3.03754\n",
      "Main effects training epoch: 101, train loss: 2.97893, val loss: 3.01733\n",
      "Main effects training epoch: 102, train loss: 2.95901, val loss: 2.99685\n",
      "Main effects training epoch: 103, train loss: 2.93881, val loss: 2.97605\n",
      "Main effects training epoch: 104, train loss: 2.91857, val loss: 2.95519\n",
      "Main effects training epoch: 105, train loss: 2.89814, val loss: 2.93413\n",
      "Main effects training epoch: 106, train loss: 2.87752, val loss: 2.91286\n",
      "Main effects training epoch: 107, train loss: 2.85661, val loss: 2.89130\n",
      "Main effects training epoch: 108, train loss: 2.83570, val loss: 2.86971\n",
      "Main effects training epoch: 109, train loss: 2.81477, val loss: 2.84812\n",
      "Main effects training epoch: 110, train loss: 2.79363, val loss: 2.82631\n",
      "Main effects training epoch: 111, train loss: 2.77228, val loss: 2.80427\n",
      "Main effects training epoch: 112, train loss: 2.75094, val loss: 2.78223\n",
      "Main effects training epoch: 113, train loss: 2.72937, val loss: 2.75993\n",
      "Main effects training epoch: 114, train loss: 2.70774, val loss: 2.73756\n",
      "Main effects training epoch: 115, train loss: 2.68583, val loss: 2.71490\n",
      "Main effects training epoch: 116, train loss: 2.66399, val loss: 2.69229\n",
      "Main effects training epoch: 117, train loss: 2.64222, val loss: 2.66975\n",
      "Main effects training epoch: 118, train loss: 2.62033, val loss: 2.64707\n",
      "Main effects training epoch: 119, train loss: 2.59824, val loss: 2.62418\n",
      "Main effects training epoch: 120, train loss: 2.57613, val loss: 2.60125\n",
      "Main effects training epoch: 121, train loss: 2.55407, val loss: 2.57835\n",
      "Main effects training epoch: 122, train loss: 2.53213, val loss: 2.55555\n",
      "Main effects training epoch: 123, train loss: 2.51018, val loss: 2.53273\n",
      "Main effects training epoch: 124, train loss: 2.48843, val loss: 2.51009\n",
      "Main effects training epoch: 125, train loss: 2.46670, val loss: 2.48747\n",
      "Main effects training epoch: 126, train loss: 2.44490, val loss: 2.46476\n",
      "Main effects training epoch: 127, train loss: 2.42305, val loss: 2.44199\n",
      "Main effects training epoch: 128, train loss: 2.40085, val loss: 2.41885\n",
      "Main effects training epoch: 129, train loss: 2.37851, val loss: 2.39556\n",
      "Main effects training epoch: 130, train loss: 2.35599, val loss: 2.37207\n",
      "Main effects training epoch: 131, train loss: 2.33330, val loss: 2.34840\n",
      "Main effects training epoch: 132, train loss: 2.31078, val loss: 2.32487\n",
      "Main effects training epoch: 133, train loss: 2.28826, val loss: 2.30133\n",
      "Main effects training epoch: 134, train loss: 2.26574, val loss: 2.27780\n",
      "Main effects training epoch: 135, train loss: 2.24313, val loss: 2.25416\n",
      "Main effects training epoch: 136, train loss: 2.22063, val loss: 2.23062\n",
      "Main effects training epoch: 137, train loss: 2.19821, val loss: 2.20713\n",
      "Main effects training epoch: 138, train loss: 2.17571, val loss: 2.18353\n",
      "Main effects training epoch: 139, train loss: 2.15298, val loss: 2.15966\n",
      "Main effects training epoch: 140, train loss: 2.13060, val loss: 2.13614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 141, train loss: 2.10831, val loss: 2.11267\n",
      "Main effects training epoch: 142, train loss: 2.08585, val loss: 2.08902\n",
      "Main effects training epoch: 143, train loss: 2.06314, val loss: 2.06510\n",
      "Main effects training epoch: 144, train loss: 2.04024, val loss: 2.04094\n",
      "Main effects training epoch: 145, train loss: 2.01709, val loss: 2.01649\n",
      "Main effects training epoch: 146, train loss: 1.99395, val loss: 1.99204\n",
      "Main effects training epoch: 147, train loss: 1.97098, val loss: 1.96772\n",
      "Main effects training epoch: 148, train loss: 1.94815, val loss: 1.94354\n",
      "Main effects training epoch: 149, train loss: 1.92560, val loss: 1.91963\n",
      "Main effects training epoch: 150, train loss: 1.90304, val loss: 1.89569\n",
      "Main effects training epoch: 151, train loss: 1.88046, val loss: 1.87169\n",
      "Main effects training epoch: 152, train loss: 1.85807, val loss: 1.84786\n",
      "Main effects training epoch: 153, train loss: 1.83548, val loss: 1.82379\n",
      "Main effects training epoch: 154, train loss: 1.81327, val loss: 1.80010\n",
      "Main effects training epoch: 155, train loss: 1.79130, val loss: 1.77665\n",
      "Main effects training epoch: 156, train loss: 1.76961, val loss: 1.75347\n",
      "Main effects training epoch: 157, train loss: 1.74795, val loss: 1.73028\n",
      "Main effects training epoch: 158, train loss: 1.72646, val loss: 1.70726\n",
      "Main effects training epoch: 159, train loss: 1.70535, val loss: 1.68461\n",
      "Main effects training epoch: 160, train loss: 1.68449, val loss: 1.66222\n",
      "Main effects training epoch: 161, train loss: 1.66354, val loss: 1.63968\n",
      "Main effects training epoch: 162, train loss: 1.64251, val loss: 1.61702\n",
      "Main effects training epoch: 163, train loss: 1.62143, val loss: 1.59427\n",
      "Main effects training epoch: 164, train loss: 1.60053, val loss: 1.57168\n",
      "Main effects training epoch: 165, train loss: 1.57998, val loss: 1.54941\n",
      "Main effects training epoch: 166, train loss: 1.55971, val loss: 1.52741\n",
      "Main effects training epoch: 167, train loss: 1.53930, val loss: 1.50522\n",
      "Main effects training epoch: 168, train loss: 1.51950, val loss: 1.48365\n",
      "Main effects training epoch: 169, train loss: 1.49983, val loss: 1.46219\n",
      "Main effects training epoch: 170, train loss: 1.48056, val loss: 1.44113\n",
      "Main effects training epoch: 171, train loss: 1.46144, val loss: 1.42019\n",
      "Main effects training epoch: 172, train loss: 1.44253, val loss: 1.39946\n",
      "Main effects training epoch: 173, train loss: 1.42393, val loss: 1.37903\n",
      "Main effects training epoch: 174, train loss: 1.40570, val loss: 1.35897\n",
      "Main effects training epoch: 175, train loss: 1.38765, val loss: 1.33911\n",
      "Main effects training epoch: 176, train loss: 1.36998, val loss: 1.31961\n",
      "Main effects training epoch: 177, train loss: 1.35287, val loss: 1.30070\n",
      "Main effects training epoch: 178, train loss: 1.33603, val loss: 1.28205\n",
      "Main effects training epoch: 179, train loss: 1.31912, val loss: 1.26327\n",
      "Main effects training epoch: 180, train loss: 1.30261, val loss: 1.24489\n",
      "Main effects training epoch: 181, train loss: 1.28639, val loss: 1.22680\n",
      "Main effects training epoch: 182, train loss: 1.27050, val loss: 1.20905\n",
      "Main effects training epoch: 183, train loss: 1.25474, val loss: 1.19140\n",
      "Main effects training epoch: 184, train loss: 1.23926, val loss: 1.17401\n",
      "Main effects training epoch: 185, train loss: 1.22434, val loss: 1.15718\n",
      "Main effects training epoch: 186, train loss: 1.20957, val loss: 1.14047\n",
      "Main effects training epoch: 187, train loss: 1.19505, val loss: 1.12400\n",
      "Main effects training epoch: 188, train loss: 1.18125, val loss: 1.10830\n",
      "Main effects training epoch: 189, train loss: 1.16815, val loss: 1.09337\n",
      "Main effects training epoch: 190, train loss: 1.15546, val loss: 1.07885\n",
      "Main effects training epoch: 191, train loss: 1.14329, val loss: 1.06489\n",
      "Main effects training epoch: 192, train loss: 1.13142, val loss: 1.05122\n",
      "Main effects training epoch: 193, train loss: 1.11989, val loss: 1.03790\n",
      "Main effects training epoch: 194, train loss: 1.10877, val loss: 1.02501\n",
      "Main effects training epoch: 195, train loss: 1.09767, val loss: 1.01209\n",
      "Main effects training epoch: 196, train loss: 1.08699, val loss: 0.99962\n",
      "Main effects training epoch: 197, train loss: 1.07672, val loss: 0.98755\n",
      "Main effects training epoch: 198, train loss: 1.06696, val loss: 0.97600\n",
      "Main effects training epoch: 199, train loss: 1.05744, val loss: 0.96469\n",
      "Main effects training epoch: 200, train loss: 1.04831, val loss: 0.95376\n",
      "Main effects training epoch: 201, train loss: 1.03956, val loss: 0.94324\n",
      "Main effects training epoch: 202, train loss: 1.03094, val loss: 0.93281\n",
      "Main effects training epoch: 203, train loss: 1.02260, val loss: 0.92266\n",
      "Main effects training epoch: 204, train loss: 1.01471, val loss: 0.91301\n",
      "Main effects training epoch: 205, train loss: 1.00698, val loss: 0.90345\n",
      "Main effects training epoch: 206, train loss: 0.99953, val loss: 0.89420\n",
      "Main effects training epoch: 207, train loss: 0.99232, val loss: 0.88516\n",
      "Main effects training epoch: 208, train loss: 0.98549, val loss: 0.87654\n",
      "Main effects training epoch: 209, train loss: 0.97914, val loss: 0.86848\n",
      "Main effects training epoch: 210, train loss: 0.97313, val loss: 0.86078\n",
      "Main effects training epoch: 211, train loss: 0.96748, val loss: 0.85349\n",
      "Main effects training epoch: 212, train loss: 0.96227, val loss: 0.84673\n",
      "Main effects training epoch: 213, train loss: 0.95735, val loss: 0.84030\n",
      "Main effects training epoch: 214, train loss: 0.95256, val loss: 0.83397\n",
      "Main effects training epoch: 215, train loss: 0.94779, val loss: 0.82758\n",
      "Main effects training epoch: 216, train loss: 0.94312, val loss: 0.82123\n",
      "Main effects training epoch: 217, train loss: 0.93890, val loss: 0.81547\n",
      "Main effects training epoch: 218, train loss: 0.93484, val loss: 0.80985\n",
      "Main effects training epoch: 219, train loss: 0.93108, val loss: 0.80458\n",
      "Main effects training epoch: 220, train loss: 0.92765, val loss: 0.79977\n",
      "Main effects training epoch: 221, train loss: 0.92436, val loss: 0.79507\n",
      "Main effects training epoch: 222, train loss: 0.92109, val loss: 0.79028\n",
      "Main effects training epoch: 223, train loss: 0.91811, val loss: 0.78584\n",
      "Main effects training epoch: 224, train loss: 0.91529, val loss: 0.78154\n",
      "Main effects training epoch: 225, train loss: 0.91262, val loss: 0.77743\n",
      "Main effects training epoch: 226, train loss: 0.91009, val loss: 0.77342\n",
      "Main effects training epoch: 227, train loss: 0.90779, val loss: 0.76973\n",
      "Main effects training epoch: 228, train loss: 0.90581, val loss: 0.76655\n",
      "Main effects training epoch: 229, train loss: 0.90394, val loss: 0.76347\n",
      "Main effects training epoch: 230, train loss: 0.90229, val loss: 0.76073\n",
      "Main effects training epoch: 231, train loss: 0.90086, val loss: 0.75838\n",
      "Main effects training epoch: 232, train loss: 0.89958, val loss: 0.75628\n",
      "Main effects training epoch: 233, train loss: 0.89842, val loss: 0.75439\n",
      "Main effects training epoch: 234, train loss: 0.89732, val loss: 0.75258\n",
      "Main effects training epoch: 235, train loss: 0.89625, val loss: 0.75075\n",
      "Main effects training epoch: 236, train loss: 0.89527, val loss: 0.74906\n",
      "Main effects training epoch: 237, train loss: 0.89437, val loss: 0.74753\n",
      "Main effects training epoch: 238, train loss: 0.89352, val loss: 0.74602\n",
      "Main effects training epoch: 239, train loss: 0.89273, val loss: 0.74469\n",
      "Main effects training epoch: 240, train loss: 0.89202, val loss: 0.74361\n",
      "Main effects training epoch: 241, train loss: 0.89136, val loss: 0.74264\n",
      "Main effects training epoch: 242, train loss: 0.89069, val loss: 0.74144\n",
      "Main effects training epoch: 243, train loss: 0.89007, val loss: 0.74040\n",
      "Main effects training epoch: 244, train loss: 0.88947, val loss: 0.73927\n",
      "Main effects training epoch: 245, train loss: 0.88890, val loss: 0.73814\n",
      "Main effects training epoch: 246, train loss: 0.88838, val loss: 0.73721\n",
      "Main effects training epoch: 247, train loss: 0.88791, val loss: 0.73633\n",
      "Main effects training epoch: 248, train loss: 0.88746, val loss: 0.73557\n",
      "Main effects training epoch: 249, train loss: 0.88702, val loss: 0.73495\n",
      "Main effects training epoch: 250, train loss: 0.88659, val loss: 0.73430\n",
      "Main effects training epoch: 251, train loss: 0.88618, val loss: 0.73369\n",
      "Main effects training epoch: 252, train loss: 0.88580, val loss: 0.73308\n",
      "Main effects training epoch: 253, train loss: 0.88541, val loss: 0.73263\n",
      "Main effects training epoch: 254, train loss: 0.88502, val loss: 0.73226\n",
      "Main effects training epoch: 255, train loss: 0.88462, val loss: 0.73190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 256, train loss: 0.88423, val loss: 0.73155\n",
      "Main effects training epoch: 257, train loss: 0.88386, val loss: 0.73111\n",
      "Main effects training epoch: 258, train loss: 0.88346, val loss: 0.73086\n",
      "Main effects training epoch: 259, train loss: 0.88305, val loss: 0.73066\n",
      "Main effects training epoch: 260, train loss: 0.88264, val loss: 0.73049\n",
      "Main effects training epoch: 261, train loss: 0.88222, val loss: 0.73032\n",
      "Main effects training epoch: 262, train loss: 0.88180, val loss: 0.73016\n",
      "Main effects training epoch: 263, train loss: 0.88139, val loss: 0.72995\n",
      "Main effects training epoch: 264, train loss: 0.88100, val loss: 0.72967\n",
      "Main effects training epoch: 265, train loss: 0.88062, val loss: 0.72934\n",
      "Main effects training epoch: 266, train loss: 0.88026, val loss: 0.72899\n",
      "Main effects training epoch: 267, train loss: 0.87989, val loss: 0.72869\n",
      "Main effects training epoch: 268, train loss: 0.87952, val loss: 0.72842\n",
      "Main effects training epoch: 269, train loss: 0.87916, val loss: 0.72816\n",
      "Main effects training epoch: 270, train loss: 0.87877, val loss: 0.72799\n",
      "Main effects training epoch: 271, train loss: 0.87840, val loss: 0.72780\n",
      "Main effects training epoch: 272, train loss: 0.87798, val loss: 0.72779\n",
      "Main effects training epoch: 273, train loss: 0.87762, val loss: 0.72762\n",
      "Main effects training epoch: 274, train loss: 0.87726, val loss: 0.72746\n",
      "Main effects training epoch: 275, train loss: 0.87687, val loss: 0.72737\n",
      "Main effects training epoch: 276, train loss: 0.87648, val loss: 0.72727\n",
      "Main effects training epoch: 277, train loss: 0.87612, val loss: 0.72714\n",
      "Main effects training epoch: 278, train loss: 0.87574, val loss: 0.72708\n",
      "Main effects training epoch: 279, train loss: 0.87535, val loss: 0.72701\n",
      "Main effects training epoch: 280, train loss: 0.87494, val loss: 0.72702\n",
      "Main effects training epoch: 281, train loss: 0.87451, val loss: 0.72704\n",
      "Main effects training epoch: 282, train loss: 0.87412, val loss: 0.72698\n",
      "Main effects training epoch: 283, train loss: 0.87374, val loss: 0.72692\n",
      "Main effects training epoch: 284, train loss: 0.87338, val loss: 0.72673\n",
      "Main effects training epoch: 285, train loss: 0.87302, val loss: 0.72657\n",
      "Main effects training epoch: 286, train loss: 0.87263, val loss: 0.72648\n",
      "Main effects training epoch: 287, train loss: 0.87224, val loss: 0.72639\n",
      "Main effects training epoch: 288, train loss: 0.87183, val loss: 0.72637\n",
      "Main effects training epoch: 289, train loss: 0.87139, val loss: 0.72641\n",
      "Main effects training epoch: 290, train loss: 0.87096, val loss: 0.72642\n",
      "Main effects training epoch: 291, train loss: 0.87050, val loss: 0.72659\n",
      "Main effects training epoch: 292, train loss: 0.87004, val loss: 0.72679\n",
      "Main effects training epoch: 293, train loss: 0.86957, val loss: 0.72716\n",
      "Main effects training epoch: 294, train loss: 0.86912, val loss: 0.72763\n",
      "Main effects training epoch: 295, train loss: 0.86868, val loss: 0.72821\n",
      "Main effects training epoch: 296, train loss: 0.86826, val loss: 0.72889\n",
      "Main effects training epoch: 297, train loss: 0.86788, val loss: 0.72956\n",
      "Main effects training epoch: 298, train loss: 0.86752, val loss: 0.73014\n",
      "Main effects training epoch: 299, train loss: 0.86720, val loss: 0.73081\n",
      "Main effects training epoch: 300, train loss: 0.86694, val loss: 0.73168\n",
      "Main effects training epoch: 301, train loss: 0.86669, val loss: 0.73246\n",
      "Main effects training epoch: 302, train loss: 0.86644, val loss: 0.73319\n",
      "Main effects training epoch: 303, train loss: 0.86618, val loss: 0.73375\n",
      "Main effects training epoch: 304, train loss: 0.86589, val loss: 0.73410\n",
      "Main effects training epoch: 305, train loss: 0.86558, val loss: 0.73436\n",
      "Main effects training epoch: 306, train loss: 0.86527, val loss: 0.73459\n",
      "Main effects training epoch: 307, train loss: 0.86497, val loss: 0.73488\n",
      "Main effects training epoch: 308, train loss: 0.86470, val loss: 0.73526\n",
      "Main effects training epoch: 309, train loss: 0.86436, val loss: 0.73536\n",
      "Main effects training epoch: 310, train loss: 0.86400, val loss: 0.73537\n",
      "Main effects training epoch: 311, train loss: 0.86361, val loss: 0.73524\n",
      "Main effects training epoch: 312, train loss: 0.86320, val loss: 0.73502\n",
      "Main effects training epoch: 313, train loss: 0.86287, val loss: 0.73508\n",
      "Main effects training epoch: 314, train loss: 0.86253, val loss: 0.73503\n",
      "Main effects training epoch: 315, train loss: 0.86219, val loss: 0.73499\n",
      "Main effects training epoch: 316, train loss: 0.86187, val loss: 0.73501\n",
      "Main effects training epoch: 317, train loss: 0.86160, val loss: 0.73525\n",
      "Main effects training epoch: 318, train loss: 0.86123, val loss: 0.73513\n",
      "Main effects training epoch: 319, train loss: 0.86086, val loss: 0.73497\n",
      "Main effects training epoch: 320, train loss: 0.86049, val loss: 0.73485\n",
      "Main effects training epoch: 321, train loss: 0.86012, val loss: 0.73473\n",
      "Main effects training epoch: 322, train loss: 0.85978, val loss: 0.73471\n",
      "Main effects training epoch: 323, train loss: 0.85944, val loss: 0.73470\n",
      "Main effects training epoch: 324, train loss: 0.85910, val loss: 0.73470\n",
      "Main effects training epoch: 325, train loss: 0.85873, val loss: 0.73461\n",
      "Main effects training epoch: 326, train loss: 0.85833, val loss: 0.73444\n",
      "Main effects training epoch: 327, train loss: 0.85801, val loss: 0.73456\n",
      "Main effects training epoch: 328, train loss: 0.85765, val loss: 0.73456\n",
      "Main effects training epoch: 329, train loss: 0.85729, val loss: 0.73451\n",
      "Main effects training epoch: 330, train loss: 0.85692, val loss: 0.73447\n",
      "Main effects training epoch: 331, train loss: 0.85657, val loss: 0.73445\n",
      "Main effects training epoch: 332, train loss: 0.85617, val loss: 0.73424\n",
      "Main effects training epoch: 333, train loss: 0.85579, val loss: 0.73406\n",
      "Main effects training epoch: 334, train loss: 0.85541, val loss: 0.73393\n",
      "Main effects training epoch: 335, train loss: 0.85500, val loss: 0.73364\n",
      "Main effects training epoch: 336, train loss: 0.85459, val loss: 0.73337\n",
      "Main effects training epoch: 337, train loss: 0.85418, val loss: 0.73300\n",
      "Main effects training epoch: 338, train loss: 0.85376, val loss: 0.73259\n",
      "Main effects training epoch: 339, train loss: 0.85336, val loss: 0.73226\n",
      "Early stop at epoch 339, with validation loss: 0.73226\n",
      "##########Stage 1: main effect training stop.##########\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.83781, val loss: 0.72308\n",
      "Interaction training epoch: 2, train loss: 0.83650, val loss: 0.72181\n",
      "Interaction training epoch: 3, train loss: 0.83559, val loss: 0.72197\n",
      "Interaction training epoch: 4, train loss: 0.83460, val loss: 0.72213\n",
      "Interaction training epoch: 5, train loss: 0.83356, val loss: 0.72173\n",
      "Interaction training epoch: 6, train loss: 0.83247, val loss: 0.72097\n",
      "Interaction training epoch: 7, train loss: 0.83144, val loss: 0.72017\n",
      "Interaction training epoch: 8, train loss: 0.83037, val loss: 0.71917\n",
      "Interaction training epoch: 9, train loss: 0.82938, val loss: 0.71853\n",
      "Interaction training epoch: 10, train loss: 0.82851, val loss: 0.71840\n",
      "Interaction training epoch: 11, train loss: 0.82773, val loss: 0.71846\n",
      "Interaction training epoch: 12, train loss: 0.82698, val loss: 0.71851\n",
      "Interaction training epoch: 13, train loss: 0.82616, val loss: 0.71825\n",
      "Interaction training epoch: 14, train loss: 0.82535, val loss: 0.71806\n",
      "Interaction training epoch: 15, train loss: 0.82455, val loss: 0.71778\n",
      "Interaction training epoch: 16, train loss: 0.82369, val loss: 0.71709\n",
      "Interaction training epoch: 17, train loss: 0.82287, val loss: 0.71656\n",
      "Interaction training epoch: 18, train loss: 0.82206, val loss: 0.71573\n",
      "Interaction training epoch: 19, train loss: 0.82129, val loss: 0.71522\n",
      "Interaction training epoch: 20, train loss: 0.82052, val loss: 0.71499\n",
      "Interaction training epoch: 21, train loss: 0.81974, val loss: 0.71478\n",
      "Interaction training epoch: 22, train loss: 0.81892, val loss: 0.71460\n",
      "Interaction training epoch: 23, train loss: 0.81812, val loss: 0.71445\n",
      "Interaction training epoch: 24, train loss: 0.81733, val loss: 0.71450\n",
      "Interaction training epoch: 25, train loss: 0.81657, val loss: 0.71457\n",
      "Interaction training epoch: 26, train loss: 0.81580, val loss: 0.71453\n",
      "Interaction training epoch: 27, train loss: 0.81502, val loss: 0.71459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 28, train loss: 0.81422, val loss: 0.71468\n",
      "Interaction training epoch: 29, train loss: 0.81344, val loss: 0.71474\n",
      "Interaction training epoch: 30, train loss: 0.81265, val loss: 0.71465\n",
      "Interaction training epoch: 31, train loss: 0.81192, val loss: 0.71479\n",
      "Interaction training epoch: 32, train loss: 0.81113, val loss: 0.71470\n",
      "Interaction training epoch: 33, train loss: 0.81027, val loss: 0.71453\n",
      "Interaction training epoch: 34, train loss: 0.80935, val loss: 0.71420\n",
      "Interaction training epoch: 35, train loss: 0.80841, val loss: 0.71376\n",
      "Interaction training epoch: 36, train loss: 0.80746, val loss: 0.71333\n",
      "Interaction training epoch: 37, train loss: 0.80649, val loss: 0.71303\n",
      "Interaction training epoch: 38, train loss: 0.80554, val loss: 0.71284\n",
      "Interaction training epoch: 39, train loss: 0.80455, val loss: 0.71251\n",
      "Interaction training epoch: 40, train loss: 0.80353, val loss: 0.71206\n",
      "Interaction training epoch: 41, train loss: 0.80251, val loss: 0.71153\n",
      "Interaction training epoch: 42, train loss: 0.80146, val loss: 0.71096\n",
      "Interaction training epoch: 43, train loss: 0.80043, val loss: 0.71060\n",
      "Interaction training epoch: 44, train loss: 0.79937, val loss: 0.71021\n",
      "Interaction training epoch: 45, train loss: 0.79833, val loss: 0.70997\n",
      "Interaction training epoch: 46, train loss: 0.79732, val loss: 0.70988\n",
      "Interaction training epoch: 47, train loss: 0.79636, val loss: 0.70993\n",
      "Interaction training epoch: 48, train loss: 0.79538, val loss: 0.70983\n",
      "Interaction training epoch: 49, train loss: 0.79443, val loss: 0.70980\n",
      "Interaction training epoch: 50, train loss: 0.79337, val loss: 0.70945\n",
      "Interaction training epoch: 51, train loss: 0.79229, val loss: 0.70872\n",
      "Interaction training epoch: 52, train loss: 0.79129, val loss: 0.70786\n",
      "Interaction training epoch: 53, train loss: 0.79028, val loss: 0.70728\n",
      "Interaction training epoch: 54, train loss: 0.78932, val loss: 0.70670\n",
      "Interaction training epoch: 55, train loss: 0.78828, val loss: 0.70631\n",
      "Interaction training epoch: 56, train loss: 0.78723, val loss: 0.70592\n",
      "Interaction training epoch: 57, train loss: 0.78613, val loss: 0.70558\n",
      "Interaction training epoch: 58, train loss: 0.78500, val loss: 0.70533\n",
      "Interaction training epoch: 59, train loss: 0.78390, val loss: 0.70506\n",
      "Interaction training epoch: 60, train loss: 0.78275, val loss: 0.70505\n",
      "Interaction training epoch: 61, train loss: 0.78157, val loss: 0.70496\n",
      "Interaction training epoch: 62, train loss: 0.78039, val loss: 0.70488\n",
      "Interaction training epoch: 63, train loss: 0.77918, val loss: 0.70489\n",
      "Interaction training epoch: 64, train loss: 0.77795, val loss: 0.70492\n",
      "Interaction training epoch: 65, train loss: 0.77669, val loss: 0.70485\n",
      "Interaction training epoch: 66, train loss: 0.77544, val loss: 0.70437\n",
      "Interaction training epoch: 67, train loss: 0.77420, val loss: 0.70382\n",
      "Interaction training epoch: 68, train loss: 0.77299, val loss: 0.70320\n",
      "Interaction training epoch: 69, train loss: 0.77179, val loss: 0.70276\n",
      "Interaction training epoch: 70, train loss: 0.77047, val loss: 0.70246\n",
      "Interaction training epoch: 71, train loss: 0.76903, val loss: 0.70229\n",
      "Interaction training epoch: 72, train loss: 0.76754, val loss: 0.70233\n",
      "Interaction training epoch: 73, train loss: 0.76617, val loss: 0.70254\n",
      "Interaction training epoch: 74, train loss: 0.76486, val loss: 0.70265\n",
      "Interaction training epoch: 75, train loss: 0.76351, val loss: 0.70261\n",
      "Interaction training epoch: 76, train loss: 0.76211, val loss: 0.70232\n",
      "Interaction training epoch: 77, train loss: 0.76074, val loss: 0.70215\n",
      "Interaction training epoch: 78, train loss: 0.75937, val loss: 0.70211\n",
      "Interaction training epoch: 79, train loss: 0.75790, val loss: 0.70176\n",
      "Interaction training epoch: 80, train loss: 0.75640, val loss: 0.70126\n",
      "Interaction training epoch: 81, train loss: 0.75489, val loss: 0.70082\n",
      "Interaction training epoch: 82, train loss: 0.75343, val loss: 0.70027\n",
      "Interaction training epoch: 83, train loss: 0.75198, val loss: 0.69987\n",
      "Interaction training epoch: 84, train loss: 0.75050, val loss: 0.69951\n",
      "Interaction training epoch: 85, train loss: 0.74907, val loss: 0.69906\n",
      "Interaction training epoch: 86, train loss: 0.74771, val loss: 0.69855\n",
      "Interaction training epoch: 87, train loss: 0.74644, val loss: 0.69804\n",
      "Interaction training epoch: 88, train loss: 0.74493, val loss: 0.69763\n",
      "Interaction training epoch: 89, train loss: 0.74324, val loss: 0.69726\n",
      "Interaction training epoch: 90, train loss: 0.74138, val loss: 0.69689\n",
      "Interaction training epoch: 91, train loss: 0.73950, val loss: 0.69655\n",
      "Interaction training epoch: 92, train loss: 0.73747, val loss: 0.69626\n",
      "Interaction training epoch: 93, train loss: 0.73550, val loss: 0.69590\n",
      "Interaction training epoch: 94, train loss: 0.73346, val loss: 0.69566\n",
      "Interaction training epoch: 95, train loss: 0.73158, val loss: 0.69523\n",
      "Interaction training epoch: 96, train loss: 0.72971, val loss: 0.69483\n",
      "Interaction training epoch: 97, train loss: 0.72782, val loss: 0.69449\n",
      "Interaction training epoch: 98, train loss: 0.72583, val loss: 0.69423\n",
      "Interaction training epoch: 99, train loss: 0.72389, val loss: 0.69387\n",
      "Interaction training epoch: 100, train loss: 0.72187, val loss: 0.69357\n",
      "Interaction training epoch: 101, train loss: 0.71978, val loss: 0.69327\n",
      "Interaction training epoch: 102, train loss: 0.71764, val loss: 0.69309\n",
      "Interaction training epoch: 103, train loss: 0.71547, val loss: 0.69308\n",
      "Interaction training epoch: 104, train loss: 0.71335, val loss: 0.69295\n",
      "Interaction training epoch: 105, train loss: 0.71115, val loss: 0.69277\n",
      "Interaction training epoch: 106, train loss: 0.70889, val loss: 0.69239\n",
      "Interaction training epoch: 107, train loss: 0.70667, val loss: 0.69199\n",
      "Interaction training epoch: 108, train loss: 0.70444, val loss: 0.69159\n",
      "Interaction training epoch: 109, train loss: 0.70233, val loss: 0.69118\n",
      "Interaction training epoch: 110, train loss: 0.70018, val loss: 0.69101\n",
      "Interaction training epoch: 111, train loss: 0.69795, val loss: 0.69084\n",
      "Interaction training epoch: 112, train loss: 0.69579, val loss: 0.69055\n",
      "Interaction training epoch: 113, train loss: 0.69370, val loss: 0.69015\n",
      "Interaction training epoch: 114, train loss: 0.69143, val loss: 0.68999\n",
      "Interaction training epoch: 115, train loss: 0.68907, val loss: 0.68996\n",
      "Interaction training epoch: 116, train loss: 0.68667, val loss: 0.69011\n",
      "Interaction training epoch: 117, train loss: 0.68422, val loss: 0.69037\n",
      "Interaction training epoch: 118, train loss: 0.68186, val loss: 0.69052\n",
      "Interaction training epoch: 119, train loss: 0.67949, val loss: 0.69046\n",
      "Interaction training epoch: 120, train loss: 0.67709, val loss: 0.69048\n",
      "Interaction training epoch: 121, train loss: 0.67466, val loss: 0.69063\n",
      "Interaction training epoch: 122, train loss: 0.67222, val loss: 0.69110\n",
      "Interaction training epoch: 123, train loss: 0.66973, val loss: 0.69145\n",
      "Interaction training epoch: 124, train loss: 0.66721, val loss: 0.69135\n",
      "Interaction training epoch: 125, train loss: 0.66478, val loss: 0.69134\n",
      "Interaction training epoch: 126, train loss: 0.66230, val loss: 0.69096\n",
      "Interaction training epoch: 127, train loss: 0.65985, val loss: 0.69073\n",
      "Interaction training epoch: 128, train loss: 0.65739, val loss: 0.69062\n",
      "Interaction training epoch: 129, train loss: 0.65500, val loss: 0.69031\n",
      "Interaction training epoch: 130, train loss: 0.65256, val loss: 0.69001\n",
      "Interaction training epoch: 131, train loss: 0.64998, val loss: 0.69002\n",
      "Interaction training epoch: 132, train loss: 0.64748, val loss: 0.68990\n",
      "Interaction training epoch: 133, train loss: 0.64484, val loss: 0.68993\n",
      "Interaction training epoch: 134, train loss: 0.64214, val loss: 0.69014\n",
      "Interaction training epoch: 135, train loss: 0.63939, val loss: 0.69047\n",
      "Interaction training epoch: 136, train loss: 0.63665, val loss: 0.69065\n",
      "Interaction training epoch: 137, train loss: 0.63386, val loss: 0.69089\n",
      "Interaction training epoch: 138, train loss: 0.63106, val loss: 0.69095\n",
      "Interaction training epoch: 139, train loss: 0.62820, val loss: 0.69099\n",
      "Interaction training epoch: 140, train loss: 0.62531, val loss: 0.69153\n",
      "Interaction training epoch: 141, train loss: 0.62233, val loss: 0.69195\n",
      "Interaction training epoch: 142, train loss: 0.61943, val loss: 0.69253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 143, train loss: 0.61638, val loss: 0.69259\n",
      "Interaction training epoch: 144, train loss: 0.61340, val loss: 0.69287\n",
      "Interaction training epoch: 145, train loss: 0.61049, val loss: 0.69355\n",
      "Interaction training epoch: 146, train loss: 0.60755, val loss: 0.69408\n",
      "Interaction training epoch: 147, train loss: 0.60450, val loss: 0.69452\n",
      "Interaction training epoch: 148, train loss: 0.60138, val loss: 0.69496\n",
      "Interaction training epoch: 149, train loss: 0.59807, val loss: 0.69449\n",
      "Interaction training epoch: 150, train loss: 0.59482, val loss: 0.69400\n",
      "Interaction training epoch: 151, train loss: 0.59171, val loss: 0.69328\n",
      "Interaction training epoch: 152, train loss: 0.58872, val loss: 0.69197\n",
      "Interaction training epoch: 153, train loss: 0.58596, val loss: 0.69093\n",
      "Interaction training epoch: 154, train loss: 0.58366, val loss: 0.68956\n",
      "Interaction training epoch: 155, train loss: 0.58164, val loss: 0.68828\n",
      "Interaction training epoch: 156, train loss: 0.57962, val loss: 0.68744\n",
      "Interaction training epoch: 157, train loss: 0.57726, val loss: 0.68712\n",
      "Interaction training epoch: 158, train loss: 0.57457, val loss: 0.68698\n",
      "Interaction training epoch: 159, train loss: 0.57206, val loss: 0.68666\n",
      "Interaction training epoch: 160, train loss: 0.56895, val loss: 0.68665\n",
      "Interaction training epoch: 161, train loss: 0.56547, val loss: 0.68658\n",
      "Interaction training epoch: 162, train loss: 0.56148, val loss: 0.68666\n",
      "Interaction training epoch: 163, train loss: 0.55749, val loss: 0.68677\n",
      "Interaction training epoch: 164, train loss: 0.55328, val loss: 0.68729\n",
      "Interaction training epoch: 165, train loss: 0.54961, val loss: 0.68770\n",
      "Interaction training epoch: 166, train loss: 0.54602, val loss: 0.68848\n",
      "Interaction training epoch: 167, train loss: 0.54266, val loss: 0.68950\n",
      "Interaction training epoch: 168, train loss: 0.53941, val loss: 0.69092\n",
      "Interaction training epoch: 169, train loss: 0.53645, val loss: 0.69286\n",
      "Interaction training epoch: 170, train loss: 0.53366, val loss: 0.69491\n",
      "Interaction training epoch: 171, train loss: 0.53112, val loss: 0.69722\n",
      "Interaction training epoch: 172, train loss: 0.52848, val loss: 0.69910\n",
      "Interaction training epoch: 173, train loss: 0.52586, val loss: 0.70111\n",
      "Interaction training epoch: 174, train loss: 0.52327, val loss: 0.70301\n",
      "Interaction training epoch: 175, train loss: 0.52021, val loss: 0.70416\n",
      "Interaction training epoch: 176, train loss: 0.51706, val loss: 0.70505\n",
      "Interaction training epoch: 177, train loss: 0.51409, val loss: 0.70666\n",
      "Interaction training epoch: 178, train loss: 0.51065, val loss: 0.70754\n",
      "Interaction training epoch: 179, train loss: 0.50716, val loss: 0.70827\n",
      "Interaction training epoch: 180, train loss: 0.50358, val loss: 0.70877\n",
      "Interaction training epoch: 181, train loss: 0.49983, val loss: 0.70800\n",
      "Interaction training epoch: 182, train loss: 0.49640, val loss: 0.70739\n",
      "Interaction training epoch: 183, train loss: 0.49301, val loss: 0.70651\n",
      "Interaction training epoch: 184, train loss: 0.48979, val loss: 0.70497\n",
      "Interaction training epoch: 185, train loss: 0.48696, val loss: 0.70349\n",
      "Interaction training epoch: 186, train loss: 0.48425, val loss: 0.70281\n",
      "Interaction training epoch: 187, train loss: 0.48172, val loss: 0.70211\n",
      "Interaction training epoch: 188, train loss: 0.47884, val loss: 0.70261\n",
      "Interaction training epoch: 189, train loss: 0.47585, val loss: 0.70366\n",
      "Interaction training epoch: 190, train loss: 0.47296, val loss: 0.70427\n",
      "Interaction training epoch: 191, train loss: 0.47026, val loss: 0.70433\n",
      "Interaction training epoch: 192, train loss: 0.46724, val loss: 0.70512\n",
      "Interaction training epoch: 193, train loss: 0.46392, val loss: 0.70686\n",
      "Interaction training epoch: 194, train loss: 0.46073, val loss: 0.70892\n",
      "Interaction training epoch: 195, train loss: 0.45770, val loss: 0.71114\n",
      "Interaction training epoch: 196, train loss: 0.45504, val loss: 0.71182\n",
      "Interaction training epoch: 197, train loss: 0.45280, val loss: 0.71087\n",
      "Interaction training epoch: 198, train loss: 0.45060, val loss: 0.71063\n",
      "Interaction training epoch: 199, train loss: 0.44836, val loss: 0.71063\n",
      "Interaction training epoch: 200, train loss: 0.44614, val loss: 0.71070\n",
      "Interaction training epoch: 201, train loss: 0.44349, val loss: 0.71169\n",
      "Interaction training epoch: 202, train loss: 0.44035, val loss: 0.71366\n",
      "Interaction training epoch: 203, train loss: 0.43708, val loss: 0.71664\n",
      "Interaction training epoch: 204, train loss: 0.43416, val loss: 0.72123\n",
      "Interaction training epoch: 205, train loss: 0.43193, val loss: 0.72620\n",
      "Interaction training epoch: 206, train loss: 0.43028, val loss: 0.73139\n",
      "Interaction training epoch: 207, train loss: 0.42901, val loss: 0.73685\n",
      "Interaction training epoch: 208, train loss: 0.42722, val loss: 0.74033\n",
      "Interaction training epoch: 209, train loss: 0.42488, val loss: 0.74227\n",
      "Interaction training epoch: 210, train loss: 0.42284, val loss: 0.74514\n",
      "Interaction training epoch: 211, train loss: 0.42030, val loss: 0.74655\n",
      "Interaction training epoch: 212, train loss: 0.41725, val loss: 0.74651\n",
      "Early stop at epoch 212, with validation loss: 0.74651\n",
      "##########Stage 2: interaction training stop.##########\n",
      "Fine tuning epoch: 1, train loss: 0.61673, val loss: 0.71448\n",
      "Fine tuning epoch: 2, train loss: 0.61534, val loss: 0.71513\n",
      "Fine tuning epoch: 3, train loss: 0.61388, val loss: 0.71560\n",
      "Fine tuning epoch: 4, train loss: 0.61244, val loss: 0.71599\n",
      "Fine tuning epoch: 5, train loss: 0.61106, val loss: 0.71651\n",
      "Fine tuning epoch: 6, train loss: 0.60968, val loss: 0.71715\n",
      "Fine tuning epoch: 7, train loss: 0.60837, val loss: 0.71798\n",
      "Fine tuning epoch: 8, train loss: 0.60705, val loss: 0.71885\n",
      "Fine tuning epoch: 9, train loss: 0.60581, val loss: 0.71985\n",
      "Fine tuning epoch: 10, train loss: 0.60462, val loss: 0.72080\n",
      "Fine tuning epoch: 11, train loss: 0.60333, val loss: 0.72202\n",
      "Fine tuning epoch: 12, train loss: 0.60205, val loss: 0.72317\n",
      "Fine tuning epoch: 13, train loss: 0.60085, val loss: 0.72416\n",
      "Fine tuning epoch: 14, train loss: 0.59966, val loss: 0.72528\n",
      "Fine tuning epoch: 15, train loss: 0.59849, val loss: 0.72655\n",
      "Fine tuning epoch: 16, train loss: 0.59745, val loss: 0.72736\n",
      "Fine tuning epoch: 17, train loss: 0.59632, val loss: 0.72844\n",
      "Fine tuning epoch: 18, train loss: 0.59523, val loss: 0.72929\n",
      "Fine tuning epoch: 19, train loss: 0.59409, val loss: 0.73032\n",
      "Fine tuning epoch: 20, train loss: 0.59291, val loss: 0.73153\n",
      "Fine tuning epoch: 21, train loss: 0.59178, val loss: 0.73259\n",
      "Fine tuning epoch: 22, train loss: 0.59065, val loss: 0.73390\n",
      "Fine tuning epoch: 23, train loss: 0.58954, val loss: 0.73544\n",
      "Fine tuning epoch: 24, train loss: 0.58846, val loss: 0.73703\n",
      "Fine tuning epoch: 25, train loss: 0.58744, val loss: 0.73825\n",
      "Fine tuning epoch: 26, train loss: 0.58639, val loss: 0.74001\n",
      "Fine tuning epoch: 27, train loss: 0.58542, val loss: 0.74131\n",
      "Fine tuning epoch: 28, train loss: 0.58454, val loss: 0.74212\n",
      "Fine tuning epoch: 29, train loss: 0.58367, val loss: 0.74304\n",
      "Fine tuning epoch: 30, train loss: 0.58273, val loss: 0.74458\n",
      "Fine tuning epoch: 31, train loss: 0.58185, val loss: 0.74581\n",
      "Fine tuning epoch: 32, train loss: 0.58106, val loss: 0.74644\n",
      "Fine tuning epoch: 33, train loss: 0.58043, val loss: 0.74672\n",
      "Fine tuning epoch: 34, train loss: 0.57984, val loss: 0.74697\n",
      "Fine tuning epoch: 35, train loss: 0.57917, val loss: 0.74752\n",
      "Fine tuning epoch: 36, train loss: 0.57859, val loss: 0.74797\n",
      "Fine tuning epoch: 37, train loss: 0.57797, val loss: 0.74846\n",
      "Fine tuning epoch: 38, train loss: 0.57701, val loss: 0.74958\n",
      "Fine tuning epoch: 39, train loss: 0.57615, val loss: 0.75053\n",
      "Fine tuning epoch: 40, train loss: 0.57503, val loss: 0.75225\n",
      "Fine tuning epoch: 41, train loss: 0.57396, val loss: 0.75426\n",
      "Fine tuning epoch: 42, train loss: 0.57297, val loss: 0.75670\n",
      "Fine tuning epoch: 43, train loss: 0.57224, val loss: 0.75911\n",
      "Fine tuning epoch: 44, train loss: 0.57164, val loss: 0.76170\n",
      "Fine tuning epoch: 45, train loss: 0.57094, val loss: 0.76336\n",
      "Fine tuning epoch: 46, train loss: 0.57018, val loss: 0.76478\n",
      "Fine tuning epoch: 47, train loss: 0.56933, val loss: 0.76497\n",
      "Fine tuning epoch: 48, train loss: 0.56851, val loss: 0.76506\n",
      "Fine tuning epoch: 49, train loss: 0.56771, val loss: 0.76558\n",
      "Fine tuning epoch: 50, train loss: 0.56699, val loss: 0.76674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning epoch: 51, train loss: 0.56629, val loss: 0.76834\n",
      "Fine tuning epoch: 52, train loss: 0.56566, val loss: 0.76955\n",
      "Early stop at epoch 52, with validation loss: 0.76955\n",
      "####################GAMI-Net training finished.####################\n",
      "Train: MSE: 0.5656621511359721\n",
      "Val: MSE: 0.7695518687666554\n",
      "[6]\n",
      "[[2 5]]\n",
      "\u001b[32m[I 2024-02-10 11:23:03,577]\u001b[0m Trial 0 finished with value: 0.7695518687666554 and parameters: {'num_of_interactions': 15}. Best is trial 0 with value: 0.7695518687666554.\u001b[0m\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "[50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      " 98 99]\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 4.49786, val loss: 4.54366\n",
      "Main effects training epoch: 2, train loss: 4.48381, val loss: 4.52952\n",
      "Main effects training epoch: 3, train loss: 4.47003, val loss: 4.51575\n",
      "Main effects training epoch: 4, train loss: 4.45657, val loss: 4.50218\n",
      "Main effects training epoch: 5, train loss: 4.44316, val loss: 4.48861\n",
      "Main effects training epoch: 6, train loss: 4.42989, val loss: 4.47525\n",
      "Main effects training epoch: 7, train loss: 4.41681, val loss: 4.46207\n",
      "Main effects training epoch: 8, train loss: 4.40400, val loss: 4.44907\n",
      "Main effects training epoch: 9, train loss: 4.39145, val loss: 4.43629\n",
      "Main effects training epoch: 10, train loss: 4.37904, val loss: 4.42371\n",
      "Main effects training epoch: 11, train loss: 4.36683, val loss: 4.41132\n",
      "Main effects training epoch: 12, train loss: 4.35463, val loss: 4.39893\n",
      "Main effects training epoch: 13, train loss: 4.34246, val loss: 4.38658\n",
      "Main effects training epoch: 14, train loss: 4.33041, val loss: 4.37435\n",
      "Main effects training epoch: 15, train loss: 4.31848, val loss: 4.36227\n",
      "Main effects training epoch: 16, train loss: 4.30669, val loss: 4.35033\n",
      "Main effects training epoch: 17, train loss: 4.29495, val loss: 4.33845\n",
      "Main effects training epoch: 18, train loss: 4.28332, val loss: 4.32667\n",
      "Main effects training epoch: 19, train loss: 4.27180, val loss: 4.31499\n",
      "Main effects training epoch: 20, train loss: 4.26031, val loss: 4.30333\n",
      "Main effects training epoch: 21, train loss: 4.24880, val loss: 4.29165\n",
      "Main effects training epoch: 22, train loss: 4.23734, val loss: 4.28002\n",
      "Main effects training epoch: 23, train loss: 4.22590, val loss: 4.26841\n",
      "Main effects training epoch: 24, train loss: 4.21445, val loss: 4.25680\n",
      "Main effects training epoch: 25, train loss: 4.20294, val loss: 4.24513\n",
      "Main effects training epoch: 26, train loss: 4.19144, val loss: 4.23346\n",
      "Main effects training epoch: 27, train loss: 4.17986, val loss: 4.22173\n",
      "Main effects training epoch: 28, train loss: 4.16829, val loss: 4.21000\n",
      "Main effects training epoch: 29, train loss: 4.15664, val loss: 4.19819\n",
      "Main effects training epoch: 30, train loss: 4.14500, val loss: 4.18639\n",
      "Main effects training epoch: 31, train loss: 4.13323, val loss: 4.17444\n",
      "Main effects training epoch: 32, train loss: 4.12137, val loss: 4.16243\n",
      "Main effects training epoch: 33, train loss: 4.10949, val loss: 4.15035\n",
      "Main effects training epoch: 34, train loss: 4.09757, val loss: 4.13823\n",
      "Main effects training epoch: 35, train loss: 4.08559, val loss: 4.12605\n",
      "Main effects training epoch: 36, train loss: 4.07362, val loss: 4.11388\n",
      "Main effects training epoch: 37, train loss: 4.06155, val loss: 4.10162\n",
      "Main effects training epoch: 38, train loss: 4.04940, val loss: 4.08928\n",
      "Main effects training epoch: 39, train loss: 4.03713, val loss: 4.07681\n",
      "Main effects training epoch: 40, train loss: 4.02489, val loss: 4.06435\n",
      "Main effects training epoch: 41, train loss: 4.01260, val loss: 4.05190\n",
      "Main effects training epoch: 42, train loss: 4.00023, val loss: 4.03937\n",
      "Main effects training epoch: 43, train loss: 3.98771, val loss: 4.02674\n",
      "Main effects training epoch: 44, train loss: 3.97507, val loss: 4.01397\n",
      "Main effects training epoch: 45, train loss: 3.96243, val loss: 4.00122\n",
      "Main effects training epoch: 46, train loss: 3.94975, val loss: 3.98844\n",
      "Main effects training epoch: 47, train loss: 3.93698, val loss: 3.97561\n",
      "Main effects training epoch: 48, train loss: 3.92397, val loss: 3.96259\n",
      "Main effects training epoch: 49, train loss: 3.91095, val loss: 3.94956\n",
      "Main effects training epoch: 50, train loss: 3.89782, val loss: 3.93641\n",
      "Main effects training epoch: 51, train loss: 3.88457, val loss: 3.92313\n",
      "Main effects training epoch: 52, train loss: 3.87111, val loss: 3.90968\n",
      "Main effects training epoch: 53, train loss: 3.85755, val loss: 3.89610\n",
      "Main effects training epoch: 54, train loss: 3.84403, val loss: 3.88252\n",
      "Main effects training epoch: 55, train loss: 3.83052, val loss: 3.86895\n",
      "Main effects training epoch: 56, train loss: 3.81697, val loss: 3.85536\n",
      "Main effects training epoch: 57, train loss: 3.80320, val loss: 3.84155\n",
      "Main effects training epoch: 58, train loss: 3.78933, val loss: 3.82762\n",
      "Main effects training epoch: 59, train loss: 3.77541, val loss: 3.81363\n",
      "Main effects training epoch: 60, train loss: 3.76136, val loss: 3.79951\n",
      "Main effects training epoch: 61, train loss: 3.74719, val loss: 3.78524\n",
      "Main effects training epoch: 62, train loss: 3.73279, val loss: 3.77072\n",
      "Main effects training epoch: 63, train loss: 3.71814, val loss: 3.75596\n",
      "Main effects training epoch: 64, train loss: 3.70325, val loss: 3.74096\n",
      "Main effects training epoch: 65, train loss: 3.68831, val loss: 3.72588\n",
      "Main effects training epoch: 66, train loss: 3.67319, val loss: 3.71063\n",
      "Main effects training epoch: 67, train loss: 3.65792, val loss: 3.69520\n",
      "Main effects training epoch: 68, train loss: 3.64262, val loss: 3.67971\n",
      "Main effects training epoch: 69, train loss: 3.62713, val loss: 3.66402\n",
      "Main effects training epoch: 70, train loss: 3.61155, val loss: 3.64824\n",
      "Main effects training epoch: 71, train loss: 3.59584, val loss: 3.63231\n",
      "Main effects training epoch: 72, train loss: 3.58001, val loss: 3.61623\n",
      "Main effects training epoch: 73, train loss: 3.56415, val loss: 3.60010\n",
      "Main effects training epoch: 74, train loss: 3.54816, val loss: 3.58382\n",
      "Main effects training epoch: 75, train loss: 3.53189, val loss: 3.56724\n",
      "Main effects training epoch: 76, train loss: 3.51545, val loss: 3.55049\n",
      "Main effects training epoch: 77, train loss: 3.49887, val loss: 3.53358\n",
      "Main effects training epoch: 78, train loss: 3.48214, val loss: 3.51650\n",
      "Main effects training epoch: 79, train loss: 3.46534, val loss: 3.49935\n",
      "Main effects training epoch: 80, train loss: 3.44840, val loss: 3.48210\n",
      "Main effects training epoch: 81, train loss: 3.43132, val loss: 3.46470\n",
      "Main effects training epoch: 82, train loss: 3.41404, val loss: 3.44709\n",
      "Main effects training epoch: 83, train loss: 3.39672, val loss: 3.42942\n",
      "Main effects training epoch: 84, train loss: 3.37924, val loss: 3.41154\n",
      "Main effects training epoch: 85, train loss: 3.36160, val loss: 3.39347\n",
      "Main effects training epoch: 86, train loss: 3.34388, val loss: 3.37531\n",
      "Main effects training epoch: 87, train loss: 3.32598, val loss: 3.35697\n",
      "Main effects training epoch: 88, train loss: 3.30776, val loss: 3.33827\n",
      "Main effects training epoch: 89, train loss: 3.28930, val loss: 3.31934\n",
      "Main effects training epoch: 90, train loss: 3.27063, val loss: 3.30010\n",
      "Main effects training epoch: 91, train loss: 3.25165, val loss: 3.28053\n",
      "Main effects training epoch: 92, train loss: 3.23242, val loss: 3.26066\n",
      "Main effects training epoch: 93, train loss: 3.21299, val loss: 3.24061\n",
      "Main effects training epoch: 94, train loss: 3.19324, val loss: 3.22025\n",
      "Main effects training epoch: 95, train loss: 3.17325, val loss: 3.19966\n",
      "Main effects training epoch: 96, train loss: 3.15295, val loss: 3.17880\n",
      "Main effects training epoch: 97, train loss: 3.13228, val loss: 3.15763\n",
      "Main effects training epoch: 98, train loss: 3.11145, val loss: 3.13631\n",
      "Main effects training epoch: 99, train loss: 3.09066, val loss: 3.11502\n",
      "Main effects training epoch: 100, train loss: 3.06946, val loss: 3.09335\n",
      "Main effects training epoch: 101, train loss: 3.04806, val loss: 3.07151\n",
      "Main effects training epoch: 102, train loss: 3.02636, val loss: 3.04934\n",
      "Main effects training epoch: 103, train loss: 3.00430, val loss: 3.02678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 104, train loss: 2.98218, val loss: 3.00415\n",
      "Main effects training epoch: 105, train loss: 2.95982, val loss: 2.98128\n",
      "Main effects training epoch: 106, train loss: 2.93720, val loss: 2.95814\n",
      "Main effects training epoch: 107, train loss: 2.91426, val loss: 2.93462\n",
      "Main effects training epoch: 108, train loss: 2.89123, val loss: 2.91103\n",
      "Main effects training epoch: 109, train loss: 2.86817, val loss: 2.88738\n",
      "Main effects training epoch: 110, train loss: 2.84489, val loss: 2.86350\n",
      "Main effects training epoch: 111, train loss: 2.82139, val loss: 2.83940\n",
      "Main effects training epoch: 112, train loss: 2.79794, val loss: 2.81535\n",
      "Main effects training epoch: 113, train loss: 2.77431, val loss: 2.79113\n",
      "Main effects training epoch: 114, train loss: 2.75068, val loss: 2.76687\n",
      "Main effects training epoch: 115, train loss: 2.72681, val loss: 2.74232\n",
      "Main effects training epoch: 116, train loss: 2.70299, val loss: 2.71781\n",
      "Main effects training epoch: 117, train loss: 2.67927, val loss: 2.69337\n",
      "Main effects training epoch: 118, train loss: 2.65543, val loss: 2.66879\n",
      "Main effects training epoch: 119, train loss: 2.63141, val loss: 2.64400\n",
      "Main effects training epoch: 120, train loss: 2.60735, val loss: 2.61913\n",
      "Main effects training epoch: 121, train loss: 2.58333, val loss: 2.59428\n",
      "Main effects training epoch: 122, train loss: 2.55943, val loss: 2.56952\n",
      "Main effects training epoch: 123, train loss: 2.53550, val loss: 2.54479\n",
      "Main effects training epoch: 124, train loss: 2.51182, val loss: 2.52029\n",
      "Main effects training epoch: 125, train loss: 2.48819, val loss: 2.49582\n",
      "Main effects training epoch: 126, train loss: 2.46452, val loss: 2.47128\n",
      "Main effects training epoch: 127, train loss: 2.44082, val loss: 2.44670\n",
      "Main effects training epoch: 128, train loss: 2.41676, val loss: 2.42172\n",
      "Main effects training epoch: 129, train loss: 2.39262, val loss: 2.39657\n",
      "Main effects training epoch: 130, train loss: 2.36826, val loss: 2.37119\n",
      "Main effects training epoch: 131, train loss: 2.34370, val loss: 2.34556\n",
      "Main effects training epoch: 132, train loss: 2.31926, val loss: 2.32004\n",
      "Main effects training epoch: 133, train loss: 2.29487, val loss: 2.29454\n",
      "Main effects training epoch: 134, train loss: 2.27054, val loss: 2.26910\n",
      "Main effects training epoch: 135, train loss: 2.24611, val loss: 2.24350\n",
      "Main effects training epoch: 136, train loss: 2.22180, val loss: 2.21799\n",
      "Main effects training epoch: 137, train loss: 2.19754, val loss: 2.19249\n",
      "Main effects training epoch: 138, train loss: 2.17321, val loss: 2.16694\n",
      "Main effects training epoch: 139, train loss: 2.14865, val loss: 2.14112\n",
      "Main effects training epoch: 140, train loss: 2.12445, val loss: 2.11566\n",
      "Main effects training epoch: 141, train loss: 2.10035, val loss: 2.09030\n",
      "Main effects training epoch: 142, train loss: 2.07606, val loss: 2.06473\n",
      "Main effects training epoch: 143, train loss: 2.05152, val loss: 2.03887\n",
      "Main effects training epoch: 144, train loss: 2.02672, val loss: 2.01269\n",
      "Main effects training epoch: 145, train loss: 2.00165, val loss: 1.98618\n",
      "Main effects training epoch: 146, train loss: 1.97657, val loss: 1.95966\n",
      "Main effects training epoch: 147, train loss: 1.95162, val loss: 1.93327\n",
      "Main effects training epoch: 148, train loss: 1.92680, val loss: 1.90702\n",
      "Main effects training epoch: 149, train loss: 1.90225, val loss: 1.88105\n",
      "Main effects training epoch: 150, train loss: 1.87770, val loss: 1.85504\n",
      "Main effects training epoch: 151, train loss: 1.85311, val loss: 1.82896\n",
      "Main effects training epoch: 152, train loss: 1.82866, val loss: 1.80298\n",
      "Main effects training epoch: 153, train loss: 1.80398, val loss: 1.77671\n",
      "Main effects training epoch: 154, train loss: 1.77971, val loss: 1.75085\n",
      "Main effects training epoch: 155, train loss: 1.75569, val loss: 1.72521\n",
      "Main effects training epoch: 156, train loss: 1.73199, val loss: 1.69988\n",
      "Main effects training epoch: 157, train loss: 1.70832, val loss: 1.67456\n",
      "Main effects training epoch: 158, train loss: 1.68485, val loss: 1.64940\n",
      "Main effects training epoch: 159, train loss: 1.66181, val loss: 1.62465\n",
      "Main effects training epoch: 160, train loss: 1.63906, val loss: 1.60018\n",
      "Main effects training epoch: 161, train loss: 1.61629, val loss: 1.57566\n",
      "Main effects training epoch: 162, train loss: 1.59347, val loss: 1.55102\n",
      "Main effects training epoch: 163, train loss: 1.57064, val loss: 1.52632\n",
      "Main effects training epoch: 164, train loss: 1.54804, val loss: 1.50181\n",
      "Main effects training epoch: 165, train loss: 1.52587, val loss: 1.47772\n",
      "Main effects training epoch: 166, train loss: 1.50408, val loss: 1.45396\n",
      "Main effects training epoch: 167, train loss: 1.48222, val loss: 1.43008\n",
      "Main effects training epoch: 168, train loss: 1.46110, val loss: 1.40693\n",
      "Main effects training epoch: 169, train loss: 1.44019, val loss: 1.38397\n",
      "Main effects training epoch: 170, train loss: 1.41979, val loss: 1.36151\n",
      "Main effects training epoch: 171, train loss: 1.39958, val loss: 1.33921\n",
      "Main effects training epoch: 172, train loss: 1.37969, val loss: 1.31719\n",
      "Main effects training epoch: 173, train loss: 1.36019, val loss: 1.29553\n",
      "Main effects training epoch: 174, train loss: 1.34114, val loss: 1.27433\n",
      "Main effects training epoch: 175, train loss: 1.32238, val loss: 1.25337\n",
      "Main effects training epoch: 176, train loss: 1.30408, val loss: 1.23287\n",
      "Main effects training epoch: 177, train loss: 1.28648, val loss: 1.21311\n",
      "Main effects training epoch: 178, train loss: 1.26925, val loss: 1.19371\n",
      "Main effects training epoch: 179, train loss: 1.25196, val loss: 1.17415\n",
      "Main effects training epoch: 180, train loss: 1.23514, val loss: 1.15506\n",
      "Main effects training epoch: 181, train loss: 1.21866, val loss: 1.13629\n",
      "Main effects training epoch: 182, train loss: 1.20269, val loss: 1.11805\n",
      "Main effects training epoch: 183, train loss: 1.18691, val loss: 1.09994\n",
      "Main effects training epoch: 184, train loss: 1.17155, val loss: 1.08223\n",
      "Main effects training epoch: 185, train loss: 1.15686, val loss: 1.06522\n",
      "Main effects training epoch: 186, train loss: 1.14241, val loss: 1.04841\n",
      "Main effects training epoch: 187, train loss: 1.12825, val loss: 1.03184\n",
      "Main effects training epoch: 188, train loss: 1.11494, val loss: 1.01618\n",
      "Main effects training epoch: 189, train loss: 1.10243, val loss: 1.00140\n",
      "Main effects training epoch: 190, train loss: 1.09040, val loss: 0.98711\n",
      "Main effects training epoch: 191, train loss: 1.07895, val loss: 0.97345\n",
      "Main effects training epoch: 192, train loss: 1.06790, val loss: 0.96018\n",
      "Main effects training epoch: 193, train loss: 1.05723, val loss: 0.94731\n",
      "Main effects training epoch: 194, train loss: 1.04705, val loss: 0.93498\n",
      "Main effects training epoch: 195, train loss: 1.03692, val loss: 0.92261\n",
      "Main effects training epoch: 196, train loss: 1.02727, val loss: 0.91078\n",
      "Main effects training epoch: 197, train loss: 1.01809, val loss: 0.89943\n",
      "Main effects training epoch: 198, train loss: 1.00946, val loss: 0.88868\n",
      "Main effects training epoch: 199, train loss: 1.00111, val loss: 0.87818\n",
      "Main effects training epoch: 200, train loss: 0.99324, val loss: 0.86815\n",
      "Main effects training epoch: 201, train loss: 0.98576, val loss: 0.85855\n",
      "Main effects training epoch: 202, train loss: 0.97840, val loss: 0.84899\n",
      "Main effects training epoch: 203, train loss: 0.97142, val loss: 0.83981\n",
      "Main effects training epoch: 204, train loss: 0.96487, val loss: 0.83110\n",
      "Main effects training epoch: 205, train loss: 0.95850, val loss: 0.82255\n",
      "Main effects training epoch: 206, train loss: 0.95247, val loss: 0.81437\n",
      "Main effects training epoch: 207, train loss: 0.94673, val loss: 0.80649\n",
      "Main effects training epoch: 208, train loss: 0.94138, val loss: 0.79905\n",
      "Main effects training epoch: 209, train loss: 0.93650, val loss: 0.79220\n",
      "Main effects training epoch: 210, train loss: 0.93192, val loss: 0.78568\n",
      "Main effects training epoch: 211, train loss: 0.92770, val loss: 0.77959\n",
      "Main effects training epoch: 212, train loss: 0.92389, val loss: 0.77405\n",
      "Main effects training epoch: 213, train loss: 0.92037, val loss: 0.76887\n",
      "Main effects training epoch: 214, train loss: 0.91690, val loss: 0.76366\n",
      "Main effects training epoch: 215, train loss: 0.91348, val loss: 0.75840\n",
      "Main effects training epoch: 216, train loss: 0.91015, val loss: 0.75316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 217, train loss: 0.90719, val loss: 0.74846\n",
      "Main effects training epoch: 218, train loss: 0.90439, val loss: 0.74390\n",
      "Main effects training epoch: 219, train loss: 0.90184, val loss: 0.73966\n",
      "Main effects training epoch: 220, train loss: 0.89961, val loss: 0.73588\n",
      "Main effects training epoch: 221, train loss: 0.89750, val loss: 0.73215\n",
      "Main effects training epoch: 222, train loss: 0.89540, val loss: 0.72828\n",
      "Main effects training epoch: 223, train loss: 0.89357, val loss: 0.72474\n",
      "Main effects training epoch: 224, train loss: 0.89188, val loss: 0.72136\n",
      "Main effects training epoch: 225, train loss: 0.89035, val loss: 0.71819\n",
      "Main effects training epoch: 226, train loss: 0.88895, val loss: 0.71514\n",
      "Main effects training epoch: 227, train loss: 0.88775, val loss: 0.71234\n",
      "Main effects training epoch: 228, train loss: 0.88678, val loss: 0.71004\n",
      "Main effects training epoch: 229, train loss: 0.88592, val loss: 0.70785\n",
      "Main effects training epoch: 230, train loss: 0.88519, val loss: 0.70596\n",
      "Main effects training epoch: 231, train loss: 0.88462, val loss: 0.70449\n",
      "Main effects training epoch: 232, train loss: 0.88412, val loss: 0.70324\n",
      "Main effects training epoch: 233, train loss: 0.88367, val loss: 0.70210\n",
      "Main effects training epoch: 234, train loss: 0.88326, val loss: 0.70103\n",
      "Main effects training epoch: 235, train loss: 0.88289, val loss: 0.69991\n",
      "Main effects training epoch: 236, train loss: 0.88256, val loss: 0.69892\n",
      "Main effects training epoch: 237, train loss: 0.88225, val loss: 0.69807\n",
      "Main effects training epoch: 238, train loss: 0.88197, val loss: 0.69719\n",
      "Main effects training epoch: 239, train loss: 0.88170, val loss: 0.69645\n",
      "Main effects training epoch: 240, train loss: 0.88144, val loss: 0.69595\n",
      "Main effects training epoch: 241, train loss: 0.88117, val loss: 0.69558\n",
      "Main effects training epoch: 242, train loss: 0.88094, val loss: 0.69493\n",
      "Main effects training epoch: 243, train loss: 0.88071, val loss: 0.69443\n",
      "Main effects training epoch: 244, train loss: 0.88051, val loss: 0.69377\n",
      "Main effects training epoch: 245, train loss: 0.88034, val loss: 0.69311\n",
      "Main effects training epoch: 246, train loss: 0.88016, val loss: 0.69260\n",
      "Main effects training epoch: 247, train loss: 0.88000, val loss: 0.69208\n",
      "Main effects training epoch: 248, train loss: 0.87983, val loss: 0.69169\n",
      "Main effects training epoch: 249, train loss: 0.87962, val loss: 0.69144\n",
      "Main effects training epoch: 250, train loss: 0.87941, val loss: 0.69118\n",
      "Main effects training epoch: 251, train loss: 0.87922, val loss: 0.69091\n",
      "Main effects training epoch: 252, train loss: 0.87904, val loss: 0.69067\n",
      "Main effects training epoch: 253, train loss: 0.87881, val loss: 0.69058\n",
      "Main effects training epoch: 254, train loss: 0.87856, val loss: 0.69054\n",
      "Main effects training epoch: 255, train loss: 0.87830, val loss: 0.69051\n",
      "Main effects training epoch: 256, train loss: 0.87804, val loss: 0.69050\n",
      "Main effects training epoch: 257, train loss: 0.87782, val loss: 0.69038\n",
      "Main effects training epoch: 258, train loss: 0.87754, val loss: 0.69044\n",
      "Main effects training epoch: 259, train loss: 0.87726, val loss: 0.69055\n",
      "Main effects training epoch: 260, train loss: 0.87697, val loss: 0.69069\n",
      "Main effects training epoch: 261, train loss: 0.87669, val loss: 0.69083\n",
      "Main effects training epoch: 262, train loss: 0.87641, val loss: 0.69094\n",
      "Main effects training epoch: 263, train loss: 0.87614, val loss: 0.69103\n",
      "Main effects training epoch: 264, train loss: 0.87592, val loss: 0.69096\n",
      "Main effects training epoch: 265, train loss: 0.87569, val loss: 0.69087\n",
      "Main effects training epoch: 266, train loss: 0.87547, val loss: 0.69080\n",
      "Main effects training epoch: 267, train loss: 0.87523, val loss: 0.69075\n",
      "Main effects training epoch: 268, train loss: 0.87500, val loss: 0.69070\n",
      "Main effects training epoch: 269, train loss: 0.87479, val loss: 0.69060\n",
      "Main effects training epoch: 270, train loss: 0.87453, val loss: 0.69062\n",
      "Main effects training epoch: 271, train loss: 0.87429, val loss: 0.69059\n",
      "Main effects training epoch: 272, train loss: 0.87399, val loss: 0.69075\n",
      "Main effects training epoch: 273, train loss: 0.87376, val loss: 0.69072\n",
      "Main effects training epoch: 274, train loss: 0.87353, val loss: 0.69070\n",
      "Main effects training epoch: 275, train loss: 0.87329, val loss: 0.69074\n",
      "Main effects training epoch: 276, train loss: 0.87305, val loss: 0.69074\n",
      "Main effects training epoch: 277, train loss: 0.87283, val loss: 0.69069\n",
      "Main effects training epoch: 278, train loss: 0.87259, val loss: 0.69072\n",
      "Main effects training epoch: 279, train loss: 0.87234, val loss: 0.69076\n",
      "Main effects training epoch: 280, train loss: 0.87202, val loss: 0.69095\n",
      "Main effects training epoch: 281, train loss: 0.87169, val loss: 0.69118\n",
      "Main effects training epoch: 282, train loss: 0.87142, val loss: 0.69130\n",
      "Main effects training epoch: 283, train loss: 0.87116, val loss: 0.69139\n",
      "Main effects training epoch: 284, train loss: 0.87093, val loss: 0.69134\n",
      "Main effects training epoch: 285, train loss: 0.87070, val loss: 0.69132\n",
      "Main effects training epoch: 286, train loss: 0.87043, val loss: 0.69140\n",
      "Main effects training epoch: 287, train loss: 0.87017, val loss: 0.69150\n",
      "Main effects training epoch: 288, train loss: 0.86987, val loss: 0.69172\n",
      "Main effects training epoch: 289, train loss: 0.86956, val loss: 0.69198\n",
      "Main effects training epoch: 290, train loss: 0.86927, val loss: 0.69220\n",
      "Main effects training epoch: 291, train loss: 0.86894, val loss: 0.69261\n",
      "Main effects training epoch: 292, train loss: 0.86861, val loss: 0.69304\n",
      "Main effects training epoch: 293, train loss: 0.86828, val loss: 0.69363\n",
      "Main effects training epoch: 294, train loss: 0.86795, val loss: 0.69435\n",
      "Main effects training epoch: 295, train loss: 0.86763, val loss: 0.69522\n",
      "Main effects training epoch: 296, train loss: 0.86733, val loss: 0.69621\n",
      "Main effects training epoch: 297, train loss: 0.86709, val loss: 0.69718\n",
      "Main effects training epoch: 298, train loss: 0.86688, val loss: 0.69805\n",
      "Main effects training epoch: 299, train loss: 0.86670, val loss: 0.69906\n",
      "Main effects training epoch: 300, train loss: 0.86658, val loss: 0.70031\n",
      "Main effects training epoch: 301, train loss: 0.86648, val loss: 0.70140\n",
      "Main effects training epoch: 302, train loss: 0.86638, val loss: 0.70234\n",
      "Main effects training epoch: 303, train loss: 0.86626, val loss: 0.70307\n",
      "Main effects training epoch: 304, train loss: 0.86610, val loss: 0.70355\n",
      "Main effects training epoch: 305, train loss: 0.86592, val loss: 0.70393\n",
      "Main effects training epoch: 306, train loss: 0.86573, val loss: 0.70424\n",
      "Main effects training epoch: 307, train loss: 0.86556, val loss: 0.70467\n",
      "Main effects training epoch: 308, train loss: 0.86542, val loss: 0.70525\n",
      "Early stop at epoch 308, with validation loss: 0.70525\n",
      "##########Stage 1: main effect training stop.##########\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.85590, val loss: 0.68317\n",
      "Interaction training epoch: 2, train loss: 0.85456, val loss: 0.68191\n",
      "Interaction training epoch: 3, train loss: 0.85322, val loss: 0.68066\n",
      "Interaction training epoch: 4, train loss: 0.85187, val loss: 0.67901\n",
      "Interaction training epoch: 5, train loss: 0.85063, val loss: 0.67725\n",
      "Interaction training epoch: 6, train loss: 0.84945, val loss: 0.67564\n",
      "Interaction training epoch: 7, train loss: 0.84829, val loss: 0.67426\n",
      "Interaction training epoch: 8, train loss: 0.84716, val loss: 0.67334\n",
      "Interaction training epoch: 9, train loss: 0.84614, val loss: 0.67222\n",
      "Interaction training epoch: 10, train loss: 0.84506, val loss: 0.67135\n",
      "Interaction training epoch: 11, train loss: 0.84393, val loss: 0.67058\n",
      "Interaction training epoch: 12, train loss: 0.84278, val loss: 0.66999\n",
      "Interaction training epoch: 13, train loss: 0.84156, val loss: 0.66961\n",
      "Interaction training epoch: 14, train loss: 0.84031, val loss: 0.66913\n",
      "Interaction training epoch: 15, train loss: 0.83906, val loss: 0.66871\n",
      "Interaction training epoch: 16, train loss: 0.83788, val loss: 0.66841\n",
      "Interaction training epoch: 17, train loss: 0.83667, val loss: 0.66860\n",
      "Interaction training epoch: 18, train loss: 0.83552, val loss: 0.66848\n",
      "Interaction training epoch: 19, train loss: 0.83442, val loss: 0.66816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 20, train loss: 0.83334, val loss: 0.66775\n",
      "Interaction training epoch: 21, train loss: 0.83221, val loss: 0.66736\n",
      "Interaction training epoch: 22, train loss: 0.83098, val loss: 0.66718\n",
      "Interaction training epoch: 23, train loss: 0.82969, val loss: 0.66710\n",
      "Interaction training epoch: 24, train loss: 0.82834, val loss: 0.66695\n",
      "Interaction training epoch: 25, train loss: 0.82695, val loss: 0.66680\n",
      "Interaction training epoch: 26, train loss: 0.82552, val loss: 0.66678\n",
      "Interaction training epoch: 27, train loss: 0.82410, val loss: 0.66692\n",
      "Interaction training epoch: 28, train loss: 0.82268, val loss: 0.66730\n",
      "Interaction training epoch: 29, train loss: 0.82135, val loss: 0.66756\n",
      "Interaction training epoch: 30, train loss: 0.82007, val loss: 0.66740\n",
      "Interaction training epoch: 31, train loss: 0.81882, val loss: 0.66716\n",
      "Interaction training epoch: 32, train loss: 0.81753, val loss: 0.66702\n",
      "Interaction training epoch: 33, train loss: 0.81617, val loss: 0.66695\n",
      "Interaction training epoch: 34, train loss: 0.81482, val loss: 0.66676\n",
      "Interaction training epoch: 35, train loss: 0.81345, val loss: 0.66670\n",
      "Interaction training epoch: 36, train loss: 0.81212, val loss: 0.66650\n",
      "Interaction training epoch: 37, train loss: 0.81076, val loss: 0.66629\n",
      "Interaction training epoch: 38, train loss: 0.80935, val loss: 0.66641\n",
      "Interaction training epoch: 39, train loss: 0.80781, val loss: 0.66657\n",
      "Interaction training epoch: 40, train loss: 0.80627, val loss: 0.66683\n",
      "Interaction training epoch: 41, train loss: 0.80473, val loss: 0.66699\n",
      "Interaction training epoch: 42, train loss: 0.80315, val loss: 0.66702\n",
      "Interaction training epoch: 43, train loss: 0.80155, val loss: 0.66691\n",
      "Interaction training epoch: 44, train loss: 0.79995, val loss: 0.66700\n",
      "Interaction training epoch: 45, train loss: 0.79837, val loss: 0.66750\n",
      "Interaction training epoch: 46, train loss: 0.79675, val loss: 0.66793\n",
      "Interaction training epoch: 47, train loss: 0.79514, val loss: 0.66845\n",
      "Interaction training epoch: 48, train loss: 0.79344, val loss: 0.66880\n",
      "Interaction training epoch: 49, train loss: 0.79169, val loss: 0.66907\n",
      "Interaction training epoch: 50, train loss: 0.78993, val loss: 0.66941\n",
      "Interaction training epoch: 51, train loss: 0.78813, val loss: 0.66935\n",
      "Interaction training epoch: 52, train loss: 0.78636, val loss: 0.66929\n",
      "Interaction training epoch: 53, train loss: 0.78456, val loss: 0.66916\n",
      "Interaction training epoch: 54, train loss: 0.78276, val loss: 0.66858\n",
      "Interaction training epoch: 55, train loss: 0.78097, val loss: 0.66804\n",
      "Interaction training epoch: 56, train loss: 0.77917, val loss: 0.66744\n",
      "Interaction training epoch: 57, train loss: 0.77729, val loss: 0.66703\n",
      "Interaction training epoch: 58, train loss: 0.77546, val loss: 0.66631\n",
      "Interaction training epoch: 59, train loss: 0.77374, val loss: 0.66555\n",
      "Interaction training epoch: 60, train loss: 0.77207, val loss: 0.66483\n",
      "Interaction training epoch: 61, train loss: 0.77073, val loss: 0.66361\n",
      "Interaction training epoch: 62, train loss: 0.76915, val loss: 0.66283\n",
      "Interaction training epoch: 63, train loss: 0.76737, val loss: 0.66232\n",
      "Interaction training epoch: 64, train loss: 0.76551, val loss: 0.66198\n",
      "Interaction training epoch: 65, train loss: 0.76337, val loss: 0.66215\n",
      "Interaction training epoch: 66, train loss: 0.76109, val loss: 0.66278\n",
      "Interaction training epoch: 67, train loss: 0.75888, val loss: 0.66341\n",
      "Interaction training epoch: 68, train loss: 0.75672, val loss: 0.66401\n",
      "Interaction training epoch: 69, train loss: 0.75451, val loss: 0.66457\n",
      "Interaction training epoch: 70, train loss: 0.75234, val loss: 0.66518\n",
      "Interaction training epoch: 71, train loss: 0.75014, val loss: 0.66588\n",
      "Interaction training epoch: 72, train loss: 0.74800, val loss: 0.66672\n",
      "Interaction training epoch: 73, train loss: 0.74588, val loss: 0.66766\n",
      "Interaction training epoch: 74, train loss: 0.74369, val loss: 0.66802\n",
      "Interaction training epoch: 75, train loss: 0.74152, val loss: 0.66824\n",
      "Interaction training epoch: 76, train loss: 0.73944, val loss: 0.66854\n",
      "Interaction training epoch: 77, train loss: 0.73739, val loss: 0.66887\n",
      "Interaction training epoch: 78, train loss: 0.73531, val loss: 0.66940\n",
      "Interaction training epoch: 79, train loss: 0.73310, val loss: 0.66962\n",
      "Interaction training epoch: 80, train loss: 0.73067, val loss: 0.66924\n",
      "Interaction training epoch: 81, train loss: 0.72816, val loss: 0.66839\n",
      "Interaction training epoch: 82, train loss: 0.72568, val loss: 0.66741\n",
      "Interaction training epoch: 83, train loss: 0.72329, val loss: 0.66661\n",
      "Interaction training epoch: 84, train loss: 0.72094, val loss: 0.66605\n",
      "Interaction training epoch: 85, train loss: 0.71862, val loss: 0.66537\n",
      "Interaction training epoch: 86, train loss: 0.71627, val loss: 0.66456\n",
      "Interaction training epoch: 87, train loss: 0.71413, val loss: 0.66326\n",
      "Interaction training epoch: 88, train loss: 0.71175, val loss: 0.66272\n",
      "Interaction training epoch: 89, train loss: 0.70927, val loss: 0.66266\n",
      "Interaction training epoch: 90, train loss: 0.70675, val loss: 0.66256\n",
      "Interaction training epoch: 91, train loss: 0.70412, val loss: 0.66295\n",
      "Interaction training epoch: 92, train loss: 0.70161, val loss: 0.66292\n",
      "Interaction training epoch: 93, train loss: 0.69909, val loss: 0.66274\n",
      "Interaction training epoch: 94, train loss: 0.69645, val loss: 0.66308\n",
      "Interaction training epoch: 95, train loss: 0.69379, val loss: 0.66339\n",
      "Interaction training epoch: 96, train loss: 0.69102, val loss: 0.66441\n",
      "Interaction training epoch: 97, train loss: 0.68826, val loss: 0.66539\n",
      "Interaction training epoch: 98, train loss: 0.68555, val loss: 0.66646\n",
      "Interaction training epoch: 99, train loss: 0.68292, val loss: 0.66743\n",
      "Interaction training epoch: 100, train loss: 0.68022, val loss: 0.66833\n",
      "Interaction training epoch: 101, train loss: 0.67753, val loss: 0.66956\n",
      "Interaction training epoch: 102, train loss: 0.67491, val loss: 0.67108\n",
      "Interaction training epoch: 103, train loss: 0.67234, val loss: 0.67262\n",
      "Interaction training epoch: 104, train loss: 0.66971, val loss: 0.67398\n",
      "Interaction training epoch: 105, train loss: 0.66682, val loss: 0.67471\n",
      "Interaction training epoch: 106, train loss: 0.66386, val loss: 0.67515\n",
      "Interaction training epoch: 107, train loss: 0.66070, val loss: 0.67462\n",
      "Interaction training epoch: 108, train loss: 0.65755, val loss: 0.67350\n",
      "Interaction training epoch: 109, train loss: 0.65449, val loss: 0.67234\n",
      "Interaction training epoch: 110, train loss: 0.65152, val loss: 0.67044\n",
      "Interaction training epoch: 111, train loss: 0.64878, val loss: 0.66828\n",
      "Interaction training epoch: 112, train loss: 0.64626, val loss: 0.66601\n",
      "Interaction training epoch: 113, train loss: 0.64372, val loss: 0.66430\n",
      "Interaction training epoch: 114, train loss: 0.64110, val loss: 0.66320\n",
      "Interaction training epoch: 115, train loss: 0.63828, val loss: 0.66257\n",
      "Early stop at epoch 115, with validation loss: 0.66257\n",
      "##########Stage 2: interaction training stop.##########\n",
      "Fine tuning epoch: 1, train loss: 0.77899, val loss: 0.64802\n",
      "Fine tuning epoch: 2, train loss: 0.77786, val loss: 0.64786\n",
      "Fine tuning epoch: 3, train loss: 0.77670, val loss: 0.64777\n",
      "Fine tuning epoch: 4, train loss: 0.77536, val loss: 0.64787\n",
      "Fine tuning epoch: 5, train loss: 0.77403, val loss: 0.64785\n",
      "Fine tuning epoch: 6, train loss: 0.77270, val loss: 0.64788\n",
      "Fine tuning epoch: 7, train loss: 0.77144, val loss: 0.64785\n",
      "Fine tuning epoch: 8, train loss: 0.77024, val loss: 0.64772\n",
      "Fine tuning epoch: 9, train loss: 0.76904, val loss: 0.64747\n",
      "Fine tuning epoch: 10, train loss: 0.76771, val loss: 0.64738\n",
      "Fine tuning epoch: 11, train loss: 0.76635, val loss: 0.64738\n",
      "Fine tuning epoch: 12, train loss: 0.76495, val loss: 0.64740\n",
      "Fine tuning epoch: 13, train loss: 0.76350, val loss: 0.64761\n",
      "Fine tuning epoch: 14, train loss: 0.76205, val loss: 0.64763\n",
      "Fine tuning epoch: 15, train loss: 0.76061, val loss: 0.64754\n",
      "Fine tuning epoch: 16, train loss: 0.75925, val loss: 0.64712\n",
      "Fine tuning epoch: 17, train loss: 0.75778, val loss: 0.64701\n",
      "Fine tuning epoch: 18, train loss: 0.75634, val loss: 0.64711\n",
      "Fine tuning epoch: 19, train loss: 0.75488, val loss: 0.64727\n",
      "Fine tuning epoch: 20, train loss: 0.75344, val loss: 0.64736\n",
      "Fine tuning epoch: 21, train loss: 0.75201, val loss: 0.64716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning epoch: 22, train loss: 0.75056, val loss: 0.64700\n",
      "Fine tuning epoch: 23, train loss: 0.74918, val loss: 0.64660\n",
      "Fine tuning epoch: 24, train loss: 0.74778, val loss: 0.64635\n",
      "Fine tuning epoch: 25, train loss: 0.74642, val loss: 0.64592\n",
      "Fine tuning epoch: 26, train loss: 0.74510, val loss: 0.64522\n",
      "Fine tuning epoch: 27, train loss: 0.74366, val loss: 0.64467\n",
      "Fine tuning epoch: 28, train loss: 0.74216, val loss: 0.64441\n",
      "Fine tuning epoch: 29, train loss: 0.74066, val loss: 0.64415\n",
      "Fine tuning epoch: 30, train loss: 0.73919, val loss: 0.64387\n",
      "Fine tuning epoch: 31, train loss: 0.73767, val loss: 0.64358\n",
      "Fine tuning epoch: 32, train loss: 0.73616, val loss: 0.64351\n",
      "Fine tuning epoch: 33, train loss: 0.73465, val loss: 0.64341\n",
      "Fine tuning epoch: 34, train loss: 0.73316, val loss: 0.64346\n",
      "Fine tuning epoch: 35, train loss: 0.73168, val loss: 0.64318\n",
      "Fine tuning epoch: 36, train loss: 0.73010, val loss: 0.64309\n",
      "Fine tuning epoch: 37, train loss: 0.72846, val loss: 0.64310\n",
      "Fine tuning epoch: 38, train loss: 0.72677, val loss: 0.64307\n",
      "Fine tuning epoch: 39, train loss: 0.72504, val loss: 0.64302\n",
      "Fine tuning epoch: 40, train loss: 0.72334, val loss: 0.64313\n",
      "Fine tuning epoch: 41, train loss: 0.72171, val loss: 0.64319\n",
      "Fine tuning epoch: 42, train loss: 0.72002, val loss: 0.64336\n",
      "Fine tuning epoch: 43, train loss: 0.71838, val loss: 0.64376\n",
      "Fine tuning epoch: 44, train loss: 0.71670, val loss: 0.64381\n",
      "Fine tuning epoch: 45, train loss: 0.71498, val loss: 0.64363\n",
      "Fine tuning epoch: 46, train loss: 0.71323, val loss: 0.64333\n",
      "Fine tuning epoch: 47, train loss: 0.71146, val loss: 0.64330\n",
      "Fine tuning epoch: 48, train loss: 0.70960, val loss: 0.64342\n",
      "Fine tuning epoch: 49, train loss: 0.70775, val loss: 0.64302\n",
      "Fine tuning epoch: 50, train loss: 0.70591, val loss: 0.64256\n",
      "Fine tuning epoch: 51, train loss: 0.70417, val loss: 0.64219\n",
      "Fine tuning epoch: 52, train loss: 0.70245, val loss: 0.64182\n",
      "Fine tuning epoch: 53, train loss: 0.70070, val loss: 0.64185\n",
      "Fine tuning epoch: 54, train loss: 0.69895, val loss: 0.64148\n",
      "Fine tuning epoch: 55, train loss: 0.69722, val loss: 0.64113\n",
      "Fine tuning epoch: 56, train loss: 0.69549, val loss: 0.64016\n",
      "Fine tuning epoch: 57, train loss: 0.69382, val loss: 0.63912\n",
      "Fine tuning epoch: 58, train loss: 0.69207, val loss: 0.63867\n",
      "Fine tuning epoch: 59, train loss: 0.69023, val loss: 0.63856\n",
      "Fine tuning epoch: 60, train loss: 0.68840, val loss: 0.63829\n",
      "Fine tuning epoch: 61, train loss: 0.68659, val loss: 0.63787\n",
      "Fine tuning epoch: 62, train loss: 0.68470, val loss: 0.63765\n",
      "Fine tuning epoch: 63, train loss: 0.68279, val loss: 0.63758\n",
      "Fine tuning epoch: 64, train loss: 0.68083, val loss: 0.63772\n",
      "Fine tuning epoch: 65, train loss: 0.67882, val loss: 0.63783\n",
      "Fine tuning epoch: 66, train loss: 0.67688, val loss: 0.63801\n",
      "Fine tuning epoch: 67, train loss: 0.67494, val loss: 0.63822\n",
      "Fine tuning epoch: 68, train loss: 0.67305, val loss: 0.63806\n",
      "Fine tuning epoch: 69, train loss: 0.67113, val loss: 0.63732\n",
      "Fine tuning epoch: 70, train loss: 0.66922, val loss: 0.63679\n",
      "Fine tuning epoch: 71, train loss: 0.66736, val loss: 0.63633\n",
      "Fine tuning epoch: 72, train loss: 0.66553, val loss: 0.63582\n",
      "Fine tuning epoch: 73, train loss: 0.66387, val loss: 0.63474\n",
      "Fine tuning epoch: 74, train loss: 0.66217, val loss: 0.63382\n",
      "Fine tuning epoch: 75, train loss: 0.66042, val loss: 0.63324\n",
      "Fine tuning epoch: 76, train loss: 0.65867, val loss: 0.63278\n",
      "Fine tuning epoch: 77, train loss: 0.65713, val loss: 0.63181\n",
      "Fine tuning epoch: 78, train loss: 0.65584, val loss: 0.63053\n",
      "Fine tuning epoch: 79, train loss: 0.65452, val loss: 0.62946\n",
      "Fine tuning epoch: 80, train loss: 0.65312, val loss: 0.62862\n",
      "Fine tuning epoch: 81, train loss: 0.65171, val loss: 0.62798\n",
      "Fine tuning epoch: 82, train loss: 0.65011, val loss: 0.62767\n",
      "Fine tuning epoch: 83, train loss: 0.64839, val loss: 0.62746\n",
      "Fine tuning epoch: 84, train loss: 0.64663, val loss: 0.62750\n",
      "Fine tuning epoch: 85, train loss: 0.64492, val loss: 0.62742\n",
      "Fine tuning epoch: 86, train loss: 0.64330, val loss: 0.62734\n",
      "Fine tuning epoch: 87, train loss: 0.64164, val loss: 0.62727\n",
      "Fine tuning epoch: 88, train loss: 0.63983, val loss: 0.62743\n",
      "Fine tuning epoch: 89, train loss: 0.63800, val loss: 0.62762\n",
      "Fine tuning epoch: 90, train loss: 0.63637, val loss: 0.62744\n",
      "Fine tuning epoch: 91, train loss: 0.63444, val loss: 0.62785\n",
      "Fine tuning epoch: 92, train loss: 0.63237, val loss: 0.62850\n",
      "Fine tuning epoch: 93, train loss: 0.63035, val loss: 0.62923\n",
      "Fine tuning epoch: 94, train loss: 0.62838, val loss: 0.63000\n",
      "Fine tuning epoch: 95, train loss: 0.62654, val loss: 0.63059\n",
      "Fine tuning epoch: 96, train loss: 0.62458, val loss: 0.63152\n",
      "Fine tuning epoch: 97, train loss: 0.62260, val loss: 0.63253\n",
      "Fine tuning epoch: 98, train loss: 0.62068, val loss: 0.63346\n",
      "Fine tuning epoch: 99, train loss: 0.61889, val loss: 0.63393\n",
      "Fine tuning epoch: 100, train loss: 0.61713, val loss: 0.63431\n",
      "Fine tuning epoch: 101, train loss: 0.61531, val loss: 0.63508\n",
      "Fine tuning epoch: 102, train loss: 0.61361, val loss: 0.63560\n",
      "Fine tuning epoch: 103, train loss: 0.61204, val loss: 0.63608\n",
      "Fine tuning epoch: 104, train loss: 0.61045, val loss: 0.63672\n",
      "Fine tuning epoch: 105, train loss: 0.60874, val loss: 0.63773\n",
      "Fine tuning epoch: 106, train loss: 0.60731, val loss: 0.63834\n",
      "Fine tuning epoch: 107, train loss: 0.60571, val loss: 0.63923\n",
      "Fine tuning epoch: 108, train loss: 0.60399, val loss: 0.64047\n",
      "Fine tuning epoch: 109, train loss: 0.60235, val loss: 0.64188\n",
      "Fine tuning epoch: 110, train loss: 0.60094, val loss: 0.64317\n",
      "Fine tuning epoch: 111, train loss: 0.59969, val loss: 0.64447\n",
      "Fine tuning epoch: 112, train loss: 0.59850, val loss: 0.64566\n",
      "Fine tuning epoch: 113, train loss: 0.59737, val loss: 0.64672\n",
      "Fine tuning epoch: 114, train loss: 0.59631, val loss: 0.64812\n",
      "Fine tuning epoch: 115, train loss: 0.59518, val loss: 0.64939\n",
      "Fine tuning epoch: 116, train loss: 0.59396, val loss: 0.65054\n",
      "Fine tuning epoch: 117, train loss: 0.59273, val loss: 0.65125\n",
      "Fine tuning epoch: 118, train loss: 0.59144, val loss: 0.65204\n",
      "Fine tuning epoch: 119, train loss: 0.59020, val loss: 0.65261\n",
      "Fine tuning epoch: 120, train loss: 0.58905, val loss: 0.65328\n",
      "Fine tuning epoch: 121, train loss: 0.58801, val loss: 0.65455\n",
      "Fine tuning epoch: 122, train loss: 0.58694, val loss: 0.65566\n",
      "Fine tuning epoch: 123, train loss: 0.58591, val loss: 0.65747\n",
      "Fine tuning epoch: 124, train loss: 0.58499, val loss: 0.66000\n",
      "Fine tuning epoch: 125, train loss: 0.58404, val loss: 0.66155\n",
      "Fine tuning epoch: 126, train loss: 0.58308, val loss: 0.66274\n",
      "Fine tuning epoch: 127, train loss: 0.58203, val loss: 0.66354\n",
      "Fine tuning epoch: 128, train loss: 0.58091, val loss: 0.66404\n",
      "Fine tuning epoch: 129, train loss: 0.57989, val loss: 0.66434\n",
      "Fine tuning epoch: 130, train loss: 0.57905, val loss: 0.66556\n",
      "Fine tuning epoch: 131, train loss: 0.57831, val loss: 0.66649\n",
      "Fine tuning epoch: 132, train loss: 0.57748, val loss: 0.66812\n",
      "Fine tuning epoch: 133, train loss: 0.57679, val loss: 0.66873\n",
      "Fine tuning epoch: 134, train loss: 0.57603, val loss: 0.66959\n",
      "Fine tuning epoch: 135, train loss: 0.57538, val loss: 0.67025\n",
      "Fine tuning epoch: 136, train loss: 0.57489, val loss: 0.67019\n",
      "Fine tuning epoch: 137, train loss: 0.57435, val loss: 0.67051\n",
      "Fine tuning epoch: 138, train loss: 0.57354, val loss: 0.67169\n",
      "Early stop at epoch 138, with validation loss: 0.67169\n",
      "####################GAMI-Net training finished.####################\n",
      "Train: MSE: 0.5735358337708326\n",
      "Val: MSE: 0.6716876330156157\n",
      "[ 7 10]\n",
      "[[4 6]\n",
      " [2 6]]\n",
      "\u001b[32m[I 2024-02-10 11:26:27,195]\u001b[0m Trial 1 finished with value: 0.6716876330156157 and parameters: {'num_of_interactions': 35}. Best is trial 1 with value: 0.6716876330156157.\u001b[0m\n",
      "Number of finished trials: 2\n",
      "Best trial:\n",
      "  Value: 0.6716876330156157\n",
      "  Params: \n",
      "    num_of_interactions: 35\n",
      "Training completed in 00:05:43.33 for 2 trials\n",
      "0\n",
      "                               val-0\n",
      "params_num_of_interactions          \n",
      "15                          0.665445\n",
      "35                          0.826518\n",
      "1\n",
      "                               val-0     val-1\n",
      "params_num_of_interactions                    \n",
      "15                          0.665445  0.769552\n",
      "35                          0.826518  0.671688\n",
      "   params_num_of_interactions         0\n",
      "0                          15  0.717499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53 92 78 13  7 30 22 24 33  8 43 62  3 71 45 48  6 99 82 76 60 80 90 68\n",
      " 51 27 18 56 63 74  1 61 42 41  4 15 17 40 38  5 91 59  0 34 28 50 11 35\n",
      " 23 52 10 31 66 57 79 85 32 84 14 89 19 29 49 97 98 69 20 94 72 77 25 37\n",
      " 81 46 39 65 58 12 88 70 87 36 21 83  9 96 67 64 47 44]\n",
      "[26 86  2 55 75 93 16 73 54 95]\n",
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 4.66816, val loss: 3.46710\n",
      "Main effects training epoch: 2, train loss: 4.64648, val loss: 3.44799\n",
      "Main effects training epoch: 3, train loss: 4.62509, val loss: 3.42921\n",
      "Main effects training epoch: 4, train loss: 4.60391, val loss: 3.41064\n",
      "Main effects training epoch: 5, train loss: 4.58300, val loss: 3.39225\n",
      "Main effects training epoch: 6, train loss: 4.56246, val loss: 3.37423\n",
      "Main effects training epoch: 7, train loss: 4.54215, val loss: 3.35642\n",
      "Main effects training epoch: 8, train loss: 4.52217, val loss: 3.33888\n",
      "Main effects training epoch: 9, train loss: 4.50234, val loss: 3.32132\n",
      "Main effects training epoch: 10, train loss: 4.48273, val loss: 3.30392\n",
      "Main effects training epoch: 11, train loss: 4.46291, val loss: 3.28629\n",
      "Main effects training epoch: 12, train loss: 4.44330, val loss: 3.26882\n",
      "Main effects training epoch: 13, train loss: 4.42388, val loss: 3.25146\n",
      "Main effects training epoch: 14, train loss: 4.40459, val loss: 3.23420\n",
      "Main effects training epoch: 15, train loss: 4.38541, val loss: 3.21713\n",
      "Main effects training epoch: 16, train loss: 4.36608, val loss: 3.19997\n",
      "Main effects training epoch: 17, train loss: 4.34657, val loss: 3.18268\n",
      "Main effects training epoch: 18, train loss: 4.32691, val loss: 3.16525\n",
      "Main effects training epoch: 19, train loss: 4.30689, val loss: 3.14755\n",
      "Main effects training epoch: 20, train loss: 4.28653, val loss: 3.12956\n",
      "Main effects training epoch: 21, train loss: 4.26612, val loss: 3.11159\n",
      "Main effects training epoch: 22, train loss: 4.24548, val loss: 3.09341\n",
      "Main effects training epoch: 23, train loss: 4.22469, val loss: 3.07517\n",
      "Main effects training epoch: 24, train loss: 4.20362, val loss: 3.05660\n",
      "Main effects training epoch: 25, train loss: 4.18213, val loss: 3.03768\n",
      "Main effects training epoch: 26, train loss: 4.16036, val loss: 3.01847\n",
      "Main effects training epoch: 27, train loss: 4.13810, val loss: 2.99875\n",
      "Main effects training epoch: 28, train loss: 4.11556, val loss: 2.97877\n",
      "Main effects training epoch: 29, train loss: 4.09230, val loss: 2.95826\n",
      "Main effects training epoch: 30, train loss: 4.06840, val loss: 2.93731\n",
      "Main effects training epoch: 31, train loss: 4.04408, val loss: 2.91588\n",
      "Main effects training epoch: 32, train loss: 4.01925, val loss: 2.89405\n",
      "Main effects training epoch: 33, train loss: 3.99407, val loss: 2.87192\n",
      "Main effects training epoch: 34, train loss: 3.96815, val loss: 2.84927\n",
      "Main effects training epoch: 35, train loss: 3.94158, val loss: 2.82610\n",
      "Main effects training epoch: 36, train loss: 3.91443, val loss: 2.80236\n",
      "Main effects training epoch: 37, train loss: 3.88676, val loss: 2.77819\n",
      "Main effects training epoch: 38, train loss: 3.85857, val loss: 2.75361\n",
      "Main effects training epoch: 39, train loss: 3.82967, val loss: 2.72844\n",
      "Main effects training epoch: 40, train loss: 3.80026, val loss: 2.70280\n",
      "Main effects training epoch: 41, train loss: 3.77055, val loss: 2.67694\n",
      "Main effects training epoch: 42, train loss: 3.74042, val loss: 2.65079\n",
      "Main effects training epoch: 43, train loss: 3.70972, val loss: 2.62423\n",
      "Main effects training epoch: 44, train loss: 3.67869, val loss: 2.59740\n",
      "Main effects training epoch: 45, train loss: 3.64706, val loss: 2.57010\n",
      "Main effects training epoch: 46, train loss: 3.61495, val loss: 2.54237\n",
      "Main effects training epoch: 47, train loss: 3.58230, val loss: 2.51420\n",
      "Main effects training epoch: 48, train loss: 3.54887, val loss: 2.48537\n",
      "Main effects training epoch: 49, train loss: 3.51491, val loss: 2.45615\n",
      "Main effects training epoch: 50, train loss: 3.48055, val loss: 2.42663\n",
      "Main effects training epoch: 51, train loss: 3.44582, val loss: 2.39680\n",
      "Main effects training epoch: 52, train loss: 3.41081, val loss: 2.36679\n",
      "Main effects training epoch: 53, train loss: 3.37508, val loss: 2.33625\n",
      "Main effects training epoch: 54, train loss: 3.33874, val loss: 2.30527\n",
      "Main effects training epoch: 55, train loss: 3.30169, val loss: 2.27380\n",
      "Main effects training epoch: 56, train loss: 3.26356, val loss: 2.24124\n",
      "Main effects training epoch: 57, train loss: 3.22491, val loss: 2.20820\n",
      "Main effects training epoch: 58, train loss: 3.18558, val loss: 2.17468\n",
      "Main effects training epoch: 59, train loss: 3.14564, val loss: 2.14076\n",
      "Main effects training epoch: 60, train loss: 3.10504, val loss: 2.10633\n",
      "Main effects training epoch: 61, train loss: 3.06383, val loss: 2.07138\n",
      "Main effects training epoch: 62, train loss: 3.02149, val loss: 2.03557\n",
      "Main effects training epoch: 63, train loss: 2.97818, val loss: 1.99876\n",
      "Main effects training epoch: 64, train loss: 2.93415, val loss: 1.96133\n",
      "Main effects training epoch: 65, train loss: 2.88935, val loss: 1.92343\n",
      "Main effects training epoch: 66, train loss: 2.84404, val loss: 1.88531\n",
      "Main effects training epoch: 67, train loss: 2.79810, val loss: 1.84674\n",
      "Main effects training epoch: 68, train loss: 2.75187, val loss: 1.80801\n",
      "Main effects training epoch: 69, train loss: 2.70486, val loss: 1.76871\n",
      "Main effects training epoch: 70, train loss: 2.65742, val loss: 1.72921\n",
      "Main effects training epoch: 71, train loss: 2.60926, val loss: 1.68923\n",
      "Main effects training epoch: 72, train loss: 2.56119, val loss: 1.64945\n",
      "Main effects training epoch: 73, train loss: 2.51258, val loss: 1.60939\n",
      "Main effects training epoch: 74, train loss: 2.46358, val loss: 1.56915\n",
      "Main effects training epoch: 75, train loss: 2.41472, val loss: 1.52916\n",
      "Main effects training epoch: 76, train loss: 2.36535, val loss: 1.48890\n",
      "Main effects training epoch: 77, train loss: 2.31503, val loss: 1.44800\n",
      "Main effects training epoch: 78, train loss: 2.26491, val loss: 1.40739\n",
      "Main effects training epoch: 79, train loss: 2.21469, val loss: 1.36690\n",
      "Main effects training epoch: 80, train loss: 2.16407, val loss: 1.32631\n",
      "Main effects training epoch: 81, train loss: 2.11376, val loss: 1.28619\n",
      "Main effects training epoch: 82, train loss: 2.06329, val loss: 1.24618\n",
      "Main effects training epoch: 83, train loss: 2.01285, val loss: 1.20638\n",
      "Main effects training epoch: 84, train loss: 1.96240, val loss: 1.16681\n",
      "Main effects training epoch: 85, train loss: 1.91196, val loss: 1.12749\n",
      "Main effects training epoch: 86, train loss: 1.86084, val loss: 1.08800\n",
      "Main effects training epoch: 87, train loss: 1.81070, val loss: 1.04956\n",
      "Main effects training epoch: 88, train loss: 1.76094, val loss: 1.01167\n",
      "Main effects training epoch: 89, train loss: 1.71228, val loss: 0.97495\n",
      "Main effects training epoch: 90, train loss: 1.66416, val loss: 0.93896\n",
      "Main effects training epoch: 91, train loss: 1.61703, val loss: 0.90405\n",
      "Main effects training epoch: 92, train loss: 1.57056, val loss: 0.87005\n",
      "Main effects training epoch: 93, train loss: 1.52532, val loss: 0.83738\n",
      "Main effects training epoch: 94, train loss: 1.48086, val loss: 0.80571\n",
      "Main effects training epoch: 95, train loss: 1.43716, val loss: 0.77503\n",
      "Main effects training epoch: 96, train loss: 1.39468, val loss: 0.74573\n",
      "Main effects training epoch: 97, train loss: 1.35389, val loss: 0.71814\n",
      "Main effects training epoch: 98, train loss: 1.31502, val loss: 0.69242\n",
      "Main effects training epoch: 99, train loss: 1.27839, val loss: 0.66874\n",
      "Main effects training epoch: 100, train loss: 1.24306, val loss: 0.64647\n",
      "Main effects training epoch: 101, train loss: 1.20919, val loss: 0.62568\n",
      "Main effects training epoch: 102, train loss: 1.17886, val loss: 0.60763\n",
      "Main effects training epoch: 103, train loss: 1.14979, val loss: 0.59092\n",
      "Main effects training epoch: 104, train loss: 1.12158, val loss: 0.57532\n",
      "Main effects training epoch: 105, train loss: 1.09452, val loss: 0.56099\n",
      "Main effects training epoch: 106, train loss: 1.06905, val loss: 0.54821\n",
      "Main effects training epoch: 107, train loss: 1.04600, val loss: 0.53735\n",
      "Main effects training epoch: 108, train loss: 1.02449, val loss: 0.52794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 109, train loss: 1.00411, val loss: 0.51977\n",
      "Main effects training epoch: 110, train loss: 0.98615, val loss: 0.51332\n",
      "Main effects training epoch: 111, train loss: 0.96956, val loss: 0.50809\n",
      "Main effects training epoch: 112, train loss: 0.95448, val loss: 0.50407\n",
      "Main effects training epoch: 113, train loss: 0.94002, val loss: 0.50103\n",
      "Main effects training epoch: 114, train loss: 0.92786, val loss: 0.49923\n",
      "Main effects training epoch: 115, train loss: 0.91674, val loss: 0.49836\n",
      "Main effects training epoch: 116, train loss: 0.90761, val loss: 0.49832\n",
      "Main effects training epoch: 117, train loss: 0.89903, val loss: 0.49906\n",
      "Main effects training epoch: 118, train loss: 0.89185, val loss: 0.50034\n",
      "Main effects training epoch: 119, train loss: 0.88578, val loss: 0.50202\n",
      "Main effects training epoch: 120, train loss: 0.88025, val loss: 0.50417\n",
      "Main effects training epoch: 121, train loss: 0.87551, val loss: 0.50658\n",
      "Main effects training epoch: 122, train loss: 0.87125, val loss: 0.50941\n",
      "Main effects training epoch: 123, train loss: 0.86752, val loss: 0.51248\n",
      "Main effects training epoch: 124, train loss: 0.86418, val loss: 0.51596\n",
      "Main effects training epoch: 125, train loss: 0.86138, val loss: 0.51953\n",
      "Main effects training epoch: 126, train loss: 0.85901, val loss: 0.52308\n",
      "Main effects training epoch: 127, train loss: 0.85691, val loss: 0.52685\n",
      "Main effects training epoch: 128, train loss: 0.85514, val loss: 0.53066\n",
      "Main effects training epoch: 129, train loss: 0.85361, val loss: 0.53477\n",
      "Main effects training epoch: 130, train loss: 0.85235, val loss: 0.53880\n",
      "Main effects training epoch: 131, train loss: 0.85132, val loss: 0.54215\n",
      "Main effects training epoch: 132, train loss: 0.85040, val loss: 0.54485\n",
      "Main effects training epoch: 133, train loss: 0.84952, val loss: 0.54681\n",
      "Main effects training epoch: 134, train loss: 0.84866, val loss: 0.54820\n",
      "Main effects training epoch: 135, train loss: 0.84779, val loss: 0.54819\n",
      "Main effects training epoch: 136, train loss: 0.84699, val loss: 0.54841\n",
      "Main effects training epoch: 137, train loss: 0.84624, val loss: 0.54921\n",
      "Main effects training epoch: 138, train loss: 0.84549, val loss: 0.54901\n",
      "Main effects training epoch: 139, train loss: 0.84475, val loss: 0.54889\n",
      "Main effects training epoch: 140, train loss: 0.84400, val loss: 0.54856\n",
      "Main effects training epoch: 141, train loss: 0.84324, val loss: 0.54843\n",
      "Main effects training epoch: 142, train loss: 0.84248, val loss: 0.54888\n",
      "Main effects training epoch: 143, train loss: 0.84178, val loss: 0.54934\n",
      "Main effects training epoch: 144, train loss: 0.84107, val loss: 0.54968\n",
      "Main effects training epoch: 145, train loss: 0.84033, val loss: 0.54927\n",
      "Main effects training epoch: 146, train loss: 0.83960, val loss: 0.54829\n",
      "Main effects training epoch: 147, train loss: 0.83886, val loss: 0.54778\n",
      "Main effects training epoch: 148, train loss: 0.83814, val loss: 0.54632\n",
      "Main effects training epoch: 149, train loss: 0.83743, val loss: 0.54578\n",
      "Main effects training epoch: 150, train loss: 0.83669, val loss: 0.54561\n",
      "Main effects training epoch: 151, train loss: 0.83595, val loss: 0.54510\n",
      "Main effects training epoch: 152, train loss: 0.83514, val loss: 0.54585\n",
      "Main effects training epoch: 153, train loss: 0.83435, val loss: 0.54645\n",
      "Main effects training epoch: 154, train loss: 0.83360, val loss: 0.54737\n",
      "Main effects training epoch: 155, train loss: 0.83281, val loss: 0.54685\n",
      "Main effects training epoch: 156, train loss: 0.83197, val loss: 0.54681\n",
      "Main effects training epoch: 157, train loss: 0.83115, val loss: 0.54702\n",
      "Main effects training epoch: 158, train loss: 0.83025, val loss: 0.54644\n",
      "Main effects training epoch: 159, train loss: 0.82931, val loss: 0.54646\n",
      "Main effects training epoch: 160, train loss: 0.82839, val loss: 0.54687\n",
      "Main effects training epoch: 161, train loss: 0.82745, val loss: 0.54591\n",
      "Main effects training epoch: 162, train loss: 0.82657, val loss: 0.54457\n",
      "Main effects training epoch: 163, train loss: 0.82582, val loss: 0.54329\n",
      "Main effects training epoch: 164, train loss: 0.82514, val loss: 0.54182\n",
      "Main effects training epoch: 165, train loss: 0.82449, val loss: 0.53923\n",
      "Main effects training epoch: 166, train loss: 0.82388, val loss: 0.53669\n",
      "Main effects training epoch: 167, train loss: 0.82328, val loss: 0.53492\n",
      "Early stop at epoch 167, with validation loss: 0.53492\n",
      "##########Stage 1: main effect training stop.##########\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.76214, val loss: 0.50120\n",
      "Interaction training epoch: 2, train loss: 0.76090, val loss: 0.49477\n",
      "Interaction training epoch: 3, train loss: 0.75947, val loss: 0.49104\n",
      "Interaction training epoch: 4, train loss: 0.75741, val loss: 0.49278\n",
      "Interaction training epoch: 5, train loss: 0.75553, val loss: 0.49415\n",
      "Interaction training epoch: 6, train loss: 0.75386, val loss: 0.49474\n",
      "Interaction training epoch: 7, train loss: 0.75230, val loss: 0.49397\n",
      "Interaction training epoch: 8, train loss: 0.75072, val loss: 0.49461\n",
      "Interaction training epoch: 9, train loss: 0.74917, val loss: 0.49601\n",
      "Interaction training epoch: 10, train loss: 0.74761, val loss: 0.49620\n",
      "Interaction training epoch: 11, train loss: 0.74597, val loss: 0.49595\n",
      "Interaction training epoch: 12, train loss: 0.74426, val loss: 0.49570\n",
      "Interaction training epoch: 13, train loss: 0.74252, val loss: 0.49617\n",
      "Interaction training epoch: 14, train loss: 0.74078, val loss: 0.49623\n",
      "Interaction training epoch: 15, train loss: 0.73896, val loss: 0.49645\n",
      "Interaction training epoch: 16, train loss: 0.73725, val loss: 0.49828\n",
      "Interaction training epoch: 17, train loss: 0.73570, val loss: 0.49937\n",
      "Interaction training epoch: 18, train loss: 0.73399, val loss: 0.49990\n",
      "Interaction training epoch: 19, train loss: 0.73224, val loss: 0.49980\n",
      "Interaction training epoch: 20, train loss: 0.73051, val loss: 0.49955\n",
      "Interaction training epoch: 21, train loss: 0.72876, val loss: 0.49911\n",
      "Interaction training epoch: 22, train loss: 0.72694, val loss: 0.49640\n",
      "Interaction training epoch: 23, train loss: 0.72504, val loss: 0.49607\n",
      "Interaction training epoch: 24, train loss: 0.72313, val loss: 0.49556\n",
      "Interaction training epoch: 25, train loss: 0.72131, val loss: 0.49241\n",
      "Interaction training epoch: 26, train loss: 0.71962, val loss: 0.48962\n",
      "Interaction training epoch: 27, train loss: 0.71797, val loss: 0.48683\n",
      "Interaction training epoch: 28, train loss: 0.71635, val loss: 0.48393\n",
      "Interaction training epoch: 29, train loss: 0.71465, val loss: 0.48105\n",
      "Interaction training epoch: 30, train loss: 0.71263, val loss: 0.48004\n",
      "Interaction training epoch: 31, train loss: 0.71043, val loss: 0.48003\n",
      "Interaction training epoch: 32, train loss: 0.70841, val loss: 0.47916\n",
      "Interaction training epoch: 33, train loss: 0.70633, val loss: 0.47907\n",
      "Interaction training epoch: 34, train loss: 0.70420, val loss: 0.48009\n",
      "Interaction training epoch: 35, train loss: 0.70211, val loss: 0.48096\n",
      "Interaction training epoch: 36, train loss: 0.69989, val loss: 0.48220\n",
      "Interaction training epoch: 37, train loss: 0.69765, val loss: 0.48201\n",
      "Interaction training epoch: 38, train loss: 0.69542, val loss: 0.48051\n",
      "Interaction training epoch: 39, train loss: 0.69318, val loss: 0.47830\n",
      "Interaction training epoch: 40, train loss: 0.69099, val loss: 0.47726\n",
      "Interaction training epoch: 41, train loss: 0.68883, val loss: 0.47498\n",
      "Interaction training epoch: 42, train loss: 0.68652, val loss: 0.47342\n",
      "Interaction training epoch: 43, train loss: 0.68411, val loss: 0.47123\n",
      "Interaction training epoch: 44, train loss: 0.68167, val loss: 0.46895\n",
      "Interaction training epoch: 45, train loss: 0.67924, val loss: 0.46701\n",
      "Interaction training epoch: 46, train loss: 0.67686, val loss: 0.46495\n",
      "Interaction training epoch: 47, train loss: 0.67457, val loss: 0.46167\n",
      "Interaction training epoch: 48, train loss: 0.67220, val loss: 0.45904\n",
      "Interaction training epoch: 49, train loss: 0.66999, val loss: 0.45535\n",
      "Interaction training epoch: 50, train loss: 0.66755, val loss: 0.45359\n",
      "Interaction training epoch: 51, train loss: 0.66496, val loss: 0.45292\n",
      "Interaction training epoch: 52, train loss: 0.66197, val loss: 0.45438\n",
      "Interaction training epoch: 53, train loss: 0.65912, val loss: 0.45626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 54, train loss: 0.65636, val loss: 0.45868\n",
      "Interaction training epoch: 55, train loss: 0.65366, val loss: 0.46003\n",
      "Interaction training epoch: 56, train loss: 0.65102, val loss: 0.46078\n",
      "Interaction training epoch: 57, train loss: 0.64830, val loss: 0.45900\n",
      "Interaction training epoch: 58, train loss: 0.64559, val loss: 0.45830\n",
      "Interaction training epoch: 59, train loss: 0.64289, val loss: 0.45881\n",
      "Interaction training epoch: 60, train loss: 0.64015, val loss: 0.45775\n",
      "Interaction training epoch: 61, train loss: 0.63740, val loss: 0.45703\n",
      "Interaction training epoch: 62, train loss: 0.63460, val loss: 0.45452\n",
      "Interaction training epoch: 63, train loss: 0.63177, val loss: 0.45229\n",
      "Interaction training epoch: 64, train loss: 0.62904, val loss: 0.44799\n",
      "Interaction training epoch: 65, train loss: 0.62639, val loss: 0.44322\n",
      "Interaction training epoch: 66, train loss: 0.62372, val loss: 0.43996\n",
      "Interaction training epoch: 67, train loss: 0.62087, val loss: 0.43804\n",
      "Interaction training epoch: 68, train loss: 0.61796, val loss: 0.43545\n",
      "Interaction training epoch: 69, train loss: 0.61476, val loss: 0.43403\n",
      "Interaction training epoch: 70, train loss: 0.61177, val loss: 0.43157\n",
      "Interaction training epoch: 71, train loss: 0.60856, val loss: 0.43141\n",
      "Interaction training epoch: 72, train loss: 0.60542, val loss: 0.43022\n",
      "Interaction training epoch: 73, train loss: 0.60229, val loss: 0.43185\n",
      "Interaction training epoch: 74, train loss: 0.59931, val loss: 0.43067\n",
      "Interaction training epoch: 75, train loss: 0.59648, val loss: 0.42762\n",
      "Interaction training epoch: 76, train loss: 0.59408, val loss: 0.42083\n",
      "Interaction training epoch: 77, train loss: 0.59242, val loss: 0.41334\n",
      "Interaction training epoch: 78, train loss: 0.59046, val loss: 0.40904\n",
      "Interaction training epoch: 79, train loss: 0.58790, val loss: 0.40713\n",
      "Interaction training epoch: 80, train loss: 0.58466, val loss: 0.40710\n",
      "Interaction training epoch: 81, train loss: 0.58132, val loss: 0.40687\n",
      "Interaction training epoch: 82, train loss: 0.57779, val loss: 0.40781\n",
      "Interaction training epoch: 83, train loss: 0.57443, val loss: 0.40818\n",
      "Interaction training epoch: 84, train loss: 0.57121, val loss: 0.40858\n",
      "Interaction training epoch: 85, train loss: 0.56817, val loss: 0.40966\n",
      "Interaction training epoch: 86, train loss: 0.56514, val loss: 0.41107\n",
      "Interaction training epoch: 87, train loss: 0.56218, val loss: 0.41366\n",
      "Interaction training epoch: 88, train loss: 0.55931, val loss: 0.41163\n",
      "Interaction training epoch: 89, train loss: 0.55658, val loss: 0.41073\n",
      "Interaction training epoch: 90, train loss: 0.55383, val loss: 0.40779\n",
      "Interaction training epoch: 91, train loss: 0.55106, val loss: 0.40608\n",
      "Interaction training epoch: 92, train loss: 0.54839, val loss: 0.40350\n",
      "Interaction training epoch: 93, train loss: 0.54576, val loss: 0.40260\n",
      "Interaction training epoch: 94, train loss: 0.54327, val loss: 0.40119\n",
      "Interaction training epoch: 95, train loss: 0.54075, val loss: 0.39971\n",
      "Interaction training epoch: 96, train loss: 0.53817, val loss: 0.39894\n",
      "Interaction training epoch: 97, train loss: 0.53593, val loss: 0.39633\n",
      "Interaction training epoch: 98, train loss: 0.53412, val loss: 0.39169\n",
      "Interaction training epoch: 99, train loss: 0.53224, val loss: 0.38779\n",
      "Interaction training epoch: 100, train loss: 0.52984, val loss: 0.38617\n",
      "Interaction training epoch: 101, train loss: 0.52667, val loss: 0.38870\n",
      "Interaction training epoch: 102, train loss: 0.52375, val loss: 0.39292\n",
      "Interaction training epoch: 103, train loss: 0.52139, val loss: 0.39437\n",
      "Interaction training epoch: 104, train loss: 0.51902, val loss: 0.39484\n",
      "Interaction training epoch: 105, train loss: 0.51675, val loss: 0.39801\n",
      "Interaction training epoch: 106, train loss: 0.51432, val loss: 0.39995\n",
      "Interaction training epoch: 107, train loss: 0.51225, val loss: 0.40339\n",
      "Interaction training epoch: 108, train loss: 0.50997, val loss: 0.40600\n",
      "Interaction training epoch: 109, train loss: 0.50752, val loss: 0.40825\n",
      "Interaction training epoch: 110, train loss: 0.50403, val loss: 0.40348\n",
      "Interaction training epoch: 111, train loss: 0.50147, val loss: 0.40277\n",
      "Interaction training epoch: 112, train loss: 0.49866, val loss: 0.39693\n",
      "Interaction training epoch: 113, train loss: 0.49622, val loss: 0.39367\n",
      "Interaction training epoch: 114, train loss: 0.49392, val loss: 0.39505\n",
      "Interaction training epoch: 115, train loss: 0.49162, val loss: 0.39458\n",
      "Interaction training epoch: 116, train loss: 0.48925, val loss: 0.39374\n",
      "Interaction training epoch: 117, train loss: 0.48707, val loss: 0.39069\n",
      "Interaction training epoch: 118, train loss: 0.48506, val loss: 0.38603\n",
      "Interaction training epoch: 119, train loss: 0.48292, val loss: 0.38160\n",
      "Interaction training epoch: 120, train loss: 0.48027, val loss: 0.38292\n",
      "Interaction training epoch: 121, train loss: 0.47765, val loss: 0.38595\n",
      "Interaction training epoch: 122, train loss: 0.47553, val loss: 0.38868\n",
      "Interaction training epoch: 123, train loss: 0.47354, val loss: 0.39194\n",
      "Interaction training epoch: 124, train loss: 0.47202, val loss: 0.39639\n",
      "Interaction training epoch: 125, train loss: 0.47011, val loss: 0.39808\n",
      "Interaction training epoch: 126, train loss: 0.46712, val loss: 0.39358\n",
      "Interaction training epoch: 127, train loss: 0.46427, val loss: 0.38566\n",
      "Interaction training epoch: 128, train loss: 0.46222, val loss: 0.37915\n",
      "Interaction training epoch: 129, train loss: 0.46102, val loss: 0.37172\n",
      "Interaction training epoch: 130, train loss: 0.46097, val loss: 0.36491\n",
      "Interaction training epoch: 131, train loss: 0.46023, val loss: 0.36153\n",
      "Interaction training epoch: 132, train loss: 0.45755, val loss: 0.36161\n",
      "Interaction training epoch: 133, train loss: 0.45434, val loss: 0.36309\n",
      "Interaction training epoch: 134, train loss: 0.45101, val loss: 0.36576\n",
      "Interaction training epoch: 135, train loss: 0.44842, val loss: 0.36702\n",
      "Interaction training epoch: 136, train loss: 0.44608, val loss: 0.36901\n",
      "Interaction training epoch: 137, train loss: 0.44375, val loss: 0.37141\n",
      "Interaction training epoch: 138, train loss: 0.44157, val loss: 0.37199\n",
      "Interaction training epoch: 139, train loss: 0.43934, val loss: 0.37294\n",
      "Interaction training epoch: 140, train loss: 0.43713, val loss: 0.37369\n",
      "Interaction training epoch: 141, train loss: 0.43499, val loss: 0.37283\n",
      "Interaction training epoch: 142, train loss: 0.43285, val loss: 0.37221\n",
      "Interaction training epoch: 143, train loss: 0.43063, val loss: 0.36948\n",
      "Interaction training epoch: 144, train loss: 0.42858, val loss: 0.36582\n",
      "Interaction training epoch: 145, train loss: 0.42683, val loss: 0.36132\n",
      "Interaction training epoch: 146, train loss: 0.42496, val loss: 0.35896\n",
      "Interaction training epoch: 147, train loss: 0.42288, val loss: 0.35843\n",
      "Interaction training epoch: 148, train loss: 0.42143, val loss: 0.35526\n",
      "Interaction training epoch: 149, train loss: 0.42061, val loss: 0.35146\n",
      "Interaction training epoch: 150, train loss: 0.41844, val loss: 0.35128\n",
      "Interaction training epoch: 151, train loss: 0.41623, val loss: 0.35128\n",
      "Interaction training epoch: 152, train loss: 0.41402, val loss: 0.35165\n",
      "Interaction training epoch: 153, train loss: 0.41180, val loss: 0.35609\n",
      "Interaction training epoch: 154, train loss: 0.41028, val loss: 0.36126\n",
      "Interaction training epoch: 155, train loss: 0.40866, val loss: 0.36285\n",
      "Interaction training epoch: 156, train loss: 0.40630, val loss: 0.36027\n",
      "Interaction training epoch: 157, train loss: 0.40382, val loss: 0.35285\n",
      "Interaction training epoch: 158, train loss: 0.40192, val loss: 0.34548\n",
      "Interaction training epoch: 159, train loss: 0.40043, val loss: 0.33886\n",
      "Interaction training epoch: 160, train loss: 0.39869, val loss: 0.33528\n",
      "Interaction training epoch: 161, train loss: 0.39687, val loss: 0.33277\n",
      "Interaction training epoch: 162, train loss: 0.39461, val loss: 0.33245\n",
      "Interaction training epoch: 163, train loss: 0.39234, val loss: 0.33388\n",
      "Interaction training epoch: 164, train loss: 0.39014, val loss: 0.33411\n",
      "Interaction training epoch: 165, train loss: 0.38764, val loss: 0.33818\n",
      "Interaction training epoch: 166, train loss: 0.38563, val loss: 0.34420\n",
      "Interaction training epoch: 167, train loss: 0.38361, val loss: 0.34458\n",
      "Interaction training epoch: 168, train loss: 0.38136, val loss: 0.34104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 169, train loss: 0.37934, val loss: 0.34122\n",
      "Interaction training epoch: 170, train loss: 0.37722, val loss: 0.34021\n",
      "Interaction training epoch: 171, train loss: 0.37521, val loss: 0.33929\n",
      "Interaction training epoch: 172, train loss: 0.37311, val loss: 0.33901\n",
      "Interaction training epoch: 173, train loss: 0.37104, val loss: 0.33627\n",
      "Interaction training epoch: 174, train loss: 0.36906, val loss: 0.33578\n",
      "Interaction training epoch: 175, train loss: 0.36705, val loss: 0.33380\n",
      "Interaction training epoch: 176, train loss: 0.36507, val loss: 0.33691\n",
      "Interaction training epoch: 177, train loss: 0.36305, val loss: 0.33814\n",
      "Interaction training epoch: 178, train loss: 0.36107, val loss: 0.33538\n",
      "Interaction training epoch: 179, train loss: 0.35958, val loss: 0.32975\n",
      "Interaction training epoch: 180, train loss: 0.35836, val loss: 0.32526\n",
      "Interaction training epoch: 181, train loss: 0.35664, val loss: 0.32377\n",
      "Interaction training epoch: 182, train loss: 0.35434, val loss: 0.32228\n",
      "Interaction training epoch: 183, train loss: 0.35196, val loss: 0.31837\n",
      "Interaction training epoch: 184, train loss: 0.34962, val loss: 0.31594\n",
      "Interaction training epoch: 185, train loss: 0.34738, val loss: 0.31496\n",
      "Interaction training epoch: 186, train loss: 0.34542, val loss: 0.31462\n",
      "Interaction training epoch: 187, train loss: 0.34372, val loss: 0.31104\n",
      "Interaction training epoch: 188, train loss: 0.34198, val loss: 0.30840\n",
      "Interaction training epoch: 189, train loss: 0.34015, val loss: 0.30586\n",
      "Interaction training epoch: 190, train loss: 0.33840, val loss: 0.30302\n",
      "Interaction training epoch: 191, train loss: 0.33649, val loss: 0.30451\n",
      "Interaction training epoch: 192, train loss: 0.33469, val loss: 0.31113\n",
      "Interaction training epoch: 193, train loss: 0.33270, val loss: 0.31260\n",
      "Interaction training epoch: 194, train loss: 0.33068, val loss: 0.31213\n",
      "Interaction training epoch: 195, train loss: 0.32861, val loss: 0.30943\n",
      "Interaction training epoch: 196, train loss: 0.32659, val loss: 0.30523\n",
      "Interaction training epoch: 197, train loss: 0.32487, val loss: 0.30130\n",
      "Interaction training epoch: 198, train loss: 0.32360, val loss: 0.29574\n",
      "Interaction training epoch: 199, train loss: 0.32195, val loss: 0.29254\n",
      "Interaction training epoch: 200, train loss: 0.31970, val loss: 0.29282\n",
      "Interaction training epoch: 201, train loss: 0.31758, val loss: 0.29288\n",
      "Interaction training epoch: 202, train loss: 0.31567, val loss: 0.29393\n",
      "Interaction training epoch: 203, train loss: 0.31396, val loss: 0.29274\n",
      "Interaction training epoch: 204, train loss: 0.31223, val loss: 0.29363\n",
      "Interaction training epoch: 205, train loss: 0.31056, val loss: 0.29482\n",
      "Interaction training epoch: 206, train loss: 0.30906, val loss: 0.29617\n",
      "Interaction training epoch: 207, train loss: 0.30749, val loss: 0.29583\n",
      "Interaction training epoch: 208, train loss: 0.30599, val loss: 0.28967\n",
      "Interaction training epoch: 209, train loss: 0.30441, val loss: 0.28788\n",
      "Interaction training epoch: 210, train loss: 0.30263, val loss: 0.28865\n",
      "Interaction training epoch: 211, train loss: 0.30090, val loss: 0.28910\n",
      "Interaction training epoch: 212, train loss: 0.29917, val loss: 0.29118\n",
      "Interaction training epoch: 213, train loss: 0.29750, val loss: 0.29170\n",
      "Interaction training epoch: 214, train loss: 0.29585, val loss: 0.29464\n",
      "Interaction training epoch: 215, train loss: 0.29434, val loss: 0.29955\n",
      "Interaction training epoch: 216, train loss: 0.29280, val loss: 0.30129\n",
      "Interaction training epoch: 217, train loss: 0.29102, val loss: 0.30190\n",
      "Interaction training epoch: 218, train loss: 0.28926, val loss: 0.30216\n",
      "Interaction training epoch: 219, train loss: 0.28741, val loss: 0.30063\n",
      "Interaction training epoch: 220, train loss: 0.28511, val loss: 0.29559\n",
      "Interaction training epoch: 221, train loss: 0.28323, val loss: 0.28965\n",
      "Interaction training epoch: 222, train loss: 0.28178, val loss: 0.27971\n",
      "Interaction training epoch: 223, train loss: 0.28071, val loss: 0.27284\n",
      "Interaction training epoch: 224, train loss: 0.27900, val loss: 0.27082\n",
      "Interaction training epoch: 225, train loss: 0.27725, val loss: 0.27351\n",
      "Interaction training epoch: 226, train loss: 0.27633, val loss: 0.28004\n",
      "Interaction training epoch: 227, train loss: 0.27567, val loss: 0.28440\n",
      "Interaction training epoch: 228, train loss: 0.27514, val loss: 0.28889\n",
      "Interaction training epoch: 229, train loss: 0.27352, val loss: 0.28887\n",
      "Interaction training epoch: 230, train loss: 0.26987, val loss: 0.28067\n",
      "Interaction training epoch: 231, train loss: 0.26719, val loss: 0.27604\n",
      "Interaction training epoch: 232, train loss: 0.26530, val loss: 0.27491\n",
      "Interaction training epoch: 233, train loss: 0.26362, val loss: 0.27429\n",
      "Interaction training epoch: 234, train loss: 0.26221, val loss: 0.27462\n",
      "Interaction training epoch: 235, train loss: 0.26111, val loss: 0.27278\n",
      "Interaction training epoch: 236, train loss: 0.26064, val loss: 0.26833\n",
      "Interaction training epoch: 237, train loss: 0.25944, val loss: 0.26705\n",
      "Interaction training epoch: 238, train loss: 0.25735, val loss: 0.26852\n",
      "Interaction training epoch: 239, train loss: 0.25521, val loss: 0.27183\n",
      "Interaction training epoch: 240, train loss: 0.25384, val loss: 0.27628\n",
      "Interaction training epoch: 241, train loss: 0.25273, val loss: 0.27864\n",
      "Interaction training epoch: 242, train loss: 0.25124, val loss: 0.27816\n",
      "Interaction training epoch: 243, train loss: 0.24913, val loss: 0.27134\n",
      "Interaction training epoch: 244, train loss: 0.24729, val loss: 0.26493\n",
      "Interaction training epoch: 245, train loss: 0.24565, val loss: 0.25760\n",
      "Interaction training epoch: 246, train loss: 0.24462, val loss: 0.24910\n",
      "Interaction training epoch: 247, train loss: 0.24461, val loss: 0.23889\n",
      "Interaction training epoch: 248, train loss: 0.24453, val loss: 0.23132\n",
      "Interaction training epoch: 249, train loss: 0.24333, val loss: 0.22772\n",
      "Interaction training epoch: 250, train loss: 0.24047, val loss: 0.22906\n",
      "Interaction training epoch: 251, train loss: 0.23795, val loss: 0.23180\n",
      "Interaction training epoch: 252, train loss: 0.23615, val loss: 0.23297\n",
      "Interaction training epoch: 253, train loss: 0.23485, val loss: 0.23823\n",
      "Interaction training epoch: 254, train loss: 0.23407, val loss: 0.24354\n",
      "Interaction training epoch: 255, train loss: 0.23323, val loss: 0.24751\n",
      "Interaction training epoch: 256, train loss: 0.23207, val loss: 0.25046\n",
      "Interaction training epoch: 257, train loss: 0.22998, val loss: 0.24739\n",
      "Interaction training epoch: 258, train loss: 0.22728, val loss: 0.23905\n",
      "Interaction training epoch: 259, train loss: 0.22573, val loss: 0.23329\n",
      "Interaction training epoch: 260, train loss: 0.22492, val loss: 0.22842\n",
      "Interaction training epoch: 261, train loss: 0.22416, val loss: 0.22490\n",
      "Interaction training epoch: 262, train loss: 0.22254, val loss: 0.22358\n",
      "Interaction training epoch: 263, train loss: 0.22095, val loss: 0.22141\n",
      "Interaction training epoch: 264, train loss: 0.21861, val loss: 0.22485\n",
      "Interaction training epoch: 265, train loss: 0.21707, val loss: 0.22756\n",
      "Interaction training epoch: 266, train loss: 0.21594, val loss: 0.22999\n",
      "Interaction training epoch: 267, train loss: 0.21490, val loss: 0.23227\n",
      "Interaction training epoch: 268, train loss: 0.21375, val loss: 0.23278\n",
      "Interaction training epoch: 269, train loss: 0.21228, val loss: 0.22982\n",
      "Interaction training epoch: 270, train loss: 0.21071, val loss: 0.22244\n",
      "Interaction training epoch: 271, train loss: 0.20947, val loss: 0.22009\n",
      "Interaction training epoch: 272, train loss: 0.20815, val loss: 0.22074\n",
      "Interaction training epoch: 273, train loss: 0.20677, val loss: 0.21932\n",
      "Interaction training epoch: 274, train loss: 0.20544, val loss: 0.21776\n",
      "Interaction training epoch: 275, train loss: 0.20433, val loss: 0.21452\n",
      "Interaction training epoch: 276, train loss: 0.20321, val loss: 0.21244\n",
      "Interaction training epoch: 277, train loss: 0.20199, val loss: 0.21140\n",
      "Interaction training epoch: 278, train loss: 0.20043, val loss: 0.21773\n",
      "Interaction training epoch: 279, train loss: 0.20024, val loss: 0.22635\n",
      "Interaction training epoch: 280, train loss: 0.19997, val loss: 0.23194\n",
      "Interaction training epoch: 281, train loss: 0.19919, val loss: 0.23522\n",
      "Interaction training epoch: 282, train loss: 0.19642, val loss: 0.22979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 283, train loss: 0.19428, val loss: 0.22155\n",
      "Interaction training epoch: 284, train loss: 0.19354, val loss: 0.21539\n",
      "Interaction training epoch: 285, train loss: 0.19262, val loss: 0.21317\n",
      "Interaction training epoch: 286, train loss: 0.19153, val loss: 0.21061\n",
      "Interaction training epoch: 287, train loss: 0.18963, val loss: 0.21432\n",
      "Interaction training epoch: 288, train loss: 0.18843, val loss: 0.21893\n",
      "Interaction training epoch: 289, train loss: 0.18773, val loss: 0.22341\n",
      "Interaction training epoch: 290, train loss: 0.18677, val loss: 0.22214\n",
      "Interaction training epoch: 291, train loss: 0.18545, val loss: 0.21639\n",
      "Interaction training epoch: 292, train loss: 0.18436, val loss: 0.21220\n",
      "Interaction training epoch: 293, train loss: 0.18331, val loss: 0.20931\n",
      "Interaction training epoch: 294, train loss: 0.18213, val loss: 0.20903\n",
      "Interaction training epoch: 295, train loss: 0.18093, val loss: 0.20953\n",
      "Interaction training epoch: 296, train loss: 0.17967, val loss: 0.20804\n",
      "Interaction training epoch: 297, train loss: 0.17857, val loss: 0.20728\n",
      "Interaction training epoch: 298, train loss: 0.17775, val loss: 0.20805\n",
      "Interaction training epoch: 299, train loss: 0.17705, val loss: 0.20815\n",
      "Interaction training epoch: 300, train loss: 0.17602, val loss: 0.20802\n",
      "Interaction training epoch: 301, train loss: 0.17516, val loss: 0.20837\n",
      "Interaction training epoch: 302, train loss: 0.17415, val loss: 0.20844\n",
      "Interaction training epoch: 303, train loss: 0.17325, val loss: 0.20894\n",
      "Interaction training epoch: 304, train loss: 0.17192, val loss: 0.20613\n",
      "Interaction training epoch: 305, train loss: 0.17067, val loss: 0.20145\n",
      "Interaction training epoch: 306, train loss: 0.16963, val loss: 0.19796\n",
      "Interaction training epoch: 307, train loss: 0.16869, val loss: 0.19528\n",
      "Interaction training epoch: 308, train loss: 0.16786, val loss: 0.19217\n",
      "Interaction training epoch: 309, train loss: 0.16722, val loss: 0.18957\n",
      "Interaction training epoch: 310, train loss: 0.16659, val loss: 0.18714\n",
      "Interaction training epoch: 311, train loss: 0.16577, val loss: 0.18477\n",
      "Interaction training epoch: 312, train loss: 0.16478, val loss: 0.18545\n",
      "Interaction training epoch: 313, train loss: 0.16380, val loss: 0.18578\n",
      "Interaction training epoch: 314, train loss: 0.16290, val loss: 0.18733\n",
      "Interaction training epoch: 315, train loss: 0.16222, val loss: 0.18991\n",
      "Interaction training epoch: 316, train loss: 0.16099, val loss: 0.18812\n",
      "Interaction training epoch: 317, train loss: 0.15973, val loss: 0.18568\n",
      "Interaction training epoch: 318, train loss: 0.15884, val loss: 0.18253\n",
      "Interaction training epoch: 319, train loss: 0.15821, val loss: 0.17789\n",
      "Interaction training epoch: 320, train loss: 0.15758, val loss: 0.17474\n",
      "Interaction training epoch: 321, train loss: 0.15708, val loss: 0.17142\n",
      "Interaction training epoch: 322, train loss: 0.15648, val loss: 0.16936\n",
      "Interaction training epoch: 323, train loss: 0.15532, val loss: 0.16988\n",
      "Interaction training epoch: 324, train loss: 0.15427, val loss: 0.16932\n",
      "Interaction training epoch: 325, train loss: 0.15371, val loss: 0.16723\n",
      "Interaction training epoch: 326, train loss: 0.15248, val loss: 0.16886\n",
      "Interaction training epoch: 327, train loss: 0.15146, val loss: 0.17003\n",
      "Interaction training epoch: 328, train loss: 0.15046, val loss: 0.17253\n",
      "Interaction training epoch: 329, train loss: 0.14941, val loss: 0.17285\n",
      "Interaction training epoch: 330, train loss: 0.14844, val loss: 0.17426\n",
      "Interaction training epoch: 331, train loss: 0.14749, val loss: 0.17553\n",
      "Interaction training epoch: 332, train loss: 0.14661, val loss: 0.17563\n",
      "Interaction training epoch: 333, train loss: 0.14592, val loss: 0.17331\n",
      "Interaction training epoch: 334, train loss: 0.14550, val loss: 0.17176\n",
      "Interaction training epoch: 335, train loss: 0.14463, val loss: 0.17369\n",
      "Interaction training epoch: 336, train loss: 0.14355, val loss: 0.17625\n",
      "Interaction training epoch: 337, train loss: 0.14271, val loss: 0.17987\n",
      "Interaction training epoch: 338, train loss: 0.14219, val loss: 0.18374\n",
      "Interaction training epoch: 339, train loss: 0.14182, val loss: 0.18692\n",
      "Interaction training epoch: 340, train loss: 0.14118, val loss: 0.18838\n",
      "Interaction training epoch: 341, train loss: 0.13994, val loss: 0.18549\n",
      "Interaction training epoch: 342, train loss: 0.13868, val loss: 0.17849\n",
      "Interaction training epoch: 343, train loss: 0.13864, val loss: 0.17021\n",
      "Interaction training epoch: 344, train loss: 0.13892, val loss: 0.16597\n",
      "Interaction training epoch: 345, train loss: 0.13916, val loss: 0.16250\n",
      "Interaction training epoch: 346, train loss: 0.13827, val loss: 0.16190\n",
      "Interaction training epoch: 347, train loss: 0.13679, val loss: 0.16332\n",
      "Interaction training epoch: 348, train loss: 0.13514, val loss: 0.16729\n",
      "Interaction training epoch: 349, train loss: 0.13449, val loss: 0.17083\n",
      "Interaction training epoch: 350, train loss: 0.13407, val loss: 0.17311\n",
      "Interaction training epoch: 351, train loss: 0.13366, val loss: 0.17750\n",
      "Interaction training epoch: 352, train loss: 0.13275, val loss: 0.17796\n",
      "Interaction training epoch: 353, train loss: 0.13193, val loss: 0.17900\n",
      "Interaction training epoch: 354, train loss: 0.13085, val loss: 0.17666\n",
      "Interaction training epoch: 355, train loss: 0.13024, val loss: 0.17262\n",
      "Interaction training epoch: 356, train loss: 0.12985, val loss: 0.17001\n",
      "Interaction training epoch: 357, train loss: 0.12904, val loss: 0.17147\n",
      "Interaction training epoch: 358, train loss: 0.12811, val loss: 0.17636\n",
      "Interaction training epoch: 359, train loss: 0.12741, val loss: 0.17805\n",
      "Interaction training epoch: 360, train loss: 0.12670, val loss: 0.17831\n",
      "Interaction training epoch: 361, train loss: 0.12613, val loss: 0.17991\n",
      "Interaction training epoch: 362, train loss: 0.12565, val loss: 0.18165\n",
      "Interaction training epoch: 363, train loss: 0.12505, val loss: 0.18127\n",
      "Interaction training epoch: 364, train loss: 0.12431, val loss: 0.17837\n",
      "Interaction training epoch: 365, train loss: 0.12382, val loss: 0.17547\n",
      "Interaction training epoch: 366, train loss: 0.12341, val loss: 0.17607\n",
      "Interaction training epoch: 367, train loss: 0.12292, val loss: 0.17562\n",
      "Interaction training epoch: 368, train loss: 0.12224, val loss: 0.17465\n",
      "Interaction training epoch: 369, train loss: 0.12117, val loss: 0.17633\n",
      "Interaction training epoch: 370, train loss: 0.12042, val loss: 0.17806\n",
      "Interaction training epoch: 371, train loss: 0.11989, val loss: 0.17687\n",
      "Interaction training epoch: 372, train loss: 0.11930, val loss: 0.17648\n",
      "Interaction training epoch: 373, train loss: 0.11888, val loss: 0.17401\n",
      "Interaction training epoch: 374, train loss: 0.11850, val loss: 0.17086\n",
      "Interaction training epoch: 375, train loss: 0.11814, val loss: 0.16904\n",
      "Interaction training epoch: 376, train loss: 0.11789, val loss: 0.16647\n",
      "Interaction training epoch: 377, train loss: 0.11792, val loss: 0.16272\n",
      "Interaction training epoch: 378, train loss: 0.11712, val loss: 0.16342\n",
      "Interaction training epoch: 379, train loss: 0.11620, val loss: 0.16683\n",
      "Interaction training epoch: 380, train loss: 0.11597, val loss: 0.17265\n",
      "Interaction training epoch: 381, train loss: 0.11556, val loss: 0.17315\n",
      "Interaction training epoch: 382, train loss: 0.11462, val loss: 0.17075\n",
      "Interaction training epoch: 383, train loss: 0.11398, val loss: 0.17074\n",
      "Interaction training epoch: 384, train loss: 0.11323, val loss: 0.16831\n",
      "Interaction training epoch: 385, train loss: 0.11259, val loss: 0.16823\n",
      "Interaction training epoch: 386, train loss: 0.11193, val loss: 0.16896\n",
      "Interaction training epoch: 387, train loss: 0.11125, val loss: 0.17122\n",
      "Interaction training epoch: 388, train loss: 0.11078, val loss: 0.17443\n",
      "Interaction training epoch: 389, train loss: 0.11045, val loss: 0.17807\n",
      "Interaction training epoch: 390, train loss: 0.11035, val loss: 0.18310\n",
      "Interaction training epoch: 391, train loss: 0.11028, val loss: 0.18782\n",
      "Interaction training epoch: 392, train loss: 0.10978, val loss: 0.18904\n",
      "Interaction training epoch: 393, train loss: 0.10852, val loss: 0.18567\n",
      "Interaction training epoch: 394, train loss: 0.10768, val loss: 0.18023\n",
      "Interaction training epoch: 395, train loss: 0.10731, val loss: 0.17703\n",
      "Interaction training epoch: 396, train loss: 0.10688, val loss: 0.17535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 397, train loss: 0.10622, val loss: 0.17639\n",
      "Early stop at epoch 397, with validation loss: 0.17639\n",
      "##########Stage 2: interaction training stop.##########\n",
      "Fine tuning epoch: 1, train loss: 0.32664, val loss: 0.12373\n",
      "Fine tuning epoch: 2, train loss: 0.32352, val loss: 0.12477\n",
      "Fine tuning epoch: 3, train loss: 0.31954, val loss: 0.12533\n",
      "Fine tuning epoch: 4, train loss: 0.31495, val loss: 0.12676\n",
      "Fine tuning epoch: 5, train loss: 0.31037, val loss: 0.12881\n",
      "Fine tuning epoch: 6, train loss: 0.30593, val loss: 0.13150\n",
      "Fine tuning epoch: 7, train loss: 0.30174, val loss: 0.13482\n",
      "Fine tuning epoch: 8, train loss: 0.29779, val loss: 0.13653\n",
      "Fine tuning epoch: 9, train loss: 0.29410, val loss: 0.13732\n",
      "Fine tuning epoch: 10, train loss: 0.29064, val loss: 0.13765\n",
      "Fine tuning epoch: 11, train loss: 0.28755, val loss: 0.13771\n",
      "Fine tuning epoch: 12, train loss: 0.28429, val loss: 0.13841\n",
      "Fine tuning epoch: 13, train loss: 0.28116, val loss: 0.13987\n",
      "Fine tuning epoch: 14, train loss: 0.27829, val loss: 0.13965\n",
      "Fine tuning epoch: 15, train loss: 0.27544, val loss: 0.13980\n",
      "Fine tuning epoch: 16, train loss: 0.27255, val loss: 0.14060\n",
      "Fine tuning epoch: 17, train loss: 0.26962, val loss: 0.14233\n",
      "Fine tuning epoch: 18, train loss: 0.26698, val loss: 0.14384\n",
      "Fine tuning epoch: 19, train loss: 0.26489, val loss: 0.14756\n",
      "Fine tuning epoch: 20, train loss: 0.26335, val loss: 0.15184\n",
      "Fine tuning epoch: 21, train loss: 0.26154, val loss: 0.15424\n",
      "Fine tuning epoch: 22, train loss: 0.25876, val loss: 0.15386\n",
      "Fine tuning epoch: 23, train loss: 0.25550, val loss: 0.15091\n",
      "Fine tuning epoch: 24, train loss: 0.25253, val loss: 0.14706\n",
      "Fine tuning epoch: 25, train loss: 0.24992, val loss: 0.14355\n",
      "Fine tuning epoch: 26, train loss: 0.24742, val loss: 0.13970\n",
      "Fine tuning epoch: 27, train loss: 0.24556, val loss: 0.13514\n",
      "Fine tuning epoch: 28, train loss: 0.24324, val loss: 0.13358\n",
      "Fine tuning epoch: 29, train loss: 0.24121, val loss: 0.13183\n",
      "Fine tuning epoch: 30, train loss: 0.23942, val loss: 0.12979\n",
      "Fine tuning epoch: 31, train loss: 0.23785, val loss: 0.12798\n",
      "Fine tuning epoch: 32, train loss: 0.23578, val loss: 0.12748\n",
      "Fine tuning epoch: 33, train loss: 0.23352, val loss: 0.12805\n",
      "Fine tuning epoch: 34, train loss: 0.23141, val loss: 0.12958\n",
      "Fine tuning epoch: 35, train loss: 0.22959, val loss: 0.13056\n",
      "Fine tuning epoch: 36, train loss: 0.22770, val loss: 0.13192\n",
      "Fine tuning epoch: 37, train loss: 0.22591, val loss: 0.13295\n",
      "Fine tuning epoch: 38, train loss: 0.22399, val loss: 0.13388\n",
      "Fine tuning epoch: 39, train loss: 0.22229, val loss: 0.13613\n",
      "Fine tuning epoch: 40, train loss: 0.22058, val loss: 0.13731\n",
      "Fine tuning epoch: 41, train loss: 0.21878, val loss: 0.13703\n",
      "Fine tuning epoch: 42, train loss: 0.21733, val loss: 0.13485\n",
      "Fine tuning epoch: 43, train loss: 0.21645, val loss: 0.13411\n",
      "Fine tuning epoch: 44, train loss: 0.21567, val loss: 0.13442\n",
      "Fine tuning epoch: 45, train loss: 0.21451, val loss: 0.13482\n",
      "Fine tuning epoch: 46, train loss: 0.21252, val loss: 0.13535\n",
      "Fine tuning epoch: 47, train loss: 0.21025, val loss: 0.13538\n",
      "Fine tuning epoch: 48, train loss: 0.20839, val loss: 0.13469\n",
      "Fine tuning epoch: 49, train loss: 0.20660, val loss: 0.13457\n",
      "Fine tuning epoch: 50, train loss: 0.20515, val loss: 0.13442\n",
      "Fine tuning epoch: 51, train loss: 0.20393, val loss: 0.13404\n",
      "Fine tuning epoch: 52, train loss: 0.20251, val loss: 0.13310\n",
      "Early stop at epoch 52, with validation loss: 0.13310\n",
      "####################GAMI-Net training finished.####################\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function GAMINet.predict_graph at 0x7f14ec1b9900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "main_support_true: [1 1 1 1 0 0 0 0 0 0]\n",
      "main_support_recovered: [1 0 0 0 0 1 0 0 0 0]\n",
      "interaction_support_true: [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "interaction_support_recovered: [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fabf9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"\"\"/home/gridsan/shibal/.conda/envs/EBM/bin/python /home/gridsan/shibal/elaan/baselines/EBM/ebm_synthetic.py  --dist 'normal' --seed 1 --dataset 'synthetic' --correlation 0.5 --train_size 100 --version 1 \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "621e3dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:17) [GCC 12.2.0] linux /home/gridsan/shibal/.conda/envs/EBM/bin/python\n",
      "===================FOLD: 0 ================\n",
      "\u001b[32m[I 2024-02-10 10:59:43,182]\u001b[0m A new study created in memory with name: no-name-5c169082-29b4-4d3b-bb08-c1ca54a1d6d7\u001b[0m\n",
      "Train: MSE: 1.2536109119609844e-30\n",
      "Val: MSE: 0.5760261642941736\n",
      "\u001b[32m[I 2024-02-10 11:00:03,742]\u001b[0m Trial 0 finished with value: 0.5760261642941736 and parameters: {'num_of_interactions': 25}. Best is trial 0 with value: 0.5760261642941736.\u001b[0m\n",
      "Train: MSE: 1.6285047312156263e-30\n",
      "Val: MSE: 0.5760261642941041\n",
      "\u001b[32m[I 2024-02-10 11:00:30,101]\u001b[0m Trial 1 finished with value: 0.5760261642941041 and parameters: {'num_of_interactions': 33}. Best is trial 1 with value: 0.5760261642941041.\u001b[0m\n",
      "Number of finished trials: 2\n",
      "Best trial:\n",
      "  Value: 0.5760261642941041\n",
      "  Params: \n",
      "    num_of_interactions: 33\n",
      "Training completed in 00:00:46.92\n",
      "===================FOLD: 1 ================\n",
      "\u001b[32m[I 2024-02-10 11:00:30,135]\u001b[0m A new study created in memory with name: no-name-b59bea0f-7465-4069-93f6-ff636da71b23\u001b[0m\n",
      "Train: MSE: 1.9323394392421567e-30\n",
      "Val: MSE: 0.5020193753529592\n",
      "\u001b[32m[I 2024-02-10 11:00:52,714]\u001b[0m Trial 0 finished with value: 0.5020193753529592 and parameters: {'num_of_interactions': 25}. Best is trial 0 with value: 0.5020193753529592.\u001b[0m\n",
      "Train: MSE: 1.4277920161313662e-30\n",
      "Val: MSE: 0.5020193753530092\n",
      "\u001b[32m[I 2024-02-10 11:01:17,403]\u001b[0m Trial 1 finished with value: 0.5020193753530092 and parameters: {'num_of_interactions': 33}. Best is trial 0 with value: 0.5020193753529592.\u001b[0m\n",
      "Number of finished trials: 2\n",
      "Best trial:\n",
      "  Value: 0.5020193753529592\n",
      "  Params: \n",
      "    num_of_interactions: 25\n",
      "Training completed in 00:00:47.27\n",
      "0\n",
      "                               val-0\n",
      "params_num_of_interactions          \n",
      "25                          0.576026\n",
      "33                          0.576026\n",
      "1\n",
      "                               val-0     val-1\n",
      "params_num_of_interactions                    \n",
      "25                          0.576026  0.502019\n",
      "33                          0.576026  0.502019\n",
      "   params_num_of_interactions         0\n",
      "0                          33  0.539023\n",
      "num_of_interactions_opt: 33\n",
      "['feature_0000', 'feature_0001', 'feature_0002', 'feature_0003', 'feature_0004', 'feature_0005', 'feature_0006', 'feature_0007', 'feature_0008', 'feature_0009', 'feature_0000 & feature_0001', 'feature_0000 & feature_0002', 'feature_0000 & feature_0003', 'feature_0000 & feature_0005', 'feature_0000 & feature_0007', 'feature_0000 & feature_0009', 'feature_0001 & feature_0002', 'feature_0001 & feature_0003', 'feature_0001 & feature_0005', 'feature_0001 & feature_0007', 'feature_0001 & feature_0008', 'feature_0001 & feature_0009', 'feature_0002 & feature_0005', 'feature_0002 & feature_0006', 'feature_0002 & feature_0007', 'feature_0002 & feature_0008', 'feature_0002 & feature_0009', 'feature_0003 & feature_0004', 'feature_0003 & feature_0006', 'feature_0003 & feature_0007', 'feature_0003 & feature_0009', 'feature_0004 & feature_0005', 'feature_0004 & feature_0007', 'feature_0004 & feature_0009', 'feature_0005 & feature_0006', 'feature_0005 & feature_0007', 'feature_0005 & feature_0008', 'feature_0005 & feature_0009', 'feature_0006 & feature_0007', 'feature_0006 & feature_0008', 'feature_0006 & feature_0009', 'feature_0007 & feature_0008', 'feature_0007 & feature_0009']\n",
      "main_support_true: [1 1 1 1 0 0 0 0 0 0]\n",
      "main_support_recovered: [1 1 1 1 1 1 1 1 1 1]\n",
      "interaction_support_true: [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "interaction_support_recovered: [1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628765e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-additive2]",
   "language": "python",
   "name": "conda-env-.conda-additive2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
